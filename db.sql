-- --------------------------------------------------------
-- Host:                         127.0.0.1
-- Server version:               5.5.24 - MySQL Community Server (GPL)
-- Server OS:                    Win64
-- HeidiSQL version:             7.0.0.4160
-- Date/time:                    2012-07-08 01:45:05
-- --------------------------------------------------------

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET NAMES utf8 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;

-- Dumping database structure for talkincode_db1
DROP DATABASE IF EXISTS `talkincode_db1`;
CREATE DATABASE IF NOT EXISTS `talkincode_db1` /*!40100 DEFAULT CHARACTER SET utf8 */;
USE `talkincode_db1`;


-- Dumping structure for table talkincode_db1.authkeys
DROP TABLE IF EXISTS `authkeys`;
CREATE TABLE IF NOT EXISTS `authkeys` (
  `authkey` varchar(128) NOT NULL,
  `consumer` varchar(255) NOT NULL,
  `description` varchar(1024) DEFAULT NULL,
  `hits` int(11) NOT NULL DEFAULT '0',
  `create_time` varchar(19) DEFAULT NULL,
  `status` int(1) DEFAULT '1',
  PRIMARY KEY (`authkey`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- Dumping data for table talkincode_db1.authkeys: ~4 rows (approximately)
DELETE FROM `authkeys`;
/*!40000 ALTER TABLE `authkeys` DISABLE KEYS */;
INSERT INTO `authkeys` (`authkey`, `consumer`, `description`, `hits`, `create_time`, `status`) VALUES
	('4661d99ed6c44cffac0ec49a8810fed9', 'test', '', 0, '2012-07-07 01:13:54', 1),
	('494ec9f9cbaf40cfa8d4b44447374d27', 'public', 'public authkey', 10, '2012-06-30 21:20:12', 1),
	('c6ea05d93eb44b9a988ffbfe84d869a9', 'jamiesun', '', 0, '2012-07-07 01:20:22', 1),
	('e3fbf732af7a4f09ae8a2fc9c14e1fc6', 'test2', '', 0, '2012-07-07 01:17:17', 1);
/*!40000 ALTER TABLE `authkeys` ENABLE KEYS */;


-- Dumping structure for table talkincode_db1.category
DROP TABLE IF EXISTS `category`;
CREATE TABLE IF NOT EXISTS `category` (
  `id` varchar(32) NOT NULL,
  `parent` varchar(32) NOT NULL,
  `name` varchar(128) NOT NULL,
  `nicename` varchar(255) DEFAULT NULL,
  `description` text,
  PRIMARY KEY (`id`),
  KEY `parent` (`parent`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- Dumping data for table talkincode_db1.category: ~0 rows (approximately)
DELETE FROM `category`;
/*!40000 ALTER TABLE `category` DISABLE KEYS */;
/*!40000 ALTER TABLE `category` ENABLE KEYS */;


-- Dumping structure for table talkincode_db1.codes
DROP TABLE IF EXISTS `codes`;
CREATE TABLE IF NOT EXISTS `codes` (
  `id` varchar(32) NOT NULL,
  `parent` varchar(32) DEFAULT NULL,
  `title` varchar(512) DEFAULT NULL,
  `auther` varchar(128) DEFAULT NULL,
  `email` varchar(255) DEFAULT NULL,
  `tags` varchar(255) DEFAULT NULL,
  `content` text,
  `authkey` varchar(128) NOT NULL,
  `lang` varchar(32) DEFAULT NULL,
  `filename` varchar(255) DEFAULT NULL,
  `hits` int(11) DEFAULT '0',
  `create_time` varchar(19) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- Dumping data for table talkincode_db1.codes: ~22 rows (approximately)
DELETE FROM `codes`;
/*!40000 ALTER TABLE `codes` DISABLE KEYS */;
INSERT INTO `codes` (`id`, `parent`, `title`, `auther`, `email`, `tags`, `content`, `authkey`, `lang`, `filename`, `hits`, `create_time`) VALUES
	('023a60199fd7403f986bb993c3d57874', NULL, ' python anydbm', 'jamiesun', 'jamiesun.net@gmail.com', 'other', '"""Generic interface to all dbm clones.\n\nInstead of\n\n        import dbm\n        d = dbm.open(file, \'w\', 0666)\n\nuse\n\n        import anydbm\n        d = anydbm.open(file, \'w\')\n\nThe returned object is a dbhash, gdbm, dbm or dumbdbm object,\ndependent on the type of database being opened (determined by whichdb\nmodule) in the case of an existing dbm. If the dbm does not exist and\nthe create or new flag (\'c\' or \'n\') was specified, the dbm type will\nbe determined by the availability of the modules (tested in the above\norder).\n\nIt has the following interface (key and data are strings):\n\n        d[key] = data   # store data at key (may override data at\n                        # existing key)\n        data = d[key]   # retrieve data at key (raise KeyError if no\n                        # such key)\n        del d[key]      # delete data stored at key (raises KeyError\n                        # if no such key)\n        flag = key in d   # true if the key exists\n        list = d.keys() # return a list of all existing keys (slow!)\n\nFuture versions may change the order in which implementations are\ntested for existence, and add interfaces to other dbm-like\nimplementations.\n@description: python anydbm\n@tags:python,dbm\n"""\n\nclass error(Exception):\n    pass\n\n_names = [\'dbhash\', \'gdbm\', \'dbm\', \'dumbdbm\']\n_errors = [error]\n_defaultmod = None\n\nfor _name in _names:\n    try:\n        _mod = __import__(_name)\n    except ImportError:\n        continue\n    if not _defaultmod:\n        _defaultmod = _mod\n    _errors.append(_mod.error)\n\nif not _defaultmod:\n    raise ImportError, "no dbm clone found; tried %s" % _names\n\nerror = tuple(_errors)\n\ndef open(file, flag=\'r\', mode=0666):\n    """Open or create database at path given by *file*.\n\n    Optional argument *flag* can be \'r\' (default) for read-only access, \'w\'\n    for read-write access of an existing database, \'c\' for read-write access\n    to a new or existing database, and \'n\' for read-write access to a new\n    database.\n\n    Note: \'r\' and \'w\' fail if the database doesn\'t exist; \'c\' creates it\n    only if it doesn\'t exist; and \'n\' always creates a new database.\n    """\n\n    # guess the type of an existing database\n    from whichdb import whichdb\n    result=whichdb(file)\n    if result is None:\n        # db doesn\'t exist\n        if \'c\' in flag or \'n\' in flag:\n            # file doesn\'t exist and the new\n            # flag was used so use default type\n            mod = _defaultmod\n        else:\n            raise error, "need \'c\' or \'n\' flag to open new db"\n    elif result == "":\n        # db type cannot be determined\n        raise error, "db type could not be determined"\n    else:\n        mod = __import__(result)\n    return mod.open(file, flag, mode)\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'anydbm.py', 5, '2012-07-06 13:41:35'),
	('038b2af0ca714704bc80d89388095b77', NULL, ' python argparse', 'jamiesun', 'jamiesun.net@gmail.com', 'other', '#! /usr/bin/env python\n#@description: python argparse\n#@tags:python,argparse\n"""RFC 3548: Base16, Base32, Base64 Data Encodings"""\n\n# Modified 04-Oct-1995 by Jack Jansen to use binascii module\n# Modified 30-Dec-2003 by Barry Warsaw to add full RFC 3548 support\n\nimport re\nimport struct\nimport binascii\n\n\n__all__ = [\n    # Legacy interface exports traditional RFC 1521 Base64 encodings\n    \'encode\', \'decode\', \'encodestring\', \'decodestring\',\n    # Generalized interface for other encodings\n    \'b64encode\', \'b64decode\', \'b32encode\', \'b32decode\',\n    \'b16encode\', \'b16decode\',\n    # Standard Base64 encoding\n    \'standard_b64encode\', \'standard_b64decode\',\n    # Some common Base64 alternatives.  As referenced by RFC 3458, see thread\n    # starting at:\n    #\n    # http://zgp.org/pipermail/p2p-hackers/2001-September/000316.html\n    \'urlsafe_b64encode\', \'urlsafe_b64decode\',\n    ]\n\n_translation = [chr(_x) for _x in range(256)]\nEMPTYSTRING = \'\'\n\n\ndef _translate(s, altchars):\n    translation = _translation[:]\n    for k, v in altchars.items():\n        translation[ord(k)] = v\n    return s.translate(\'\'.join(translation))\n\n\n\n# Base64 encoding/decoding uses binascii\n\ndef b64encode(s, altchars=None):\n    """Encode a string using Base64.\n\n    s is the string to encode.  Optional altchars must be a string of at least\n    length 2 (additional characters are ignored) which specifies an\n    alternative alphabet for the \'+\' and \'/\' characters.  This allows an\n    application to e.g. generate url or filesystem safe Base64 strings.\n\n    The encoded string is returned.\n    """\n    # Strip off the trailing newline\n    encoded = binascii.b2a_base64(s)[:-1]\n    if altchars is not None:\n        return _translate(encoded, {\'+\': altchars[0], \'/\': altchars[1]})\n    return encoded\n\n\ndef b64decode(s, altchars=None):\n    """Decode a Base64 encoded string.\n\n    s is the string to decode.  Optional altchars must be a string of at least\n    length 2 (additional characters are ignored) which specifies the\n    alternative alphabet used instead of the \'+\' and \'/\' characters.\n\n    The decoded string is returned.  A TypeError is raised if s were\n    incorrectly padded or if there are non-alphabet characters present in the\n    string.\n    """\n    if altchars is not None:\n        s = _translate(s, {altchars[0]: \'+\', altchars[1]: \'/\'})\n    try:\n        return binascii.a2b_base64(s)\n    except binascii.Error, msg:\n        # Transform this exception for consistency\n        raise TypeError(msg)\n\n\ndef standard_b64encode(s):\n    """Encode a string using the standard Base64 alphabet.\n\n    s is the string to encode.  The encoded string is returned.\n    """\n    return b64encode(s)\n\ndef standard_b64decode(s):\n    """Decode a string encoded with the standard Base64 alphabet.\n\n    s is the string to decode.  The decoded string is returned.  A TypeError\n    is raised if the string is incorrectly padded or if there are non-alphabet\n    characters present in the string.\n    """\n    return b64decode(s)\n\ndef urlsafe_b64encode(s):\n    """Encode a string using a url-safe Base64 alphabet.\n\n    s is the string to encode.  The encoded string is returned.  The alphabet\n    uses \'-\' instead of \'+\' and \'_\' instead of \'/\'.\n    """\n    return b64encode(s, \'-_\')\n\ndef urlsafe_b64decode(s):\n    """Decode a string encoded with the standard Base64 alphabet.\n\n    s is the string to decode.  The decoded string is returned.  A TypeError\n    is raised if the string is incorrectly padded or if there are non-alphabet\n    characters present in the string.\n\n    The alphabet uses \'-\' instead of \'+\' and \'_\' instead of \'/\'.\n    """\n    return b64decode(s, \'-_\')\n\n\n\n# Base32 encoding/decoding must be done in Python\n_b32alphabet = {\n    0: \'A\',  9: \'J\', 18: \'S\', 27: \'3\',\n    1: \'B\', 10: \'K\', 19: \'T\', 28: \'4\',\n    2: \'C\', 11: \'L\', 20: \'U\', 29: \'5\',\n    3: \'D\', 12: \'M\', 21: \'V\', 30: \'6\',\n    4: \'E\', 13: \'N\', 22: \'W\', 31: \'7\',\n    5: \'F\', 14: \'O\', 23: \'X\',\n    6: \'G\', 15: \'P\', 24: \'Y\',\n    7: \'H\', 16: \'Q\', 25: \'Z\',\n    8: \'I\', 17: \'R\', 26: \'2\',\n    }\n\n_b32tab = _b32alphabet.items()\n_b32tab.sort()\n_b32tab = [v for k, v in _b32tab]\n_b32rev = dict([(v, long(k)) for k, v in _b32alphabet.items()])\n\n\ndef b32encode(s):\n    """Encode a string using Base32.\n\n    s is the string to encode.  The encoded string is returned.\n    """\n    parts = []\n    quanta, leftover = divmod(len(s), 5)\n    # Pad the last quantum with zero bits if necessary\n    if leftover:\n        s += (\'\\0\' * (5 - leftover))\n        quanta += 1\n    for i in range(quanta):\n        # c1 and c2 are 16 bits wide, c3 is 8 bits wide.  The intent of this\n        # code is to process the 40 bits in units of 5 bits.  So we take the 1\n        # leftover bit of c1 and tack it onto c2.  Then we take the 2 leftover\n        # bits of c2 and tack them onto c3.  The shifts and masks are intended\n        # to give us values of exactly 5 bits in width.\n        c1, c2, c3 = struct.unpack(\'!HHB\', s[i*5:(i+1)*5])\n        c2 += (c1 & 1) << 16 # 17 bits wide\n        c3 += (c2 & 3) << 8  # 10 bits wide\n        parts.extend([_b32tab[c1 >> 11],         # bits 1 - 5\n                      _b32tab[(c1 >> 6) & 0x1f], # bits 6 - 10\n                      _b32tab[(c1 >> 1) & 0x1f], # bits 11 - 15\n                      _b32tab[c2 >> 12],         # bits 16 - 20 (1 - 5)\n                      _b32tab[(c2 >> 7) & 0x1f], # bits 21 - 25 (6 - 10)\n                      _b32tab[(c2 >> 2) & 0x1f], # bits 26 - 30 (11 - 15)\n                      _b32tab[c3 >> 5],          # bits 31 - 35 (1 - 5)\n                      _b32tab[c3 & 0x1f],        # bits 36 - 40 (1 - 5)\n                      ])\n    encoded = EMPTYSTRING.join(parts)\n    # Adjust for any leftover partial quanta\n    if leftover == 1:\n        return encoded[:-6] + \'======\'\n    elif leftover == 2:\n        return encoded[:-4] + \'====\'\n    elif leftover == 3:\n        return encoded[:-3] + \'===\'\n    elif leftover == 4:\n        return encoded[:-1] + \'=\'\n    return encoded\n\n\ndef b32decode(s, casefold=False, map01=None):\n    """Decode a Base32 encoded string.\n\n    s is the string to decode.  Optional casefold is a flag specifying whether\n    a lowercase alphabet is acceptable as input.  For security purposes, the\n    default is False.\n\n    RFC 3548 allows for optional mapping of the digit 0 (zero) to the letter O\n    (oh), and for optional mapping of the digit 1 (one) to either the letter I\n    (eye) or letter L (el).  The optional argument map01 when not None,\n    specifies which letter the digit 1 should be mapped to (when map01 is not\n    None, the digit 0 is always mapped to the letter O).  For security\n    purposes the default is None, so that 0 and 1 are not allowed in the\n    input.\n\n    The decoded string is returned.  A TypeError is raised if s were\n    incorrectly padded or if there are non-alphabet characters present in the\n    string.\n    """\n    quanta, leftover = divmod(len(s), 8)\n    if leftover:\n        raise TypeError(\'Incorrect padding\')\n    # Handle section 2.4 zero and one mapping.  The flag map01 will be either\n    # False, or the character to map the digit 1 (one) to.  It should be\n    # either L (el) or I (eye).\n    if map01:\n        s = _translate(s, {\'0\': \'O\', \'1\': map01})\n    if casefold:\n        s = s.upper()\n    # Strip off pad characters from the right.  We need to count the pad\n    # characters because this will tell us how many null bytes to remove from\n    # the end of the decoded string.\n    padchars = 0\n    mo = re.search(\'(?P<pad>[=]*)$\', s)\n    if mo:\n        padchars = len(mo.group(\'pad\'))\n        if padchars > 0:\n            s = s[:-padchars]\n    # Now decode the full quanta\n    parts = []\n    acc = 0\n    shift = 35\n    for c in s:\n        val = _b32rev.get(c)\n        if val is None:\n            raise TypeError(\'Non-base32 digit found\')\n        acc += _b32rev[c] << shift\n        shift -= 5\n        if shift < 0:\n            parts.append(binascii.unhexlify(\'%010x\' % acc))\n            acc = 0\n            shift = 35\n    # Process the last, partial quanta\n    last = binascii.unhexlify(\'%010x\' % acc)\n    if padchars == 0:\n        last = \'\'                       # No characters\n    elif padchars == 1:\n        last = last[:-1]\n    elif padchars == 3:\n        last = last[:-2]\n    elif padchars == 4:\n        last = last[:-3]\n    elif padchars == 6:\n        last = last[:-4]\n    else:\n        raise TypeError(\'Incorrect padding\')\n    parts.append(last)\n    return EMPTYSTRING.join(parts)\n\n\n\n# RFC 3548, Base 16 Alphabet specifies uppercase, but hexlify() returns\n# lowercase.  The RFC also recommends against accepting input case\n# insensitively.\ndef b16encode(s):\n    """Encode a string using Base16.\n\n    s is the string to encode.  The encoded string is returned.\n    """\n    return binascii.hexlify(s).upper()\n\n\ndef b16decode(s, casefold=False):\n    """Decode a Base16 encoded string.\n\n    s is the string to decode.  Optional casefold is a flag specifying whether\n    a lowercase alphabet is acceptable as input.  For security purposes, the\n    default is False.\n\n    The decoded string is returned.  A TypeError is raised if s were\n    incorrectly padded or if there are non-alphabet characters present in the\n    string.\n    """\n    if casefold:\n        s = s.upper()\n    if re.search(\'[^0-9A-F]\', s):\n        raise TypeError(\'Non-base16 digit found\')\n    return binascii.unhexlify(s)\n\n\n\n# Legacy interface.  This code could be cleaned up since I don\'t believe\n# binascii has any line length limitations.  It just doesn\'t seem worth it\n# though.\n\nMAXLINESIZE = 76 # Excluding the CRLF\nMAXBINSIZE = (MAXLINESIZE//4)*3\n\ndef encode(input, output):\n    """Encode a file."""\n    while True:\n        s = input.read(MAXBINSIZE)\n        if not s:\n            break\n        while len(s) < MAXBINSIZE:\n            ns = input.read(MAXBINSIZE-len(s))\n            if not ns:\n                break\n            s += ns\n        line = binascii.b2a_base64(s)\n        output.write(line)\n\n\ndef decode(input, output):\n    """Decode a file."""\n    while True:\n        line = input.readline()\n        if not line:\n            break\n        s = binascii.a2b_base64(line)\n        output.write(s)\n\n\ndef encodestring(s):\n    """Encode a string into multiple lines of base-64 data."""\n    pieces = []\n    for i in range(0, len(s), MAXBINSIZE):\n        chunk = s[i : i + MAXBINSIZE]\n        pieces.append(binascii.b2a_base64(chunk))\n    return "".join(pieces)\n\n\ndef decodestring(s):\n    """Decode a string."""\n    return binascii.a2b_base64(s)\n\n\n\n# Useable as a script...\ndef test():\n    """Small test program"""\n    import sys, getopt\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], \'deut\')\n    except getopt.error, msg:\n        sys.stdout = sys.stderr\n        print msg\n        print """usage: %s [-d|-e|-u|-t] [file|-]\n        -d, -u: decode\n        -e: encode (default)\n        -t: encode and decode string \'Aladdin:open sesame\'"""%sys.argv[0]\n        sys.exit(2)\n    func = encode\n    for o, a in opts:\n        if o == \'-e\': func = encode\n        if o == \'-d\': func = decode\n        if o == \'-u\': func = decode\n        if o == \'-t\': test1(); return\n    if args and args[0] != \'-\':\n        with open(args[0], \'rb\') as f:\n            func(f, sys.stdout)\n    else:\n        func(sys.stdin, sys.stdout)\n\n\ndef test1():\n    s0 = "Aladdin:open sesame"\n    s1 = encodestring(s0)\n    s2 = decodestring(s1)\n    print s0, repr(s1), s2\n\n\nif __name__ == \'__main__\':\n    test()\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'base64.py', 2, '2012-07-06 13:44:21'),
	('0efd503e59cb402d887ed5972f56995f', NULL, 'python cgi http server module', 'jamiesun', 'jamiesun.net@gmail.com', 'cgi,python', '"""CGI-savvy HTTP Server.\n\nThis module builds on SimpleHTTPServer by implementing GET and POST\nrequests to cgi-bin scripts.\n\nIf the os.fork() function is not present (e.g. on Windows),\nos.popen2() is used as a fallback, with slightly altered semantics; if\nthat function is not present either (e.g. on Macintosh), only Python\nscripts are supported, and they are executed by the current process.\n\nIn all cases, the implementation is intentionally naive -- all\nrequests are executed sychronously.\n\nSECURITY WARNING: DON\'T USE THIS CODE UNLESS YOU ARE INSIDE A FIREWALL\n-- it may execute arbitrary Python code or external programs.\n\nNote that status code 200 is sent prior to execution of a CGI script, so\nscripts cannot send other status codes such as 302 (redirect).\n"""\n"""\n@description:python cgi http server module\n@tags:cgi\n"""\n\n__version__ = "0.4"\n\n__all__ = ["CGIHTTPRequestHandler"]\n\nimport os\nimport sys\nimport urllib\nimport BaseHTTPServer\nimport SimpleHTTPServer\nimport select\nimport copy\n\n\nclass CGIHTTPRequestHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):\n\n    """Complete HTTP server with GET, HEAD and POST commands.\n\n    GET and HEAD also support running CGI scripts.\n\n    The POST command is *only* implemented for CGI scripts.\n\n    """\n\n    # Determine platform specifics\n    have_fork = hasattr(os, \'fork\')\n    have_popen2 = hasattr(os, \'popen2\')\n    have_popen3 = hasattr(os, \'popen3\')\n\n    # Make rfile unbuffered -- we need to read one line and then pass\n    # the rest to a subprocess, so we can\'t use buffered input.\n    rbufsize = 0\n\n    def do_POST(self):\n        """Serve a POST request.\n\n        This is only implemented for CGI scripts.\n\n        """\n\n        if self.is_cgi():\n            self.run_cgi()\n        else:\n            self.send_error(501, "Can only POST to CGI scripts")\n\n    def send_head(self):\n        """Version of send_head that support CGI scripts"""\n        if self.is_cgi():\n            return self.run_cgi()\n        else:\n            return SimpleHTTPServer.SimpleHTTPRequestHandler.send_head(self)\n\n    def is_cgi(self):\n        """Test whether self.path corresponds to a CGI script.\n\n        Returns True and updates the cgi_info attribute to the tuple\n        (dir, rest) if self.path requires running a CGI script.\n        Returns False otherwise.\n\n        If any exception is raised, the caller should assume that\n        self.path was rejected as invalid and act accordingly.\n\n        The default implementation tests whether the normalized url\n        path begins with one of the strings in self.cgi_directories\n        (and the next character is a \'/\' or the end of the string).\n        """\n        splitpath = _url_collapse_path_split(self.path)\n        if splitpath[0] in self.cgi_directories:\n            self.cgi_info = splitpath\n            return True\n        return False\n\n    cgi_directories = [\'/cgi-bin\', \'/htbin\']\n\n    def is_executable(self, path):\n        """Test whether argument path is an executable file."""\n        return executable(path)\n\n    def is_python(self, path):\n        """Test whether argument path is a Python script."""\n        head, tail = os.path.splitext(path)\n        return tail.lower() in (".py", ".pyw")\n\n    def run_cgi(self):\n        """Execute a CGI script."""\n        path = self.path\n        dir, rest = self.cgi_info\n\n        i = path.find(\'/\', len(dir) + 1)\n        while i >= 0:\n            nextdir = path[:i]\n            nextrest = path[i+1:]\n\n            scriptdir = self.translate_path(nextdir)\n            if os.path.isdir(scriptdir):\n                dir, rest = nextdir, nextrest\n                i = path.find(\'/\', len(dir) + 1)\n            else:\n                break\n\n        # find an explicit query string, if present.\n        i = rest.rfind(\'?\')\n        if i >= 0:\n            rest, query = rest[:i], rest[i+1:]\n        else:\n            query = \'\'\n\n        # dissect the part after the directory name into a script name &\n        # a possible additional path, to be stored in PATH_INFO.\n        i = rest.find(\'/\')\n        if i >= 0:\n            script, rest = rest[:i], rest[i:]\n        else:\n            script, rest = rest, \'\'\n\n        scriptname = dir + \'/\' + script\n        scriptfile = self.translate_path(scriptname)\n        if not os.path.exists(scriptfile):\n            self.send_error(404, "No such CGI script (%r)" % scriptname)\n            return\n        if not os.path.isfile(scriptfile):\n            self.send_error(403, "CGI script is not a plain file (%r)" %\n                            scriptname)\n            return\n        ispy = self.is_python(scriptname)\n        if not ispy:\n            if not (self.have_fork or self.have_popen2 or self.have_popen3):\n                self.send_error(403, "CGI script is not a Python script (%r)" %\n                                scriptname)\n                return\n            if not self.is_executable(scriptfile):\n                self.send_error(403, "CGI script is not executable (%r)" %\n                                scriptname)\n                return\n\n        # Reference: http://hoohoo.ncsa.uiuc.edu/cgi/env.html\n        # XXX Much of the following could be prepared ahead of time!\n        env = copy.deepcopy(os.environ)\n        env[\'SERVER_SOFTWARE\'] = self.version_string()\n        env[\'SERVER_NAME\'] = self.server.server_name\n        env[\'GATEWAY_INTERFACE\'] = \'CGI/1.1\'\n        env[\'SERVER_PROTOCOL\'] = self.protocol_version\n        env[\'SERVER_PORT\'] = str(self.server.server_port)\n        env[\'REQUEST_METHOD\'] = self.command\n        uqrest = urllib.unquote(rest)\n        env[\'PATH_INFO\'] = uqrest\n        env[\'PATH_TRANSLATED\'] = self.translate_path(uqrest)\n        env[\'SCRIPT_NAME\'] = scriptname\n        if query:\n            env[\'QUERY_STRING\'] = query\n        host = self.address_string()\n        if host != self.client_address[0]:\n            env[\'REMOTE_HOST\'] = host\n        env[\'REMOTE_ADDR\'] = self.client_address[0]\n        authorization = self.headers.getheader("authorization")\n        if authorization:\n            authorization = authorization.split()\n            if len(authorization) == 2:\n                import base64, binascii\n                env[\'AUTH_TYPE\'] = authorization[0]\n                if authorization[0].lower() == "basic":\n                    try:\n                        authorization = base64.decodestring(authorization[1])\n                    except binascii.Error:\n                        pass\n                    else:\n                        authorization = authorization.split(\':\')\n                        if len(authorization) == 2:\n                            env[\'REMOTE_USER\'] = authorization[0]\n        # XXX REMOTE_IDENT\n        if self.headers.typeheader is None:\n            env[\'CONTENT_TYPE\'] = self.headers.type\n        else:\n            env[\'CONTENT_TYPE\'] = self.headers.typeheader\n        length = self.headers.getheader(\'content-length\')\n        if length:\n            env[\'CONTENT_LENGTH\'] = length\n        referer = self.headers.getheader(\'referer\')\n        if referer:\n            env[\'HTTP_REFERER\'] = referer\n        accept = []\n        for line in self.headers.getallmatchingheaders(\'accept\'):\n            if line[:1] in "\\t\\n\\r ":\n                accept.append(line.strip())\n            else:\n                accept = accept + line[7:].split(\',\')\n        env[\'HTTP_ACCEPT\'] = \',\'.join(accept)\n        ua = self.headers.getheader(\'user-agent\')\n        if ua:\n            env[\'HTTP_USER_AGENT\'] = ua\n        co = filter(None, self.headers.getheaders(\'cookie\'))\n        if co:\n            env[\'HTTP_COOKIE\'] = \', \'.join(co)\n        # XXX Other HTTP_* headers\n        # Since we\'re setting the env in the parent, provide empty\n        # values to override previously set values\n        for k in (\'QUERY_STRING\', \'REMOTE_HOST\', \'CONTENT_LENGTH\',\n                  \'HTTP_USER_AGENT\', \'HTTP_COOKIE\', \'HTTP_REFERER\'):\n            env.setdefault(k, "")\n\n        self.send_response(200, "Script output follows")\n\n        decoded_query = query.replace(\'+\', \' \')\n\n        if self.have_fork:\n            # Unix -- fork as we should\n            args = [script]\n            if \'=\' not in decoded_query:\n                args.append(decoded_query)\n            nobody = nobody_uid()\n            self.wfile.flush() # Always flush before forking\n            pid = os.fork()\n            if pid != 0:\n                # Parent\n                pid, sts = os.waitpid(pid, 0)\n                # throw away additional data [see bug #427345]\n                while select.select([self.rfile], [], [], 0)[0]:\n                    if not self.rfile.read(1):\n                        break\n                if sts:\n                    self.log_error("CGI script exit status %#x", sts)\n                return\n            # Child\n            try:\n                try:\n                    os.setuid(nobody)\n                except os.error:\n                    pass\n                os.dup2(self.rfile.fileno(), 0)\n                os.dup2(self.wfile.fileno(), 1)\n                os.execve(scriptfile, args, env)\n            except:\n                self.server.handle_error(self.request, self.client_address)\n                os._exit(127)\n\n        else:\n            # Non Unix - use subprocess\n            import subprocess\n            cmdline = [scriptfile]\n            if self.is_python(scriptfile):\n                interp = sys.executable\n                if interp.lower().endswith("w.exe"):\n                    # On Windows, use python.exe, not pythonw.exe\n                    interp = interp[:-5] + interp[-4:]\n                cmdline = [interp, \'-u\'] + cmdline\n            if \'=\' not in query:\n                cmdline.append(query)\n\n            self.log_message("command: %s", subprocess.list2cmdline(cmdline))\n            try:\n                nbytes = int(length)\n            except (TypeError, ValueError):\n                nbytes = 0\n            p = subprocess.Popen(cmdline,\n                                 stdin = subprocess.PIPE,\n                                 stdout = subprocess.PIPE,\n                                 stderr = subprocess.PIPE,\n                                 env = env\n                                )\n            if self.command.lower() == "post" and nbytes > 0:\n                data = self.rfile.read(nbytes)\n            else:\n                data = None\n            # throw away additional data [see bug #427345]\n            while select.select([self.rfile._sock], [], [], 0)[0]:\n                if not self.rfile._sock.recv(1):\n                    break\n            stdout, stderr = p.communicate(data)\n            self.wfile.write(stdout)\n            if stderr:\n                self.log_error(\'%s\', stderr)\n            p.stderr.close()\n            p.stdout.close()\n            status = p.returncode\n            if status:\n                self.log_error("CGI script exit status %#x", status)\n            else:\n                self.log_message("CGI script exited OK")\n\n\n# TODO(gregory.p.smith): Move this into an appropriate library.\ndef _url_collapse_path_split(path):\n    """\n    Given a URL path, remove extra \'/\'s and \'.\' path elements and collapse\n    any \'..\' references.\n\n    Implements something akin to RFC-2396 5.2 step 6 to parse relative paths.\n\n    Returns: A tuple of (head, tail) where tail is everything after the final /\n    and head is everything before it.  Head will always start with a \'/\' and,\n    if it contains anything else, never have a trailing \'/\'.\n\n    Raises: IndexError if too many \'..\' occur within the path.\n    """\n    # Similar to os.path.split(os.path.normpath(path)) but specific to URL\n    # path semantics rather than local operating system semantics.\n    path_parts = []\n    for part in path.split(\'/\'):\n        if part == \'.\':\n            path_parts.append(\'\')\n        else:\n            path_parts.append(part)\n    # Filter out blank non trailing parts before consuming the \'..\'.\n    path_parts = [part for part in path_parts[:-1] if part] + path_parts[-1:]\n    if path_parts:\n        tail_part = path_parts.pop()\n    else:\n        tail_part = \'\'\n    head_parts = []\n    for part in path_parts:\n        if part == \'..\':\n            head_parts.pop()\n        else:\n            head_parts.append(part)\n    if tail_part and tail_part == \'..\':\n        head_parts.pop()\n        tail_part = \'\'\n    return (\'/\' + \'/\'.join(head_parts), tail_part)\n\n\nnobody = None\n\ndef nobody_uid():\n    """Internal routine to get nobody\'s uid"""\n    global nobody\n    if nobody:\n        return nobody\n    try:\n        import pwd\n    except ImportError:\n        return -1\n    try:\n        nobody = pwd.getpwnam(\'nobody\')[2]\n    except KeyError:\n        nobody = 1 + max(map(lambda x: x[2], pwd.getpwall()))\n    return nobody\n\n\ndef executable(path):\n    """Test for executable file."""\n    try:\n        st = os.stat(path)\n    except os.error:\n        return False\n    return st.st_mode & 0111 != 0\n\n\ndef test(HandlerClass = CGIHTTPRequestHandler,\n         ServerClass = BaseHTTPServer.HTTPServer):\n    SimpleHTTPServer.test(HandlerClass, ServerClass)\n\n\nif __name__ == \'__main__\':\n    test()\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'CGIHTTPServer.py', 13, '2012-07-06 13:59:37'),
	('14e984c7630b44f691221f2af52794e5', 'bc99a9d78b5647d5aa5ab5f73e55ca9e', 'python cgi module 2', 'jamiesun', 'jamiesun.net@gmail.com', 'cgi,python', '#! /usr/local/bin/python\n\n# NOTE: the above "/usr/local/bin/python" is NOT a mistake.  It is\n# intentionally NOT "/usr/bin/env python".  On many systems\n# (e.g. Solaris), /usr/local/bin is not in $PATH as passed to CGI\n# scripts, and /usr/local/bin is the default directory where Python is\n# installed, so /usr/bin/env would be unable to find python.  Granted,\n# binary installations by Linux vendors often install Python in\n# /usr/bin.  So let those vendors patch cgi.py to match their choice\n# of installation.\n\n"""Support module for CGI (Common Gateway Interface) scripts.\n\nThis module defines a number of utilities for use by CGI scripts\nwritten in Python.\n"""\n"""\n@description:python cgi module 2\n@tags:cgi\n"""\n# XXX Perhaps there should be a slimmed version that doesn\'t contain\n# all those backwards compatible and debugging classes and functions?\n\n# History\n# -------\n#\n# Michael McLay started this module.  Steve Majewski changed the\n# interface to SvFormContentDict and FormContentDict.  The multipart\n# parsing was inspired by code submitted by Andreas Paepcke.  Guido van\n# Rossum rewrote, reformatted and documented the module and is currently\n# responsible for its maintenance.\n#\n\n__version__ = "2.6"\n\n\n# Imports\n# =======\n\nfrom operator import attrgetter\nimport sys\nimport os\nimport urllib\nimport UserDict\nimport urlparse\n\nfrom warnings import filterwarnings, catch_warnings, warn\nwith catch_warnings():\n    if sys.py3kwarning:\n        filterwarnings("ignore", ".*mimetools has been removed",\n                       DeprecationWarning)\n        filterwarnings("ignore", ".*rfc822 has been removed",\n                       DeprecationWarning)\n    import mimetools\n    import rfc822\n\ntry:\n    from cStringIO import StringIO\nexcept ImportError:\n    from StringIO import StringIO\n\n__all__ = ["MiniFieldStorage", "FieldStorage", "FormContentDict",\n           "SvFormContentDict", "InterpFormContentDict", "FormContent",\n           "parse", "parse_qs", "parse_qsl", "parse_multipart",\n           "parse_header", "print_exception", "print_environ",\n           "print_form", "print_directory", "print_arguments",\n           "print_environ_usage", "escape"]\n\n# Logging support\n# ===============\n\nlogfile = ""            # Filename to log to, if not empty\nlogfp = None            # File object to log to, if not None\n\ndef initlog(*allargs):\n    """Write a log message, if there is a log file.\n\n    Even though this function is called initlog(), you should always\n    use log(); log is a variable that is set either to initlog\n    (initially), to dolog (once the log file has been opened), or to\n    nolog (when logging is disabled).\n\n    The first argument is a format string; the remaining arguments (if\n    any) are arguments to the % operator, so e.g.\n        log("%s: %s", "a", "b")\n    will write "a: b" to the log file, followed by a newline.\n\n    If the global logfp is not None, it should be a file object to\n    which log data is written.\n\n    If the global logfp is None, the global logfile may be a string\n    giving a filename to open, in append mode.  This file should be\n    world writable!!!  If the file can\'t be opened, logging is\n    silently disabled (since there is no safe place where we could\n    send an error message).\n\n    """\n    global logfp, log\n    if logfile and not logfp:\n        try:\n            logfp = open(logfile, "a")\n        except IOError:\n            pass\n    if not logfp:\n        log = nolog\n    else:\n        log = dolog\n    log(*allargs)\n\ndef dolog(fmt, *args):\n    """Write a log message to the log file.  See initlog() for docs."""\n    logfp.write(fmt%args + "\\n")\n\ndef nolog(*allargs):\n    """Dummy function, assigned to log when logging is disabled."""\n    pass\n\nlog = initlog           # The current logging function\n\n\n# Parsing functions\n# =================\n\n# Maximum input we will accept when REQUEST_METHOD is POST\n# 0 ==> unlimited input\nmaxlen = 0\n\ndef parse(fp=None, environ=os.environ, keep_blank_values=0, strict_parsing=0):\n    """Parse a query in the environment or from a file (default stdin)\n\n        Arguments, all optional:\n\n        fp              : file pointer; default: sys.stdin\n\n        environ         : environment dictionary; default: os.environ\n\n        keep_blank_values: flag indicating whether blank values in\n            percent-encoded forms should be treated as blank strings.\n            A true value indicates that blanks should be retained as\n            blank strings.  The default false value indicates that\n            blank values are to be ignored and treated as if they were\n            not included.\n\n        strict_parsing: flag indicating what to do with parsing errors.\n            If false (the default), errors are silently ignored.\n            If true, errors raise a ValueError exception.\n    """\n    if fp is None:\n        fp = sys.stdin\n    if not \'REQUEST_METHOD\' in environ:\n        environ[\'REQUEST_METHOD\'] = \'GET\'       # For testing stand-alone\n    if environ[\'REQUEST_METHOD\'] == \'POST\':\n        ctype, pdict = parse_header(environ[\'CONTENT_TYPE\'])\n        if ctype == \'multipart/form-data\':\n            return parse_multipart(fp, pdict)\n        elif ctype == \'application/x-www-form-urlencoded\':\n            clength = int(environ[\'CONTENT_LENGTH\'])\n            if maxlen and clength > maxlen:\n                raise ValueError, \'Maximum content length exceeded\'\n            qs = fp.read(clength)\n        else:\n            qs = \'\'                     # Unknown content-type\n        if \'QUERY_STRING\' in environ:\n            if qs: qs = qs + \'&\'\n            qs = qs + environ[\'QUERY_STRING\']\n        elif sys.argv[1:]:\n            if qs: qs = qs + \'&\'\n            qs = qs + sys.argv[1]\n        environ[\'QUERY_STRING\'] = qs    # XXX Shouldn\'t, really\n    elif \'QUERY_STRING\' in environ:\n        qs = environ[\'QUERY_STRING\']\n    else:\n        if sys.argv[1:]:\n            qs = sys.argv[1]\n        else:\n            qs = ""\n        environ[\'QUERY_STRING\'] = qs    # XXX Shouldn\'t, really\n    return urlparse.parse_qs(qs, keep_blank_values, strict_parsing)\n\n\n# parse query string function called from urlparse,\n# this is done in order to maintain backward compatiblity.\n\ndef parse_qs(qs, keep_blank_values=0, strict_parsing=0):\n    """Parse a query given as a string argument."""\n    warn("cgi.parse_qs is deprecated, use urlparse.parse_qs instead",\n         PendingDeprecationWarning, 2)\n    return urlparse.parse_qs(qs, keep_blank_values, strict_parsing)\n\n\ndef parse_qsl(qs, keep_blank_values=0, strict_parsing=0):\n    """Parse a query given as a string argument."""\n    warn("cgi.parse_qsl is deprecated, use urlparse.parse_qsl instead",\n         PendingDeprecationWarning, 2)\n    return urlparse.parse_qsl(qs, keep_blank_values, strict_parsing)\n\ndef parse_multipart(fp, pdict):\n    """Parse multipart input.\n\n    Arguments:\n    fp   : input file\n    pdict: dictionary containing other parameters of content-type header\n\n    Returns a dictionary just like parse_qs(): keys are the field names, each\n    value is a list of values for that field.  This is easy to use but not\n    much good if you are expecting megabytes to be uploaded -- in that case,\n    use the FieldStorage class instead which is much more flexible.  Note\n    that content-type is the raw, unparsed contents of the content-type\n    header.\n\n    XXX This does not parse nested multipart parts -- use FieldStorage for\n    that.\n\n    XXX This should really be subsumed by FieldStorage altogether -- no\n    point in having two implementations of the same parsing algorithm.\n    Also, FieldStorage protects itself better against certain DoS attacks\n    by limiting the size of the data read in one chunk.  The API here\n    does not support that kind of protection.  This also affects parse()\n    since it can call parse_multipart().\n\n    """\n    boundary = ""\n    if \'boundary\' in pdict:\n        boundary = pdict[\'boundary\']\n    if not valid_boundary(boundary):\n        raise ValueError,  (\'Invalid boundary in multipart form: %r\'\n                            % (boundary,))\n\n    nextpart = "--" + boundary\n    lastpart = "--" + boundary + "--"\n    partdict = {}\n    terminator = ""\n\n    while terminator != lastpart:\n        bytes = -1\n        data = None\n        if terminator:\n            # At start of next part.  Read headers first.\n            headers = mimetools.Message(fp)\n            clength = headers.getheader(\'content-length\')\n            if clength:\n                try:\n                    bytes = int(clength)\n                except ValueError:\n                    pass\n            if bytes > 0:\n                if maxlen and bytes > maxlen:\n                    raise ValueError, \'Maximum content length exceeded\'\n                data = fp.read(bytes)\n            else:\n                data = ""\n        # Read lines until end of part.\n        lines = []\n        while 1:\n            line = fp.readline()\n            if not line:\n                terminator = lastpart # End outer loop\n                break\n            if line[:2] == "--":\n                terminator = line.strip()\n                if terminator in (nextpart, lastpart):\n                    break\n            lines.append(line)\n        # Done with part.\n        if data is None:\n            continue\n        if bytes < 0:\n            if lines:\n                # Strip final line terminator\n                line = lines[-1]\n                if line[-2:] == "\\r\\n":\n                    line = line[:-2]\n                elif line[-1:] == "\\n":\n                    line = line[:-1]\n                lines[-1] = line\n                data = "".join(lines)\n        line = headers[\'content-disposition\']\n        if not line:\n            continue\n        key, params = parse_header(line)\n        if key != \'form-data\':\n            continue\n        if \'name\' in params:\n            name = params[\'name\']\n        else:\n            continue\n        if name in partdict:\n            partdict[name].append(data)\n        else:\n            partdict[name] = [data]\n\n    return partdict\n\n\ndef _parseparam(s):\n    while s[:1] == \';\':\n        s = s[1:]\n        end = s.find(\';\')\n        while end > 0 and (s.count(\'"\', 0, end) - s.count(\'\\\\"\', 0, end)) % 2:\n            end = s.find(\';\', end + 1)\n        if end < 0:\n            end = len(s)\n        f = s[:end]\n        yield f.strip()\n        s = s[end:]\n\ndef parse_header(line):\n    """Parse a Content-type like header.\n\n    Return the main content-type and a dictionary of options.\n\n    """\n    parts = _parseparam(\';\' + line)\n    key = parts.next()\n    pdict = {}\n    for p in parts:\n        i = p.find(\'=\')\n        if i >= 0:\n            name = p[:i].strip().lower()\n            value = p[i+1:].strip()\n            if len(value) >= 2 and value[0] == value[-1] == \'"\':\n                value = value[1:-1]\n                value = value.replace(\'\\\\\\\\\', \'\\\\\').replace(\'\\\\"\', \'"\')\n            pdict[name] = value\n    return key, pdict\n\n\n# Classes for field storage\n# =========================\n\nclass MiniFieldStorage:\n\n    """Like FieldStorage, for use when no file uploads are possible."""\n\n    # Dummy attributes\n    filename = None\n    list = None\n    type = None\n    file = None\n    type_options = {}\n    disposition = None\n    disposition_options = {}\n    headers = {}\n\n    def __init__(self, name, value):\n        """Constructor from field name and value."""\n        self.name = name\n        self.value = value\n        # self.file = StringIO(value)\n\n    def __repr__(self):\n        """Return printable representation."""\n        return "MiniFieldStorage(%r, %r)" % (self.name, self.value)\n\n\nclass FieldStorage:\n\n    """Store a sequence of fields, reading multipart/form-data.\n\n    This class provides naming, typing, files stored on disk, and\n    more.  At the top level, it is accessible like a dictionary, whose\n    keys are the field names.  (Note: None can occur as a field name.)\n    The items are either a Python list (if there\'s multiple values) or\n    another FieldStorage or MiniFieldStorage object.  If it\'s a single\n    object, it has the following attributes:\n\n    name: the field name, if specified; otherwise None\n\n    filename: the filename, if specified; otherwise None; this is the\n        client side filename, *not* the file name on which it is\n        stored (that\'s a temporary file you don\'t deal with)\n\n    value: the value as a *string*; for file uploads, this\n        transparently reads the file every time you request the value\n\n    file: the file(-like) object from which you can read the data;\n        None if the data is stored a simple string\n\n    type: the content-type, or None if not specified\n\n    type_options: dictionary of options specified on the content-type\n        line\n\n    disposition: content-disposition, or None if not specified\n\n    disposition_options: dictionary of corresponding options\n\n    headers: a dictionary(-like) object (sometimes rfc822.Message or a\n        subclass thereof) containing *all* headers\n\n    The class is subclassable, mostly for the purpose of overriding\n    the make_file() method, which is called internally to come up with\n    a file open for reading and writing.  This makes it possible to\n    override the default choice of storing all files in a temporary\n    directory and unlinking them as soon as they have been opened.\n\n    """\n\n    def __init__(self, fp=None, headers=None, outerboundary="",\n                 environ=os.environ, keep_blank_values=0, strict_parsing=0):\n        """Constructor.  Read multipart/* until last part.\n\n        Arguments, all optional:\n\n        fp              : file pointer; default: sys.stdin\n            (not used when the request method is GET)\n\n        headers         : header dictionary-like object; default:\n            taken from environ as per CGI spec\n\n        outerboundary   : terminating multipart boundary\n            (for internal use only)\n\n        environ         : environment dictionary; default: os.environ\n\n        keep_blank_values: flag indicating whether blank values in\n            percent-encoded forms should be treated as blank strings.\n            A true value indicates that blanks should be retained as\n            blank strings.  The default false value indicates that\n            blank values are to be ignored and treated as if they were\n            not included.\n\n        strict_parsing: flag indicating what to do with parsing errors.\n            If false (the default), errors are silently ignored.\n            If true, errors raise a ValueError exception.\n\n        """\n        method = \'GET\'\n        self.keep_blank_values = keep_blank_values\n        self.strict_parsing = strict_parsing\n        if \'REQUEST_METHOD\' in environ:\n            method = environ[\'REQUEST_METHOD\'].upper()\n        self.qs_on_post = None\n        if method == \'GET\' or method == \'HEAD\':\n            if \'QUERY_STRING\' in environ:\n                qs = environ[\'QUERY_STRING\']\n            elif sys.argv[1:]:\n                qs = sys.argv[1]\n            else:\n                qs = ""\n            fp = StringIO(qs)\n            if headers is None:\n                headers = {\'content-type\':\n                           "application/x-www-form-urlencoded"}\n        if headers is None:\n            headers = {}\n            if method == \'POST\':\n                # Set default content-type for POST to what\'s traditional\n                headers[\'content-type\'] = "application/x-www-form-urlencoded"\n            if \'CONTENT_TYPE\' in environ:\n                headers[\'content-type\'] = environ[\'CONTENT_TYPE\']\n            if \'QUERY_STRING\' in environ:\n                self.qs_on_post = environ[\'QUERY_STRING\']\n            if \'CONTENT_LENGTH\' in environ:\n                headers[\'content-length\'] = environ[\'CONTENT_LENGTH\']\n        self.fp = fp or sys.stdin\n        self.headers = headers\n        self.outerboundary = outerboundary\n\n        # Process content-disposition header\n        cdisp, pdict = "", {}\n        if \'content-disposition\' in self.headers:\n            cdisp, pdict = parse_header(self.headers[\'content-disposition\'])\n        self.disposition = cdisp\n        self.disposition_options = pdict\n        self.name = None\n        if \'name\' in pdict:\n            self.name = pdict[\'name\']\n        self.filename = None\n        if \'filename\' in pdict:\n            self.filename = pdict[\'filename\']\n\n        # Process content-type header\n        #\n        # Honor any existing content-type header.  But if there is no\n        # content-type header, use some sensible defaults.  Assume\n        # outerboundary is "" at the outer level, but something non-false\n        # inside a multi-part.  The default for an inner part is text/plain,\n        # but for an outer part it should be urlencoded.  This should catch\n        # bogus clients which erroneously forget to include a content-type\n        # header.\n        #\n        # See below for what we do if there does exist a content-type header,\n        # but it happens to be something we don\'t understand.\n        if \'content-type\' in self.headers:\n            ctype, pdict = parse_header(self.headers[\'content-type\'])\n        elif self.outerboundary or method != \'POST\':\n            ctype, pdict = "text/plain", {}\n        else:\n            ctype, pdict = \'application/x-www-form-urlencoded\', {}\n        self.type = ctype\n        self.type_options = pdict\n        self.innerboundary = ""\n        if \'boundary\' in pdict:\n            self.innerboundary = pdict[\'boundary\']\n        clen = -1\n        if \'content-length\' in self.headers:\n            try:\n                clen = int(self.headers[\'content-length\'])\n            except ValueError:\n                pass\n            if maxlen and clen > maxlen:\n                raise ValueError, \'Maximum content length exceeded\'\n        self.length = clen\n\n        self.list = self.file = None\n        self.done = 0\n        if ctype == \'application/x-www-form-urlencoded\':\n            self.read_urlencoded()\n        elif ctype[:10] == \'multipart/\':\n            self.read_multi(environ, keep_blank_values, strict_parsing)\n        else:\n            self.read_single()\n\n    def __repr__(self):\n        """Return a printable representation."""\n        return "FieldStorage(%r, %r, %r)" % (\n                self.name, self.filename, self.value)\n\n    def __iter__(self):\n        return iter(self.keys())\n\n    def __getattr__(self, name):\n        if name != \'value\':\n            raise AttributeError, name\n        if self.file:\n            self.file.seek(0)\n            value = self.file.read()\n            self.file.seek(0)\n        elif self.list is not None:\n            value = self.list\n        else:\n            value = None\n        return value\n\n    def __getitem__(self, key):\n        """Dictionary style indexing."""\n        if self.list is None:\n            raise TypeError, "not indexable"\n        found = []\n        for item in self.list:\n            if item.name == key: found.append(item)\n        if not found:\n            raise KeyError, key\n        if len(found) == 1:\n            return found[0]\n        else:\n            return found\n\n    def getvalue(self, key, default=None):\n        """Dictionary style get() method, including \'value\' lookup."""\n        if key in self:\n            value = self[key]\n            if type(value) is type([]):\n                return map(attrgetter(\'value\'), value)\n            else:\n                return value.value\n        else:\n            return default\n\n    def getfirst(self, key, default=None):\n        """ Return the first value received."""\n        if key in self:\n            value = self[key]\n            if type(value) is type([]):\n                return value[0].value\n            else:\n                return value.value\n        else:\n            return default\n\n    def getlist(self, key):\n        """ Return list of received values."""\n        if key in self:\n            value = self[key]\n            if type(value) is type([]):\n                return map(attrgetter(\'value\'), value)\n            else:\n                return [value.value]\n        else:\n            return []\n\n    def keys(self):\n        """Dictionary style keys() method."""\n        if self.list is None:\n            raise TypeError, "not indexable"\n        return list(set(item.name for item in self.list))\n\n    def has_key(self, key):\n        """Dictionary style has_key() method."""\n        if self.list is None:\n            raise TypeError, "not indexable"\n        return any(item.name == key for item in self.list)\n\n    def __contains__(self, key):\n        """Dictionary style __contains__ method."""\n        if self.list is None:\n            raise TypeError, "not indexable"\n        return any(item.name == key for item in self.list)\n\n    def __len__(self):\n        """Dictionary style len(x) support."""\n        return len(self.keys())\n\n    def __nonzero__(self):\n        return bool(self.list)\n\n    def read_urlencoded(self):\n        """Internal: read data in query string format."""\n        qs = self.fp.read(self.length)\n        if self.qs_on_post:\n            qs += \'&\' + self.qs_on_post\n        self.list = list = []\n        for key, value in urlparse.parse_qsl(qs, self.keep_blank_values,\n                                            self.strict_parsing):\n            list.append(MiniFieldStorage(key, value))\n        self.skip_lines()\n\n    FieldStorageClass = None\n\n    def read_multi(self, environ, keep_blank_values, strict_parsing):\n        """Internal: read a part that is itself multipart."""\n        ib = self.innerboundary\n        if not valid_boundary(ib):\n            raise ValueError, \'Invalid boundary in multipart form: %r\' % (ib,)\n        self.list = []\n        if self.qs_on_post:\n            for key, value in urlparse.parse_qsl(self.qs_on_post,\n                                self.keep_blank_values, self.strict_parsing):\n                self.list.append(MiniFieldStorage(key, value))\n            FieldStorageClass = None\n\n        klass = self.FieldStorageClass or self.__class__\n        part = klass(self.fp, {}, ib,\n                     environ, keep_blank_values, strict_parsing)\n        # Throw first part away\n        while not part.done:\n            headers = rfc822.Message(self.fp)\n            part = klass(self.fp, headers, ib,\n                         environ, keep_blank_values, strict_parsing)\n            self.list.append(part)\n        self.skip_lines()\n\n    def read_single(self):\n        """Internal: read an atomic part."""\n        if self.length >= 0:\n            self.read_binary()\n            self.skip_lines()\n        else:\n            self.read_lines()\n        self.file.seek(0)\n\n    bufsize = 8*1024            # I/O buffering size for copy to file\n\n    def read_binary(self):\n        """Internal: read binary data."""\n        self.file = self.make_file(\'b\')\n        todo = self.length\n        if todo >= 0:\n            while todo > 0:\n                data = self.fp.read(min(todo, self.bufsize))\n                if not data:\n                    self.done = -1\n                    break\n                self.file.write(data)\n                todo = todo - len(data)\n\n    def read_lines(self):\n        """Internal: read lines until EOF or outerboundary."""\n        self.file = self.__file = StringIO()\n        if self.outerboundary:\n            self.read_lines_to_outerboundary()\n        else:\n            self.read_lines_to_eof()\n\n    def __write(self, line):\n        if self.__file is not None:\n            if self.__file.tell() + len(line) > 1000:\n                self.file = self.make_file(\'\')\n                self.file.write(self.__file.getvalue())\n                self.__file = None\n        self.file.write(line)\n\n    def read_lines_to_eof(self):\n        """Internal: read lines until EOF."""\n        while 1:\n            line = self.fp.readline(1<<16)\n            if not line:\n                self.done = -1\n                break\n            self.__write(line)\n\n    def read_lines_to_outerboundary(self):\n        """Internal: read lines until outerboundary."""\n        next = "--" + self.outerboundary\n        last = next + "--"\n        delim = ""\n        last_line_lfend = True\n        while 1:\n            line = self.fp.readline(1<<16)\n            if not line:\n                self.done = -1\n                break\n            if line[:2] == "--" and last_line_lfend:\n                strippedline = line.strip()\n                if strippedline == next:\n                    break\n                if strippedline == last:\n                    self.done = 1\n                    break\n            odelim = delim\n            if line[-2:] == "\\r\\n":\n                delim = "\\r\\n"\n                line = line[:-2]\n                last_line_lfend = True\n            elif line[-1] == "\\n":\n                delim = "\\n"\n                line = line[:-1]\n                last_line_lfend = True\n            else:\n                delim = ""\n                last_line_lfend = False\n            self.__write(odelim + line)\n\n    def skip_lines(self):\n        """Internal: skip lines until outer boundary if defined."""\n        if not self.outerboundary or self.done:\n            return\n        next = "--" + self.outerboundary\n        last = next + "--"\n        last_line_lfend = True\n        while 1:\n            line = self.fp.readline(1<<16)\n            if not line:\n                self.done = -1\n                break\n            if line[:2] == "--" and last_line_lfend:\n                strippedline = line.strip()\n                if strippedline == next:\n                    break\n                if strippedline == last:\n                    self.done = 1\n                    break\n            last_line_lfend = line.endswith(\'\\n\')\n\n    def make_file(self, binary=None):\n        """Overridable: return a readable & writable file.\n\n        The file will be used as follows:\n        - data is written to it\n        - seek(0)\n        - data is read from it\n\n        The \'binary\' argument is unused -- the file is always opened\n        in binary mode.\n\n        This version opens a temporary file for reading and writing,\n        and immediately deletes (unlinks) it.  The trick (on Unix!) is\n        that the file can still be used, but it can\'t be opened by\n        another process, and it will automatically be deleted when it\n        is closed or when the current process terminates.\n\n        If you want a more permanent file, you derive a class which\n        overrides this method.  If you want a visible temporary file\n        that is nevertheless automatically deleted when the script\n        terminates, try defining a __del__ method in a derived class\n        which unlinks the temporary files you have created.\n\n        """\n        import tempfile\n        return tempfile.TemporaryFile("w+b")\n\n\n\n# Backwards Compatibility Classes\n# ===============================\n\nclass FormContentDict(UserDict.UserDict):\n    """Form content as dictionary with a list of values per field.\n\n    form = FormContentDict()\n\n    form[key] -> [value, value, ...]\n    key in form -> Boolean\n    form.keys() -> [key, key, ...]\n    form.values() -> [[val, val, ...], [val, val, ...], ...]\n    form.items() ->  [(key, [val, val, ...]), (key, [val, val, ...]), ...]\n    form.dict == {key: [val, val, ...], ...}\n\n    """\n    def __init__(self, environ=os.environ, keep_blank_values=0, strict_parsing=0):\n        self.dict = self.data = parse(environ=environ,\n                                      keep_blank_values=keep_blank_values,\n                                      strict_parsing=strict_parsing)\n        self.query_string = environ[\'QUERY_STRING\']\n\n\nclass SvFormContentDict(FormContentDict):\n    """Form content as dictionary expecting a single value per field.\n\n    If you only expect a single value for each field, then form[key]\n    will return that single value.  It will raise an IndexError if\n    that expectation is not true.  If you expect a field to have\n    possible multiple values, than you can use form.getlist(key) to\n    get all of the values.  values() and items() are a compromise:\n    they return single strings where there is a single value, and\n    lists of strings otherwise.\n\n    """\n    def __getitem__(self, key):\n        if len(self.dict[key]) > 1:\n            raise IndexError, \'expecting a single value\'\n        return self.dict[key][0]\n    def getlist(self, key):\n        return self.dict[key]\n    def values(self):\n        result = []\n        for value in self.dict.values():\n            if len(value) == 1:\n                result.append(value[0])\n            else: result.append(value)\n        return result\n    def items(self):\n        result = []\n        for key, value in self.dict.items():\n            if len(value) == 1:\n                result.append((key, value[0]))\n            else: result.append((key, value))\n        return result\n\n\nclass InterpFormContentDict(SvFormContentDict):\n    """This class is present for backwards compatibility only."""\n    def __getitem__(self, key):\n        v = SvFormContentDict.__getitem__(self, key)\n        if v[0] in \'0123456789+-.\':\n            try: return int(v)\n            except ValueError:\n                try: return float(v)\n                except ValueError: pass\n        return v.strip()\n    def values(self):\n        result = []\n        for key in self.keys():\n            try:\n                result.append(self[key])\n            except IndexError:\n                result.append(self.dict[key])\n        return result\n    def items(self):\n        result = []\n        for key in self.keys():\n            try:\n                result.append((key, self[key]))\n            except IndexError:\n                result.append((key, self.dict[key]))\n        return result\n\n\nclass FormContent(FormContentDict):\n    """This class is present for backwards compatibility only."""\n    def values(self, key):\n        if key in self.dict :return self.dict[key]\n        else: return None\n    def indexed_value(self, key, location):\n        if key in self.dict:\n            if len(self.dict[key]) > location:\n                return self.dict[key][location]\n            else: return None\n        else: return None\n    def value(self, key):\n        if key in self.dict: return self.dict[key][0]\n        else: return None\n    def length(self, key):\n        return len(self.dict[key])\n    def stripped(self, key):\n        if key in self.dict: return self.dict[key][0].strip()\n        else: return None\n    def pars(self):\n        return self.dict\n\n\n# Test/debug code\n# ===============\n\ndef test(environ=os.environ):\n    """Robust test CGI script, usable as main program.\n\n    Write minimal HTTP headers and dump all information provided to\n    the script in HTML form.\n\n    """\n    print "Content-type: text/html"\n    print\n    sys.stderr = sys.stdout\n    try:\n        form = FieldStorage()   # Replace with other classes to test those\n        print_directory()\n        print_arguments()\n        print_form(form)\n        print_environ(environ)\n        print_environ_usage()\n        def f():\n            exec "testing print_exception() -- <I>italics?</I>"\n        def g(f=f):\n            f()\n        print "<H3>What follows is a test, not an actual exception:</H3>"\n        g()\n    except:\n        print_exception()\n\n    print "<H1>Second try with a small maxlen...</H1>"\n\n    global maxlen\n    maxlen = 50\n    try:\n        form = FieldStorage()   # Replace with other classes to test those\n        print_directory()\n        print_arguments()\n        print_form(form)\n        print_environ(environ)\n    except:\n        print_exception()\n\ndef print_exception(type=None, value=None, tb=None, limit=None):\n    if type is None:\n        type, value, tb = sys.exc_info()\n    import traceback\n    print\n    print "<H3>Traceback (most recent call last):</H3>"\n    list = traceback.format_tb(tb, limit) + \\\n           traceback.format_exception_only(type, value)\n    print "<PRE>%s<B>%s</B></PRE>" % (\n        escape("".join(list[:-1])),\n        escape(list[-1]),\n        )\n    del tb\n\ndef print_environ(environ=os.environ):\n    """Dump the shell environment as HTML."""\n    keys = environ.keys()\n    keys.sort()\n    print\n    print "<H3>Shell Environment:</H3>"\n    print "<DL>"\n    for key in keys:\n        print "<DT>", escape(key), "<DD>", escape(environ[key])\n    print "</DL>"\n    print\n\ndef print_form(form):\n    """Dump the contents of a form as HTML."""\n    keys = form.keys()\n    keys.sort()\n    print\n    print "<H3>Form Contents:</H3>"\n    if not keys:\n        print "<P>No form fields."\n    print "<DL>"\n    for key in keys:\n        print "<DT>" + escape(key) + ":",\n        value = form[key]\n        print "<i>" + escape(repr(type(value))) + "</i>"\n        print "<DD>" + escape(repr(value))\n    print "</DL>"\n    print\n\ndef print_directory():\n    """Dump the current directory as HTML."""\n    print\n    print "<H3>Current Working Directory:</H3>"\n    try:\n        pwd = os.getcwd()\n    except os.error, msg:\n        print "os.error:", escape(str(msg))\n    else:\n        print escape(pwd)\n    print\n\ndef print_arguments():\n    print\n    print "<H3>Command Line Arguments:</H3>"\n    print\n    print sys.argv\n    print\n\ndef print_environ_usage():\n    """Dump a list of environment variables used by CGI as HTML."""\n    print """\n<H3>These environment variables could have been set:</H3>\n<UL>\n<LI>AUTH_TYPE\n<LI>CONTENT_LENGTH\n<LI>CONTENT_TYPE\n<LI>DATE_GMT\n<LI>DATE_LOCAL\n<LI>DOCUMENT_NAME\n<LI>DOCUMENT_ROOT\n<LI>DOCUMENT_URI\n<LI>GATEWAY_INTERFACE\n<LI>LAST_MODIFIED\n<LI>PATH\n<LI>PATH_INFO\n<LI>PATH_TRANSLATED\n<LI>QUERY_STRING\n<LI>REMOTE_ADDR\n<LI>REMOTE_HOST\n<LI>REMOTE_IDENT\n<LI>REMOTE_USER\n<LI>REQUEST_METHOD\n<LI>SCRIPT_NAME\n<LI>SERVER_NAME\n<LI>SERVER_PORT\n<LI>SERVER_PROTOCOL\n<LI>SERVER_ROOT\n<LI>SERVER_SOFTWARE\n</UL>\nIn addition, HTTP headers sent by the server may be passed in the\nenvironment as well.  Here are some common variable names:\n<UL>\n<LI>HTTP_ACCEPT\n<LI>HTTP_CONNECTION\n<LI>HTTP_HOST\n<LI>HTTP_PRAGMA\n<LI>HTTP_REFERER\n<LI>HTTP_USER_AGENT\n</UL>\n"""\n\n\n# Utilities\n# =========\n\ndef escape(s, quote=None):\n    \'\'\'Replace special characters "&", "<" and ">" to HTML-safe sequences.\n    If the optional flag quote is true, the quotation mark character (")\n    is also translated.\'\'\'\n    s = s.replace("&", "&amp;") # Must be done first!\n    s = s.replace("<", "&lt;")\n    s = s.replace(">", "&gt;")\n    if quote:\n        s = s.replace(\'"\', "&quot;")\n    return s\n\ndef valid_boundary(s, _vb_pattern="^[ -~]{0,200}[!-~]$"):\n    import re\n    return re.match(_vb_pattern, s)\n\n# Invoke mainline\n# ===============\n\n# Call test() when this file is run as a script (not imported as a module)\nif __name__ == \'__main__\':\n    test()\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'bc99a9d78b5647d5aa5ab5f73e55ca9e.py', 35, '2012-07-06 15:18:08'),
	('21dd073b9ee54b77b368b5cb7486bcb5', NULL, ' python base64', 'jamiesun', 'jamiesun.net@gmail.com', 'other', '#! /usr/bin/env python\n#@description: python base64\n#@tags:python,base64\n"""RFC 3548: Base16, Base32, Base64 Data Encodings"""\n\n# Modified 04-Oct-1995 by Jack Jansen to use binascii module\n# Modified 30-Dec-2003 by Barry Warsaw to add full RFC 3548 support\n\nimport re\nimport struct\nimport binascii\n\n\n__all__ = [\n    # Legacy interface exports traditional RFC 1521 Base64 encodings\n    \'encode\', \'decode\', \'encodestring\', \'decodestring\',\n    # Generalized interface for other encodings\n    \'b64encode\', \'b64decode\', \'b32encode\', \'b32decode\',\n    \'b16encode\', \'b16decode\',\n    # Standard Base64 encoding\n    \'standard_b64encode\', \'standard_b64decode\',\n    # Some common Base64 alternatives.  As referenced by RFC 3458, see thread\n    # starting at:\n    #\n    # http://zgp.org/pipermail/p2p-hackers/2001-September/000316.html\n    \'urlsafe_b64encode\', \'urlsafe_b64decode\',\n    ]\n\n_translation = [chr(_x) for _x in range(256)]\nEMPTYSTRING = \'\'\n\n\ndef _translate(s, altchars):\n    translation = _translation[:]\n    for k, v in altchars.items():\n        translation[ord(k)] = v\n    return s.translate(\'\'.join(translation))\n\n\n\n# Base64 encoding/decoding uses binascii\n\ndef b64encode(s, altchars=None):\n    """Encode a string using Base64.\n\n    s is the string to encode.  Optional altchars must be a string of at least\n    length 2 (additional characters are ignored) which specifies an\n    alternative alphabet for the \'+\' and \'/\' characters.  This allows an\n    application to e.g. generate url or filesystem safe Base64 strings.\n\n    The encoded string is returned.\n    """\n    # Strip off the trailing newline\n    encoded = binascii.b2a_base64(s)[:-1]\n    if altchars is not None:\n        return _translate(encoded, {\'+\': altchars[0], \'/\': altchars[1]})\n    return encoded\n\n\ndef b64decode(s, altchars=None):\n    """Decode a Base64 encoded string.\n\n    s is the string to decode.  Optional altchars must be a string of at least\n    length 2 (additional characters are ignored) which specifies the\n    alternative alphabet used instead of the \'+\' and \'/\' characters.\n\n    The decoded string is returned.  A TypeError is raised if s were\n    incorrectly padded or if there are non-alphabet characters present in the\n    string.\n    """\n    if altchars is not None:\n        s = _translate(s, {altchars[0]: \'+\', altchars[1]: \'/\'})\n    try:\n        return binascii.a2b_base64(s)\n    except binascii.Error, msg:\n        # Transform this exception for consistency\n        raise TypeError(msg)\n\n\ndef standard_b64encode(s):\n    """Encode a string using the standard Base64 alphabet.\n\n    s is the string to encode.  The encoded string is returned.\n    """\n    return b64encode(s)\n\ndef standard_b64decode(s):\n    """Decode a string encoded with the standard Base64 alphabet.\n\n    s is the string to decode.  The decoded string is returned.  A TypeError\n    is raised if the string is incorrectly padded or if there are non-alphabet\n    characters present in the string.\n    """\n    return b64decode(s)\n\ndef urlsafe_b64encode(s):\n    """Encode a string using a url-safe Base64 alphabet.\n\n    s is the string to encode.  The encoded string is returned.  The alphabet\n    uses \'-\' instead of \'+\' and \'_\' instead of \'/\'.\n    """\n    return b64encode(s, \'-_\')\n\ndef urlsafe_b64decode(s):\n    """Decode a string encoded with the standard Base64 alphabet.\n\n    s is the string to decode.  The decoded string is returned.  A TypeError\n    is raised if the string is incorrectly padded or if there are non-alphabet\n    characters present in the string.\n\n    The alphabet uses \'-\' instead of \'+\' and \'_\' instead of \'/\'.\n    """\n    return b64decode(s, \'-_\')\n\n\n\n# Base32 encoding/decoding must be done in Python\n_b32alphabet = {\n    0: \'A\',  9: \'J\', 18: \'S\', 27: \'3\',\n    1: \'B\', 10: \'K\', 19: \'T\', 28: \'4\',\n    2: \'C\', 11: \'L\', 20: \'U\', 29: \'5\',\n    3: \'D\', 12: \'M\', 21: \'V\', 30: \'6\',\n    4: \'E\', 13: \'N\', 22: \'W\', 31: \'7\',\n    5: \'F\', 14: \'O\', 23: \'X\',\n    6: \'G\', 15: \'P\', 24: \'Y\',\n    7: \'H\', 16: \'Q\', 25: \'Z\',\n    8: \'I\', 17: \'R\', 26: \'2\',\n    }\n\n_b32tab = _b32alphabet.items()\n_b32tab.sort()\n_b32tab = [v for k, v in _b32tab]\n_b32rev = dict([(v, long(k)) for k, v in _b32alphabet.items()])\n\n\ndef b32encode(s):\n    """Encode a string using Base32.\n\n    s is the string to encode.  The encoded string is returned.\n    """\n    parts = []\n    quanta, leftover = divmod(len(s), 5)\n    # Pad the last quantum with zero bits if necessary\n    if leftover:\n        s += (\'\\0\' * (5 - leftover))\n        quanta += 1\n    for i in range(quanta):\n        # c1 and c2 are 16 bits wide, c3 is 8 bits wide.  The intent of this\n        # code is to process the 40 bits in units of 5 bits.  So we take the 1\n        # leftover bit of c1 and tack it onto c2.  Then we take the 2 leftover\n        # bits of c2 and tack them onto c3.  The shifts and masks are intended\n        # to give us values of exactly 5 bits in width.\n        c1, c2, c3 = struct.unpack(\'!HHB\', s[i*5:(i+1)*5])\n        c2 += (c1 & 1) << 16 # 17 bits wide\n        c3 += (c2 & 3) << 8  # 10 bits wide\n        parts.extend([_b32tab[c1 >> 11],         # bits 1 - 5\n                      _b32tab[(c1 >> 6) & 0x1f], # bits 6 - 10\n                      _b32tab[(c1 >> 1) & 0x1f], # bits 11 - 15\n                      _b32tab[c2 >> 12],         # bits 16 - 20 (1 - 5)\n                      _b32tab[(c2 >> 7) & 0x1f], # bits 21 - 25 (6 - 10)\n                      _b32tab[(c2 >> 2) & 0x1f], # bits 26 - 30 (11 - 15)\n                      _b32tab[c3 >> 5],          # bits 31 - 35 (1 - 5)\n                      _b32tab[c3 & 0x1f],        # bits 36 - 40 (1 - 5)\n                      ])\n    encoded = EMPTYSTRING.join(parts)\n    # Adjust for any leftover partial quanta\n    if leftover == 1:\n        return encoded[:-6] + \'======\'\n    elif leftover == 2:\n        return encoded[:-4] + \'====\'\n    elif leftover == 3:\n        return encoded[:-3] + \'===\'\n    elif leftover == 4:\n        return encoded[:-1] + \'=\'\n    return encoded\n\n\ndef b32decode(s, casefold=False, map01=None):\n    """Decode a Base32 encoded string.\n\n    s is the string to decode.  Optional casefold is a flag specifying whether\n    a lowercase alphabet is acceptable as input.  For security purposes, the\n    default is False.\n\n    RFC 3548 allows for optional mapping of the digit 0 (zero) to the letter O\n    (oh), and for optional mapping of the digit 1 (one) to either the letter I\n    (eye) or letter L (el).  The optional argument map01 when not None,\n    specifies which letter the digit 1 should be mapped to (when map01 is not\n    None, the digit 0 is always mapped to the letter O).  For security\n    purposes the default is None, so that 0 and 1 are not allowed in the\n    input.\n\n    The decoded string is returned.  A TypeError is raised if s were\n    incorrectly padded or if there are non-alphabet characters present in the\n    string.\n    """\n    quanta, leftover = divmod(len(s), 8)\n    if leftover:\n        raise TypeError(\'Incorrect padding\')\n    # Handle section 2.4 zero and one mapping.  The flag map01 will be either\n    # False, or the character to map the digit 1 (one) to.  It should be\n    # either L (el) or I (eye).\n    if map01:\n        s = _translate(s, {\'0\': \'O\', \'1\': map01})\n    if casefold:\n        s = s.upper()\n    # Strip off pad characters from the right.  We need to count the pad\n    # characters because this will tell us how many null bytes to remove from\n    # the end of the decoded string.\n    padchars = 0\n    mo = re.search(\'(?P<pad>[=]*)$\', s)\n    if mo:\n        padchars = len(mo.group(\'pad\'))\n        if padchars > 0:\n            s = s[:-padchars]\n    # Now decode the full quanta\n    parts = []\n    acc = 0\n    shift = 35\n    for c in s:\n        val = _b32rev.get(c)\n        if val is None:\n            raise TypeError(\'Non-base32 digit found\')\n        acc += _b32rev[c] << shift\n        shift -= 5\n        if shift < 0:\n            parts.append(binascii.unhexlify(\'%010x\' % acc))\n            acc = 0\n            shift = 35\n    # Process the last, partial quanta\n    last = binascii.unhexlify(\'%010x\' % acc)\n    if padchars == 0:\n        last = \'\'                       # No characters\n    elif padchars == 1:\n        last = last[:-1]\n    elif padchars == 3:\n        last = last[:-2]\n    elif padchars == 4:\n        last = last[:-3]\n    elif padchars == 6:\n        last = last[:-4]\n    else:\n        raise TypeError(\'Incorrect padding\')\n    parts.append(last)\n    return EMPTYSTRING.join(parts)\n\n\n\n# RFC 3548, Base 16 Alphabet specifies uppercase, but hexlify() returns\n# lowercase.  The RFC also recommends against accepting input case\n# insensitively.\ndef b16encode(s):\n    """Encode a string using Base16.\n\n    s is the string to encode.  The encoded string is returned.\n    """\n    return binascii.hexlify(s).upper()\n\n\ndef b16decode(s, casefold=False):\n    """Decode a Base16 encoded string.\n\n    s is the string to decode.  Optional casefold is a flag specifying whether\n    a lowercase alphabet is acceptable as input.  For security purposes, the\n    default is False.\n\n    The decoded string is returned.  A TypeError is raised if s were\n    incorrectly padded or if there are non-alphabet characters present in the\n    string.\n    """\n    if casefold:\n        s = s.upper()\n    if re.search(\'[^0-9A-F]\', s):\n        raise TypeError(\'Non-base16 digit found\')\n    return binascii.unhexlify(s)\n\n\n\n# Legacy interface.  This code could be cleaned up since I don\'t believe\n# binascii has any line length limitations.  It just doesn\'t seem worth it\n# though.\n\nMAXLINESIZE = 76 # Excluding the CRLF\nMAXBINSIZE = (MAXLINESIZE//4)*3\n\ndef encode(input, output):\n    """Encode a file."""\n    while True:\n        s = input.read(MAXBINSIZE)\n        if not s:\n            break\n        while len(s) < MAXBINSIZE:\n            ns = input.read(MAXBINSIZE-len(s))\n            if not ns:\n                break\n            s += ns\n        line = binascii.b2a_base64(s)\n        output.write(line)\n\n\ndef decode(input, output):\n    """Decode a file."""\n    while True:\n        line = input.readline()\n        if not line:\n            break\n        s = binascii.a2b_base64(line)\n        output.write(s)\n\n\ndef encodestring(s):\n    """Encode a string into multiple lines of base-64 data."""\n    pieces = []\n    for i in range(0, len(s), MAXBINSIZE):\n        chunk = s[i : i + MAXBINSIZE]\n        pieces.append(binascii.b2a_base64(chunk))\n    return "".join(pieces)\n\n\ndef decodestring(s):\n    """Decode a string."""\n    return binascii.a2b_base64(s)\n\n\n\n# Useable as a script...\ndef test():\n    """Small test program"""\n    import sys, getopt\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], \'deut\')\n    except getopt.error, msg:\n        sys.stdout = sys.stderr\n        print msg\n        print """usage: %s [-d|-e|-u|-t] [file|-]\n        -d, -u: decode\n        -e: encode (default)\n        -t: encode and decode string \'Aladdin:open sesame\'"""%sys.argv[0]\n        sys.exit(2)\n    func = encode\n    for o, a in opts:\n        if o == \'-e\': func = encode\n        if o == \'-d\': func = decode\n        if o == \'-u\': func = decode\n        if o == \'-t\': test1(); return\n    if args and args[0] != \'-\':\n        with open(args[0], \'rb\') as f:\n            func(f, sys.stdout)\n    else:\n        func(sys.stdin, sys.stdout)\n\n\ndef test1():\n    s0 = "Aladdin:open sesame"\n    s1 = encodestring(s0)\n    s2 = decodestring(s1)\n    print s0, repr(s1), s2\n\n\nif __name__ == \'__main__\':\n    test()\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'base64.py', 5, '2012-07-06 13:44:36'),
	('3df4c3a6d533463f905be57c63dab77a', NULL, 'python asyncore', 'jamiesun', 'jamiesun.net@gmail.com', 'python,network,python', '# -*- Mode: Python -*-\n#   Id: asyncore.py,v 2.51 2000/09/07 22:29:26 rushing Exp\n#   Author: Sam Rushing <rushing@nightmare.com>\n\n# ======================================================================\n# Copyright 1996 by Sam Rushing\n#\n#                         All Rights Reserved\n#\n# Permission to use, copy, modify, and distribute this software and\n# its documentation for any purpose and without fee is hereby\n# granted, provided that the above copyright notice appear in all\n# copies and that both that copyright notice and this permission\n# notice appear in supporting documentation, and that the name of Sam\n# Rushing not be used in advertising or publicity pertaining to\n# distribution of the software without specific, written prior\n# permission.\n#\n# SAM RUSHING DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE,\n# INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, IN\n# NO EVENT SHALL SAM RUSHING BE LIABLE FOR ANY SPECIAL, INDIRECT OR\n# CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS\n# OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,\n# NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN\n# CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n# ======================================================================\n"""\n@description:python asyncore\n@tags:python,network\n"""\n"""Basic infrastructure for asynchronous socket service clients and servers.\n\nThere are only two ways to have a program on a single processor do "more\nthan one thing at a time".  Multi-threaded programming is the simplest and\nmost popular way to do it, but there is another very different technique,\nthat lets you have nearly all the advantages of multi-threading, without\nactually using multiple threads. it\'s really only practical if your program\nis largely I/O bound. If your program is CPU bound, then pre-emptive\nscheduled threads are probably what you really need. Network servers are\nrarely CPU-bound, however.\n\nIf your operating system supports the select() system call in its I/O\nlibrary (and nearly all do), then you can use it to juggle multiple\ncommunication channels at once; doing other work while your I/O is taking\nplace in the "background."  Although this strategy can seem strange and\ncomplex, especially at first, it is in many ways easier to understand and\ncontrol than multi-threaded programming. The module documented here solves\nmany of the difficult problems for you, making the task of building\nsophisticated high-performance network servers and clients a snap.\n"""\n\nimport select\nimport socket\nimport sys\nimport time\nimport warnings\n\nimport os\nfrom errno import EALREADY, EINPROGRESS, EWOULDBLOCK, ECONNRESET, EINVAL, \\\n     ENOTCONN, ESHUTDOWN, EINTR, EISCONN, EBADF, ECONNABORTED, EPIPE, EAGAIN, \\\n     errorcode\n\n_DISCONNECTED = frozenset((ECONNRESET, ENOTCONN, ESHUTDOWN, ECONNABORTED, EPIPE,\n                           EBADF))\n\ntry:\n    socket_map\nexcept NameError:\n    socket_map = {}\n\ndef _strerror(err):\n    try:\n        return os.strerror(err)\n    except (ValueError, OverflowError, NameError):\n        if err in errorcode:\n            return errorcode[err]\n        return "Unknown error %s" %err\n\nclass ExitNow(Exception):\n    pass\n\n_reraised_exceptions = (ExitNow, KeyboardInterrupt, SystemExit)\n\ndef read(obj):\n    try:\n        obj.handle_read_event()\n    except _reraised_exceptions:\n        raise\n    except:\n        obj.handle_error()\n\ndef write(obj):\n    try:\n        obj.handle_write_event()\n    except _reraised_exceptions:\n        raise\n    except:\n        obj.handle_error()\n\ndef _exception(obj):\n    try:\n        obj.handle_expt_event()\n    except _reraised_exceptions:\n        raise\n    except:\n        obj.handle_error()\n\ndef readwrite(obj, flags):\n    try:\n        if flags & select.POLLIN:\n            obj.handle_read_event()\n        if flags & select.POLLOUT:\n            obj.handle_write_event()\n        if flags & select.POLLPRI:\n            obj.handle_expt_event()\n        if flags & (select.POLLHUP | select.POLLERR | select.POLLNVAL):\n            obj.handle_close()\n    except socket.error, e:\n        if e.args[0] not in _DISCONNECTED:\n            obj.handle_error()\n        else:\n            obj.handle_close()\n    except _reraised_exceptions:\n        raise\n    except:\n        obj.handle_error()\n\ndef poll(timeout=0.0, map=None):\n    if map is None:\n        map = socket_map\n    if map:\n        r = []; w = []; e = []\n        for fd, obj in map.items():\n            is_r = obj.readable()\n            is_w = obj.writable()\n            if is_r:\n                r.append(fd)\n            # accepting sockets should not be writable\n            if is_w and not obj.accepting:\n                w.append(fd)\n            if is_r or is_w:\n                e.append(fd)\n        if [] == r == w == e:\n            time.sleep(timeout)\n            return\n\n        try:\n            r, w, e = select.select(r, w, e, timeout)\n        except select.error, err:\n            if err.args[0] != EINTR:\n                raise\n            else:\n                return\n\n        for fd in r:\n            obj = map.get(fd)\n            if obj is None:\n                continue\n            read(obj)\n\n        for fd in w:\n            obj = map.get(fd)\n            if obj is None:\n                continue\n            write(obj)\n\n        for fd in e:\n            obj = map.get(fd)\n            if obj is None:\n                continue\n            _exception(obj)\n\ndef poll2(timeout=0.0, map=None):\n    # Use the poll() support added to the select module in Python 2.0\n    if map is None:\n        map = socket_map\n    if timeout is not None:\n        # timeout is in milliseconds\n        timeout = int(timeout*1000)\n    pollster = select.poll()\n    if map:\n        for fd, obj in map.items():\n            flags = 0\n            if obj.readable():\n                flags |= select.POLLIN | select.POLLPRI\n            # accepting sockets should not be writable\n            if obj.writable() and not obj.accepting:\n                flags |= select.POLLOUT\n            if flags:\n                # Only check for exceptions if object was either readable\n                # or writable.\n                flags |= select.POLLERR | select.POLLHUP | select.POLLNVAL\n                pollster.register(fd, flags)\n        try:\n            r = pollster.poll(timeout)\n        except select.error, err:\n            if err.args[0] != EINTR:\n                raise\n            r = []\n        for fd, flags in r:\n            obj = map.get(fd)\n            if obj is None:\n                continue\n            readwrite(obj, flags)\n\npoll3 = poll2                           # Alias for backward compatibility\n\ndef loop(timeout=30.0, use_poll=False, map=None, count=None):\n    if map is None:\n        map = socket_map\n\n    if use_poll and hasattr(select, \'poll\'):\n        poll_fun = poll2\n    else:\n        poll_fun = poll\n\n    if count is None:\n        while map:\n            poll_fun(timeout, map)\n\n    else:\n        while map and count > 0:\n            poll_fun(timeout, map)\n            count = count - 1\n\nclass dispatcher:\n\n    debug = False\n    connected = False\n    accepting = False\n    closing = False\n    addr = None\n    ignore_log_types = frozenset([\'warning\'])\n\n    def __init__(self, sock=None, map=None):\n        if map is None:\n            self._map = socket_map\n        else:\n            self._map = map\n\n        self._fileno = None\n\n        if sock:\n            # Set to nonblocking just to make sure for cases where we\n            # get a socket from a blocking source.\n            sock.setblocking(0)\n            self.set_socket(sock, map)\n            self.connected = True\n            # The constructor no longer requires that the socket\n            # passed be connected.\n            try:\n                self.addr = sock.getpeername()\n            except socket.error, err:\n                if err.args[0] == ENOTCONN:\n                    # To handle the case where we got an unconnected\n                    # socket.\n                    self.connected = False\n                else:\n                    # The socket is broken in some unknown way, alert\n                    # the user and remove it from the map (to prevent\n                    # polling of broken sockets).\n                    self.del_channel(map)\n                    raise\n        else:\n            self.socket = None\n\n    def __repr__(self):\n        status = [self.__class__.__module__+"."+self.__class__.__name__]\n        if self.accepting and self.addr:\n            status.append(\'listening\')\n        elif self.connected:\n            status.append(\'connected\')\n        if self.addr is not None:\n            try:\n                status.append(\'%s:%d\' % self.addr)\n            except TypeError:\n                status.append(repr(self.addr))\n        return \'<%s at %#x>\' % (\' \'.join(status), id(self))\n\n    __str__ = __repr__\n\n    def add_channel(self, map=None):\n        #self.log_info(\'adding channel %s\' % self)\n        if map is None:\n            map = self._map\n        map[self._fileno] = self\n\n    def del_channel(self, map=None):\n        fd = self._fileno\n        if map is None:\n            map = self._map\n        if fd in map:\n            #self.log_info(\'closing channel %d:%s\' % (fd, self))\n            del map[fd]\n        self._fileno = None\n\n    def create_socket(self, family, type):\n        self.family_and_type = family, type\n        sock = socket.socket(family, type)\n        sock.setblocking(0)\n        self.set_socket(sock)\n\n    def set_socket(self, sock, map=None):\n        self.socket = sock\n##        self.__dict__[\'socket\'] = sock\n        self._fileno = sock.fileno()\n        self.add_channel(map)\n\n    def set_reuse_addr(self):\n        # try to re-use a server port if possible\n        try:\n            self.socket.setsockopt(\n                socket.SOL_SOCKET, socket.SO_REUSEADDR,\n                self.socket.getsockopt(socket.SOL_SOCKET,\n                                       socket.SO_REUSEADDR) | 1\n                )\n        except socket.error:\n            pass\n\n    # ==================================================\n    # predicates for select()\n    # these are used as filters for the lists of sockets\n    # to pass to select().\n    # ==================================================\n\n    def readable(self):\n        return True\n\n    def writable(self):\n        return True\n\n    # ==================================================\n    # socket object methods.\n    # ==================================================\n\n    def listen(self, num):\n        self.accepting = True\n        if os.name == \'nt\' and num > 5:\n            num = 5\n        return self.socket.listen(num)\n\n    def bind(self, addr):\n        self.addr = addr\n        return self.socket.bind(addr)\n\n    def connect(self, address):\n        self.connected = False\n        err = self.socket.connect_ex(address)\n        if err in (EINPROGRESS, EALREADY, EWOULDBLOCK) \\\n        or err == EINVAL and os.name in (\'nt\', \'ce\'):\n            return\n        if err in (0, EISCONN):\n            self.addr = address\n            self.handle_connect_event()\n        else:\n            raise socket.error(err, errorcode[err])\n\n    def accept(self):\n        # XXX can return either an address pair or None\n        try:\n            conn, addr = self.socket.accept()\n        except TypeError:\n            return None\n        except socket.error as why:\n            if why.args[0] in (EWOULDBLOCK, ECONNABORTED, EAGAIN):\n                return None\n            else:\n                raise\n        else:\n            return conn, addr\n\n    def send(self, data):\n        try:\n            result = self.socket.send(data)\n            return result\n        except socket.error, why:\n            if why.args[0] == EWOULDBLOCK:\n                return 0\n            elif why.args[0] in _DISCONNECTED:\n                self.handle_close()\n                return 0\n            else:\n                raise\n\n    def recv(self, buffer_size):\n        try:\n            data = self.socket.recv(buffer_size)\n            if not data:\n                # a closed connection is indicated by signaling\n                # a read condition, and having recv() return 0.\n                self.handle_close()\n                return \'\'\n            else:\n                return data\n        except socket.error, why:\n            # winsock sometimes throws ENOTCONN\n            if why.args[0] in _DISCONNECTED:\n                self.handle_close()\n                return \'\'\n            else:\n                raise\n\n    def close(self):\n        self.connected = False\n        self.accepting = False\n        self.del_channel()\n        try:\n            self.socket.close()\n        except socket.error, why:\n            if why.args[0] not in (ENOTCONN, EBADF):\n                raise\n\n    # cheap inheritance, used to pass all other attribute\n    # references to the underlying socket object.\n    def __getattr__(self, attr):\n        try:\n            retattr = getattr(self.socket, attr)\n        except AttributeError:\n            raise AttributeError("%s instance has no attribute \'%s\'"\n                                 %(self.__class__.__name__, attr))\n        else:\n            msg = "%(me)s.%(attr)s is deprecated. Use %(me)s.socket.%(attr)s " \\\n                  "instead." % {\'me\': self.__class__.__name__, \'attr\':attr}\n            warnings.warn(msg, DeprecationWarning, stacklevel=2)\n            return retattr\n\n    # log and log_info may be overridden to provide more sophisticated\n    # logging and warning methods. In general, log is for \'hit\' logging\n    # and \'log_info\' is for informational, warning and error logging.\n\n    def log(self, message):\n        sys.stderr.write(\'log: %s\\n\' % str(message))\n\n    def log_info(self, message, type=\'info\'):\n        if type not in self.ignore_log_types:\n            print \'%s: %s\' % (type, message)\n\n    def handle_read_event(self):\n        if self.accepting:\n            # accepting sockets are never connected, they "spawn" new\n            # sockets that are connected\n            self.handle_accept()\n        elif not self.connected:\n            self.handle_connect_event()\n            self.handle_read()\n        else:\n            self.handle_read()\n\n    def handle_connect_event(self):\n        err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)\n        if err != 0:\n            raise socket.error(err, _strerror(err))\n        self.handle_connect()\n        self.connected = True\n\n    def handle_write_event(self):\n        if self.accepting:\n            # Accepting sockets shouldn\'t get a write event.\n            # We will pretend it didn\'t happen.\n            return\n\n        if not self.connected:\n            #check for errors\n            err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)\n            if err != 0:\n                raise socket.error(err, _strerror(err))\n\n            self.handle_connect_event()\n        self.handle_write()\n\n    def handle_expt_event(self):\n        # handle_expt_event() is called if there might be an error on the\n        # socket, or if there is OOB data\n        # check for the error condition first\n        err = self.socket.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)\n        if err != 0:\n            # we can get here when select.select() says that there is an\n            # exceptional condition on the socket\n            # since there is an error, we\'ll go ahead and close the socket\n            # like we would in a subclassed handle_read() that received no\n            # data\n            self.handle_close()\n        else:\n            self.handle_expt()\n\n    def handle_error(self):\n        nil, t, v, tbinfo = compact_traceback()\n\n        # sometimes a user repr method will crash.\n        try:\n            self_repr = repr(self)\n        except:\n            self_repr = \'<__repr__(self) failed for object at %0x>\' % id(self)\n\n        self.log_info(\n            \'uncaptured python exception, closing channel %s (%s:%s %s)\' % (\n                self_repr,\n                t,\n                v,\n                tbinfo\n                ),\n            \'error\'\n            )\n        self.handle_close()\n\n    def handle_expt(self):\n        self.log_info(\'unhandled incoming priority event\', \'warning\')\n\n    def handle_read(self):\n        self.log_info(\'unhandled read event\', \'warning\')\n\n    def handle_write(self):\n        self.log_info(\'unhandled write event\', \'warning\')\n\n    def handle_connect(self):\n        self.log_info(\'unhandled connect event\', \'warning\')\n\n    def handle_accept(self):\n        self.log_info(\'unhandled accept event\', \'warning\')\n\n    def handle_close(self):\n        self.log_info(\'unhandled close event\', \'warning\')\n        self.close()\n\n# ---------------------------------------------------------------------------\n# adds simple buffered output capability, useful for simple clients.\n# [for more sophisticated usage use asynchat.async_chat]\n# ---------------------------------------------------------------------------\n\nclass dispatcher_with_send(dispatcher):\n\n    def __init__(self, sock=None, map=None):\n        dispatcher.__init__(self, sock, map)\n        self.out_buffer = \'\'\n\n    def initiate_send(self):\n        num_sent = 0\n        num_sent = dispatcher.send(self, self.out_buffer[:512])\n        self.out_buffer = self.out_buffer[num_sent:]\n\n    def handle_write(self):\n        self.initiate_send()\n\n    def writable(self):\n        return (not self.connected) or len(self.out_buffer)\n\n    def send(self, data):\n        if self.debug:\n            self.log_info(\'sending %s\' % repr(data))\n        self.out_buffer = self.out_buffer + data\n        self.initiate_send()\n\n# ---------------------------------------------------------------------------\n# used for debugging.\n# ---------------------------------------------------------------------------\n\ndef compact_traceback():\n    t, v, tb = sys.exc_info()\n    tbinfo = []\n    if not tb: # Must have a traceback\n        raise AssertionError("traceback does not exist")\n    while tb:\n        tbinfo.append((\n            tb.tb_frame.f_code.co_filename,\n            tb.tb_frame.f_code.co_name,\n            str(tb.tb_lineno)\n            ))\n        tb = tb.tb_next\n\n    # just to be safe\n    del tb\n\n    file, function, line = tbinfo[-1]\n    info = \' \'.join([\'[%s|%s|%s]\' % x for x in tbinfo])\n    return (file, function, line), t, v, info\n\ndef close_all(map=None, ignore_all=False):\n    if map is None:\n        map = socket_map\n    for x in map.values():\n        try:\n            x.close()\n        except OSError, x:\n            if x.args[0] == EBADF:\n                pass\n            elif not ignore_all:\n                raise\n        except _reraised_exceptions:\n            raise\n        except:\n            if not ignore_all:\n                raise\n    map.clear()\n\n# Asynchronous File I/O:\n#\n# After a little research (reading man pages on various unixen, and\n# digging through the linux kernel), I\'ve determined that select()\n# isn\'t meant for doing asynchronous file i/o.\n# Heartening, though - reading linux/mm/filemap.c shows that linux\n# supports asynchronous read-ahead.  So _MOST_ of the time, the data\n# will be sitting in memory for us already when we go to read it.\n#\n# What other OS\'s (besides NT) support async file i/o?  [VMS?]\n#\n# Regardless, this is useful for pipes, and stdin/stdout...\n\nif os.name == \'posix\':\n    import fcntl\n\n    class file_wrapper:\n        # Here we override just enough to make a file\n        # look like a socket for the purposes of asyncore.\n        # The passed fd is automatically os.dup()\'d\n\n        def __init__(self, fd):\n            self.fd = os.dup(fd)\n\n        def recv(self, *args):\n            return os.read(self.fd, *args)\n\n        def send(self, *args):\n            return os.write(self.fd, *args)\n\n        def getsockopt(self, level, optname, buflen=None):\n            if (level == socket.SOL_SOCKET and\n                optname == socket.SO_ERROR and\n                not buflen):\n                return 0\n            raise NotImplementedError("Only asyncore specific behaviour "\n                                      "implemented.")\n\n        read = recv\n        write = send\n\n        def close(self):\n            os.close(self.fd)\n\n        def fileno(self):\n            return self.fd\n\n    class file_dispatcher(dispatcher):\n\n        def __init__(self, fd, map=None):\n            dispatcher.__init__(self, None, map)\n            self.connected = True\n            try:\n                fd = fd.fileno()\n            except AttributeError:\n                pass\n            self.set_file(fd)\n            # set it to non-blocking mode\n            flags = fcntl.fcntl(fd, fcntl.F_GETFL, 0)\n            flags = flags | os.O_NONBLOCK\n            fcntl.fcntl(fd, fcntl.F_SETFL, flags)\n\n        def set_file(self, fd):\n            self.socket = file_wrapper(fd)\n            self._fileno = self.socket.fileno()\n            self.add_channel()\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'asyncore.py', 4, '2012-07-06 13:57:18'),
	('4d9afc1e18ca4011af211d328936227a', '(.*)\\n",content)', 'a sublime text plugin of a share code library ', 'jamiesun', 'jamiesun.net@gmail.com', 'python,sublime text 2,python', '#!/usr/bin/python2.7 \n#coding:utf-8\nimport sublime,sublime_plugin\nimport re,os,sys,json\nimport urllib,urllib2\nimport logging\n\nreload(sys)\nsys.setdefaultencoding(\'utf-8\')\n\nlogger = logging.getLogger("talkincode")\nlogger.setLevel(logging.DEBUG)\nformatter = logging.Formatter(\'%(levelname)-8s %(message)s\', \'%a, %d %b %Y %H:%M:%S\',)\nconsole_handler = logging.StreamHandler(sys.stderr)\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n"""\n@description:a sublime text plugin of a share code library \n@tags:python,sublime text 2\n"""\nsettings = sublime.load_settings(\'ShareCodeLibrary.sublime-settings\')      \n\ndef post_code(params,url):\n    sublime.status_message("post request, please wait......")\n    try:\n        data = urllib.urlencode(params) \n        logger.info(data)\n        request = urllib2.Request(url, data)\n        response = urllib2.urlopen(request)    # This request is sent in HTTP POST\n        sublime.status_message("post response:%s"%response.read())\n    except Exception,e:\n        logger.info("error %s"%e)\n        raise\n\n\nclass ShareCurrentView(sublime_plugin.TextCommand):\n    def __init__(self,view):\n        self.view = view\n\n    def run(self, edit):\n        view = self.view\n        region = sublime.Region(0L, view.size())\n        filename = os.path.basename(view.file_name())\n        content = view.substr(region)\n        titlegrp = re.search("@description:(.*)\\n",content)\n        tagsgrp = re.search("@tags:(.*)\\n",content)\n        idgrp = re.search("        if not titlegrp:\n            sublime.status_message(r"your code source must contains @description:{some text} ")\n        else:\n            title = titlegrp.group(1)\n            tags = []\n            if tagsgrp:\n                tags.append(tagsgrp.group(1))\n            default_tags = settings.get("tags")\n            if default_tags:\n                tags.append(default_tags)\n\n            parentid = 0\n            if idgrp:\n                parentid = idgrp.group(1)\n\n\n\n            filename = view.file_name()\n            fext = os.path.splitext(filename)[1]\n            if len(fext) >1:\n                fext = fext[1:]\n\n            params = dict(pid=parentid,\n                title=title,\n                auther=settings.get("auther"),\n                email=settings.get("email"),\n                tagstr=",".join(tags),\n                content=re.sub("                lang=fext,\n                filename=os.path.basename(view.file_name()),\n                authkey=settings.get("authkey"))\n\n            post_code(params,settings.get("post_url"))\n\n\n\nclass ShareCodeQuery(sublime_plugin.WindowCommand):\n    def run(self):      \n        sublime.status_message("query code index, please wait......")\n        params = dict(index_limit=settings.get("index_limit"),authkey=settings.get("authkey"))\n        url = settings.get("index_url")\n        data = urllib.urlencode(params) \n        request = urllib2.Request("%s?%s"%(url,data))\n        response = urllib2.urlopen(request)   \n\n        try:\n            rstr = response.read()\n            result = json.loads(rstr)\n            if type(result) ==dict and result.has_key("error"):\n                sublime.status_message("error:%s"%result.get("error"))\n\n            format_it = lambda row: ["%s - %s"%(row["lang"],row["title"]),\n                                     "by @%s <%s> hits : %s"%(row["auther"],row["email"],row["hits"] )]\n            items = [format_it(row) for row in result]\n\n            def on_code_click(idx):\n                if idx == -1:\n                    return\n                uid = result[idx]["id"]\n                lang = result[idx]["lang"]\n                # rfile = result[idx].get("filename")\n                code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,lang)\n                # if rfile:\n                #     code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,rfile)\n\n                if not os.path.exists(code_file_path):\n                    get_url = settings.get("get_url")\n                    request = urllib2.Request("%s/%s"%(get_url,uid))\n                    response = urllib2.urlopen(request) \n                    get_json = json.loads(response.read())\n                    if type(get_json) ==dict and get_json.has_key("error"):\n                        sublime.status_message("error:%s"%get_json.get("error"))\n\n                    code_file = open(code_file_path,"wb")\n                    code_file.write("                    code_file.write(get_json[\'content\'])\n                    code_file.close()\n\n                code_view = self.window.open_file(code_file_path)\n                self.window.focus_view(code_view)\n\n            self.window.show_quick_panel(items,on_code_click)            \n        except Exception, e:\n            sublime.status_message("error:%s"%e)\n\n        \n\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'ShareCodeLibrary..py', 7, '2012-07-06 16:36:27'),
	('6b7da8957e6441568294da1839eff350', NULL, 'python asynchat', 'jamiesun', 'jamiesun.net@gmail.com', 'python,network,python', '# -*- Mode: Python; tab-width: 4 -*-\n#       Id: asynchat.py,v 2.26 2000/09/07 22:29:26 rushing Exp\n#       Author: Sam Rushing <rushing@nightmare.com>\n\n# ======================================================================\n# Copyright 1996 by Sam Rushing\n#\n#                         All Rights Reserved\n#\n# Permission to use, copy, modify, and distribute this software and\n# its documentation for any purpose and without fee is hereby\n# granted, provided that the above copyright notice appear in all\n# copies and that both that copyright notice and this permission\n# notice appear in supporting documentation, and that the name of Sam\n# Rushing not be used in advertising or publicity pertaining to\n# distribution of the software without specific, written prior\n# permission.\n#\n# SAM RUSHING DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE,\n# INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, IN\n# NO EVENT SHALL SAM RUSHING BE LIABLE FOR ANY SPECIAL, INDIRECT OR\n# CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS\n# OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,\n# NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN\n# CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n# ======================================================================\n"""\n@description:python asynchat\n@tags:python,network\n"""\nr"""A class supporting chat-style (command/response) protocols.\n\nThis class adds support for \'chat\' style protocols - where one side\nsends a \'command\', and the other sends a response (examples would be\nthe common internet protocols - smtp, nntp, ftp, etc..).\n\nThe handle_read() method looks at the input stream for the current\n\'terminator\' (usually \'\\r\\n\' for single-line responses, \'\\r\\n.\\r\\n\'\nfor multi-line output), calling self.found_terminator() on its\nreceipt.\n\nfor example:\nSay you build an async nntp client using this class.  At the start\nof the connection, you\'ll have self.terminator set to \'\\r\\n\', in\norder to process the single-line greeting.  Just before issuing a\n\'LIST\' command you\'ll set it to \'\\r\\n.\\r\\n\'.  The output of the LIST\ncommand will be accumulated (using your own \'collect_incoming_data\'\nmethod) up to the terminator, and then control will be returned to\nyou - by calling your self.found_terminator() method.\n"""\n\nimport socket\nimport asyncore\nfrom collections import deque\nfrom sys import py3kwarning\nfrom warnings import filterwarnings, catch_warnings\n\nclass async_chat (asyncore.dispatcher):\n    """This is an abstract class.  You must derive from this class, and add\n    the two methods collect_incoming_data() and found_terminator()"""\n\n    # these are overridable defaults\n\n    ac_in_buffer_size       = 4096\n    ac_out_buffer_size      = 4096\n\n    def __init__ (self, sock=None, map=None):\n        # for string terminator matching\n        self.ac_in_buffer = \'\'\n\n        # we use a list here rather than cStringIO for a few reasons...\n        # del lst[:] is faster than sio.truncate(0)\n        # lst = [] is faster than sio.truncate(0)\n        # cStringIO will be gaining unicode support in py3k, which\n        # will negatively affect the performance of bytes compared to\n        # a \'\'.join() equivalent\n        self.incoming = []\n\n        # we toss the use of the "simple producer" and replace it with\n        # a pure deque, which the original fifo was a wrapping of\n        self.producer_fifo = deque()\n        asyncore.dispatcher.__init__ (self, sock, map)\n\n    def collect_incoming_data(self, data):\n        raise NotImplementedError("must be implemented in subclass")\n\n    def _collect_incoming_data(self, data):\n        self.incoming.append(data)\n\n    def _get_data(self):\n        d = \'\'.join(self.incoming)\n        del self.incoming[:]\n        return d\n\n    def found_terminator(self):\n        raise NotImplementedError("must be implemented in subclass")\n\n    def set_terminator (self, term):\n        "Set the input delimiter.  Can be a fixed string of any length, an integer, or None"\n        self.terminator = term\n\n    def get_terminator (self):\n        return self.terminator\n\n    # grab some more data from the socket,\n    # throw it to the collector method,\n    # check for the terminator,\n    # if found, transition to the next state.\n\n    def handle_read (self):\n\n        try:\n            data = self.recv (self.ac_in_buffer_size)\n        except socket.error, why:\n            self.handle_error()\n            return\n\n        self.ac_in_buffer = self.ac_in_buffer + data\n\n        # Continue to search for self.terminator in self.ac_in_buffer,\n        # while calling self.collect_incoming_data.  The while loop\n        # is necessary because we might read several data+terminator\n        # combos with a single recv(4096).\n\n        while self.ac_in_buffer:\n            lb = len(self.ac_in_buffer)\n            terminator = self.get_terminator()\n            if not terminator:\n                # no terminator, collect it all\n                self.collect_incoming_data (self.ac_in_buffer)\n                self.ac_in_buffer = \'\'\n            elif isinstance(terminator, int) or isinstance(terminator, long):\n                # numeric terminator\n                n = terminator\n                if lb < n:\n                    self.collect_incoming_data (self.ac_in_buffer)\n                    self.ac_in_buffer = \'\'\n                    self.terminator = self.terminator - lb\n                else:\n                    self.collect_incoming_data (self.ac_in_buffer[:n])\n                    self.ac_in_buffer = self.ac_in_buffer[n:]\n                    self.terminator = 0\n                    self.found_terminator()\n            else:\n                # 3 cases:\n                # 1) end of buffer matches terminator exactly:\n                #    collect data, transition\n                # 2) end of buffer matches some prefix:\n                #    collect data to the prefix\n                # 3) end of buffer does not match any prefix:\n                #    collect data\n                terminator_len = len(terminator)\n                index = self.ac_in_buffer.find(terminator)\n                if index != -1:\n                    # we found the terminator\n                    if index > 0:\n                        # don\'t bother reporting the empty string (source of subtle bugs)\n                        self.collect_incoming_data (self.ac_in_buffer[:index])\n                    self.ac_in_buffer = self.ac_in_buffer[index+terminator_len:]\n                    # This does the Right Thing if the terminator is changed here.\n                    self.found_terminator()\n                else:\n                    # check for a prefix of the terminator\n                    index = find_prefix_at_end (self.ac_in_buffer, terminator)\n                    if index:\n                        if index != lb:\n                            # we found a prefix, collect up to the prefix\n                            self.collect_incoming_data (self.ac_in_buffer[:-index])\n                            self.ac_in_buffer = self.ac_in_buffer[-index:]\n                        break\n                    else:\n                        # no prefix, collect it all\n                        self.collect_incoming_data (self.ac_in_buffer)\n                        self.ac_in_buffer = \'\'\n\n    def handle_write (self):\n        self.initiate_send()\n\n    def handle_close (self):\n        self.close()\n\n    def push (self, data):\n        sabs = self.ac_out_buffer_size\n        if len(data) > sabs:\n            for i in xrange(0, len(data), sabs):\n                self.producer_fifo.append(data[i:i+sabs])\n        else:\n            self.producer_fifo.append(data)\n        self.initiate_send()\n\n    def push_with_producer (self, producer):\n        self.producer_fifo.append(producer)\n        self.initiate_send()\n\n    def readable (self):\n        "predicate for inclusion in the readable for select()"\n        # cannot use the old predicate, it violates the claim of the\n        # set_terminator method.\n\n        # return (len(self.ac_in_buffer) <= self.ac_in_buffer_size)\n        return 1\n\n    def writable (self):\n        "predicate for inclusion in the writable for select()"\n        return self.producer_fifo or (not self.connected)\n\n    def close_when_done (self):\n        "automatically close this channel once the outgoing queue is empty"\n        self.producer_fifo.append(None)\n\n    def initiate_send(self):\n        while self.producer_fifo and self.connected:\n            first = self.producer_fifo[0]\n            # handle empty string/buffer or None entry\n            if not first:\n                del self.producer_fifo[0]\n                if first is None:\n                    self.handle_close()\n                    return\n\n            # handle classic producer behavior\n            obs = self.ac_out_buffer_size\n            try:\n                with catch_warnings():\n                    if py3kwarning:\n                        filterwarnings("ignore", ".*buffer", DeprecationWarning)\n                    data = buffer(first, 0, obs)\n            except TypeError:\n                data = first.more()\n                if data:\n                    self.producer_fifo.appendleft(data)\n                else:\n                    del self.producer_fifo[0]\n                continue\n\n            # send the data\n            try:\n                num_sent = self.send(data)\n            except socket.error:\n                self.handle_error()\n                return\n\n            if num_sent:\n                if num_sent < len(data) or obs < len(first):\n                    self.producer_fifo[0] = first[num_sent:]\n                else:\n                    del self.producer_fifo[0]\n            # we tried to send some actual data\n            return\n\n    def discard_buffers (self):\n        # Emergencies only!\n        self.ac_in_buffer = \'\'\n        del self.incoming[:]\n        self.producer_fifo.clear()\n\nclass simple_producer:\n\n    def __init__ (self, data, buffer_size=512):\n        self.data = data\n        self.buffer_size = buffer_size\n\n    def more (self):\n        if len (self.data) > self.buffer_size:\n            result = self.data[:self.buffer_size]\n            self.data = self.data[self.buffer_size:]\n            return result\n        else:\n            result = self.data\n            self.data = \'\'\n            return result\n\nclass fifo:\n    def __init__ (self, list=None):\n        if not list:\n            self.list = deque()\n        else:\n            self.list = deque(list)\n\n    def __len__ (self):\n        return len(self.list)\n\n    def is_empty (self):\n        return not self.list\n\n    def first (self):\n        return self.list[0]\n\n    def push (self, data):\n        self.list.append(data)\n\n    def pop (self):\n        if self.list:\n            return (1, self.list.popleft())\n        else:\n            return (0, None)\n\n# Given \'haystack\', see if any prefix of \'needle\' is at its end.  This\n# assumes an exact match has already been checked.  Return the number of\n# characters matched.\n# for example:\n# f_p_a_e ("qwerty\\r", "\\r\\n") => 1\n# f_p_a_e ("qwertydkjf", "\\r\\n") => 0\n# f_p_a_e ("qwerty\\r\\n", "\\r\\n") => <undefined>\n\n# this could maybe be made faster with a computed regex?\n# [answer: no; circa Python-2.0, Jan 2001]\n# new python:   28961/s\n# old python:   18307/s\n# re:        12820/s\n# regex:     14035/s\n\ndef find_prefix_at_end (haystack, needle):\n    l = len(needle) - 1\n    while l and not haystack.endswith(needle[:l]):\n        l -= 1\n    return l\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'asynchat.py', 2, '2012-07-06 13:56:56'),
	('73628e2c9237456cbf5803220276d510', NULL, ' python charset lib', 'jamiesun', 'jamiesun.net@gmail.com', 'other', '# Copyright (C) 2001-2006 Python Software Foundation\n# Author: Ben Gertzfield, Barry Warsaw\n# Contact: email-sig@python.org\n# @description: python charset lib\n__all__ = [\n    \'Charset\',\n    \'add_alias\',\n    \'add_charset\',\n    \'add_codec\',\n    ]\n\nimport codecs\nimport email.base64mime\nimport email.quoprimime\n\nfrom email import errors\nfrom email.encoders import encode_7or8bit\n\n\n\n# Flags for types of header encodings\nQP          = 1 # Quoted-Printable\nBASE64      = 2 # Base64\nSHORTEST    = 3 # the shorter of QP and base64, but only for headers\n\n# In "=?charset?q?hello_world?=", the =?, ?q?, and ?= add up to 7\nMISC_LEN = 7\n\nDEFAULT_CHARSET = \'us-ascii\'\n\n\n\n# Defaults\nCHARSETS = {\n    # input        header enc  body enc output conv\n    \'iso-8859-1\':  (QP,        QP,      None),\n    \'iso-8859-2\':  (QP,        QP,      None),\n    \'iso-8859-3\':  (QP,        QP,      None),\n    \'iso-8859-4\':  (QP,        QP,      None),\n    # iso-8859-5 is Cyrillic, and not especially used\n    # iso-8859-6 is Arabic, also not particularly used\n    # iso-8859-7 is Greek, QP will not make it readable\n    # iso-8859-8 is Hebrew, QP will not make it readable\n    \'iso-8859-9\':  (QP,        QP,      None),\n    \'iso-8859-10\': (QP,        QP,      None),\n    # iso-8859-11 is Thai, QP will not make it readable\n    \'iso-8859-13\': (QP,        QP,      None),\n    \'iso-8859-14\': (QP,        QP,      None),\n    \'iso-8859-15\': (QP,        QP,      None),\n    \'iso-8859-16\': (QP,        QP,      None),\n    \'windows-1252\':(QP,        QP,      None),\n    \'viscii\':      (QP,        QP,      None),\n    \'us-ascii\':    (None,      None,    None),\n    \'big5\':        (BASE64,    BASE64,  None),\n    \'gb2312\':      (BASE64,    BASE64,  None),\n    \'euc-jp\':      (BASE64,    None,    \'iso-2022-jp\'),\n    \'shift_jis\':   (BASE64,    None,    \'iso-2022-jp\'),\n    \'iso-2022-jp\': (BASE64,    None,    None),\n    \'koi8-r\':      (BASE64,    BASE64,  None),\n    \'utf-8\':       (SHORTEST,  BASE64, \'utf-8\'),\n    # We\'re making this one up to represent raw unencoded 8-bit\n    \'8bit\':        (None,      BASE64, \'utf-8\'),\n    }\n\n# Aliases for other commonly-used names for character sets.  Map\n# them to the real ones used in email.\nALIASES = {\n    \'latin_1\': \'iso-8859-1\',\n    \'latin-1\': \'iso-8859-1\',\n    \'latin_2\': \'iso-8859-2\',\n    \'latin-2\': \'iso-8859-2\',\n    \'latin_3\': \'iso-8859-3\',\n    \'latin-3\': \'iso-8859-3\',\n    \'latin_4\': \'iso-8859-4\',\n    \'latin-4\': \'iso-8859-4\',\n    \'latin_5\': \'iso-8859-9\',\n    \'latin-5\': \'iso-8859-9\',\n    \'latin_6\': \'iso-8859-10\',\n    \'latin-6\': \'iso-8859-10\',\n    \'latin_7\': \'iso-8859-13\',\n    \'latin-7\': \'iso-8859-13\',\n    \'latin_8\': \'iso-8859-14\',\n    \'latin-8\': \'iso-8859-14\',\n    \'latin_9\': \'iso-8859-15\',\n    \'latin-9\': \'iso-8859-15\',\n    \'latin_10\':\'iso-8859-16\',\n    \'latin-10\':\'iso-8859-16\',\n    \'cp949\':   \'ks_c_5601-1987\',\n    \'euc_jp\':  \'euc-jp\',\n    \'euc_kr\':  \'euc-kr\',\n    \'ascii\':   \'us-ascii\',\n    }\n\n\n# Map charsets to their Unicode codec strings.\nCODEC_MAP = {\n    \'gb2312\':      \'eucgb2312_cn\',\n    \'big5\':        \'big5_tw\',\n    # Hack: We don\'t want *any* conversion for stuff marked us-ascii, as all\n    # sorts of garbage might be sent to us in the guise of 7-bit us-ascii.\n    # Let that stuff pass through without conversion to/from Unicode.\n    \'us-ascii\':    None,\n    }\n\n\n\n# Convenience functions for extending the above mappings\ndef add_charset(charset, header_enc=None, body_enc=None, output_charset=None):\n    """Add character set properties to the global registry.\n\n    charset is the input character set, and must be the canonical name of a\n    character set.\n\n    Optional header_enc and body_enc is either Charset.QP for\n    quoted-printable, Charset.BASE64 for base64 encoding, Charset.SHORTEST for\n    the shortest of qp or base64 encoding, or None for no encoding.  SHORTEST\n    is only valid for header_enc.  It describes how message headers and\n    message bodies in the input charset are to be encoded.  Default is no\n    encoding.\n\n    Optional output_charset is the character set that the output should be\n    in.  Conversions will proceed from input charset, to Unicode, to the\n    output charset when the method Charset.convert() is called.  The default\n    is to output in the same character set as the input.\n\n    Both input_charset and output_charset must have Unicode codec entries in\n    the module\'s charset-to-codec mapping; use add_codec(charset, codecname)\n    to add codecs the module does not know about.  See the codecs module\'s\n    documentation for more information.\n    """\n    if body_enc == SHORTEST:\n        raise ValueError(\'SHORTEST not allowed for body_enc\')\n    CHARSETS[charset] = (header_enc, body_enc, output_charset)\n\n\ndef add_alias(alias, canonical):\n    """Add a character set alias.\n\n    alias is the alias name, e.g. latin-1\n    canonical is the character set\'s canonical name, e.g. iso-8859-1\n    """\n    ALIASES[alias] = canonical\n\n\ndef add_codec(charset, codecname):\n    """Add a codec that map characters in the given charset to/from Unicode.\n\n    charset is the canonical name of a character set.  codecname is the name\n    of a Python codec, as appropriate for the second argument to the unicode()\n    built-in, or to the encode() method of a Unicode string.\n    """\n    CODEC_MAP[charset] = codecname\n\n\n\nclass Charset:\n    """Map character sets to their email properties.\n\n    This class provides information about the requirements imposed on email\n    for a specific character set.  It also provides convenience routines for\n    converting between character sets, given the availability of the\n    applicable codecs.  Given a character set, it will do its best to provide\n    information on how to use that character set in an email in an\n    RFC-compliant way.\n\n    Certain character sets must be encoded with quoted-printable or base64\n    when used in email headers or bodies.  Certain character sets must be\n    converted outright, and are not allowed in email.  Instances of this\n    module expose the following information about a character set:\n\n    input_charset: The initial character set specified.  Common aliases\n                   are converted to their `official\' email names (e.g. latin_1\n                   is converted to iso-8859-1).  Defaults to 7-bit us-ascii.\n\n    header_encoding: If the character set must be encoded before it can be\n                     used in an email header, this attribute will be set to\n                     Charset.QP (for quoted-printable), Charset.BASE64 (for\n                     base64 encoding), or Charset.SHORTEST for the shortest of\n                     QP or BASE64 encoding.  Otherwise, it will be None.\n\n    body_encoding: Same as header_encoding, but describes the encoding for the\n                   mail message\'s body, which indeed may be different than the\n                   header encoding.  Charset.SHORTEST is not allowed for\n                   body_encoding.\n\n    output_charset: Some character sets must be converted before the can be\n                    used in email headers or bodies.  If the input_charset is\n                    one of them, this attribute will contain the name of the\n                    charset output will be converted to.  Otherwise, it will\n                    be None.\n\n    input_codec: The name of the Python codec used to convert the\n                 input_charset to Unicode.  If no conversion codec is\n                 necessary, this attribute will be None.\n\n    output_codec: The name of the Python codec used to convert Unicode\n                  to the output_charset.  If no conversion codec is necessary,\n                  this attribute will have the same value as the input_codec.\n    """\n    def __init__(self, input_charset=DEFAULT_CHARSET):\n        # RFC 2046, $4.1.2 says charsets are not case sensitive.  We coerce to\n        # unicode because its .lower() is locale insensitive.  If the argument\n        # is already a unicode, we leave it at that, but ensure that the\n        # charset is ASCII, as the standard (RFC XXX) requires.\n        try:\n            if isinstance(input_charset, unicode):\n                input_charset.encode(\'ascii\')\n            else:\n                input_charset = unicode(input_charset, \'ascii\')\n        except UnicodeError:\n            raise errors.CharsetError(input_charset)\n        input_charset = input_charset.lower().encode(\'ascii\')\n        # Set the input charset after filtering through the aliases and/or codecs\n        if not (input_charset in ALIASES or input_charset in CHARSETS):\n            try:\n                input_charset = codecs.lookup(input_charset).name\n            except LookupError:\n                pass\n        self.input_charset = ALIASES.get(input_charset, input_charset)\n        # We can try to guess which encoding and conversion to use by the\n        # charset_map dictionary.  Try that first, but let the user override\n        # it.\n        henc, benc, conv = CHARSETS.get(self.input_charset,\n                                        (SHORTEST, BASE64, None))\n        if not conv:\n            conv = self.input_charset\n        # Set the attributes, allowing the arguments to override the default.\n        self.header_encoding = henc\n        self.body_encoding = benc\n        self.output_charset = ALIASES.get(conv, conv)\n        # Now set the codecs.  If one isn\'t defined for input_charset,\n        # guess and try a Unicode codec with the same name as input_codec.\n        self.input_codec = CODEC_MAP.get(self.input_charset,\n                                         self.input_charset)\n        self.output_codec = CODEC_MAP.get(self.output_charset,\n                                          self.output_charset)\n\n    def __str__(self):\n        return self.input_charset.lower()\n\n    __repr__ = __str__\n\n    def __eq__(self, other):\n        return str(self) == str(other).lower()\n\n    def __ne__(self, other):\n        return not self.__eq__(other)\n\n    def get_body_encoding(self):\n        """Return the content-transfer-encoding used for body encoding.\n\n        This is either the string `quoted-printable\' or `base64\' depending on\n        the encoding used, or it is a function in which case you should call\n        the function with a single argument, the Message object being\n        encoded.  The function should then set the Content-Transfer-Encoding\n        header itself to whatever is appropriate.\n\n        Returns "quoted-printable" if self.body_encoding is QP.\n        Returns "base64" if self.body_encoding is BASE64.\n        Returns "7bit" otherwise.\n        """\n        assert self.body_encoding != SHORTEST\n        if self.body_encoding == QP:\n            return \'quoted-printable\'\n        elif self.body_encoding == BASE64:\n            return \'base64\'\n        else:\n            return encode_7or8bit\n\n    def convert(self, s):\n        """Convert a string from the input_codec to the output_codec."""\n        if self.input_codec != self.output_codec:\n            return unicode(s, self.input_codec).encode(self.output_codec)\n        else:\n            return s\n\n    def to_splittable(self, s):\n        """Convert a possibly multibyte string to a safely splittable format.\n\n        Uses the input_codec to try and convert the string to Unicode, so it\n        can be safely split on character boundaries (even for multibyte\n        characters).\n\n        Returns the string as-is if it isn\'t known how to convert it to\n        Unicode with the input_charset.\n\n        Characters that could not be converted to Unicode will be replaced\n        with the Unicode replacement character U+FFFD.\n        """\n        if isinstance(s, unicode) or self.input_codec is None:\n            return s\n        try:\n            return unicode(s, self.input_codec, \'replace\')\n        except LookupError:\n            # Input codec not installed on system, so return the original\n            # string unchanged.\n            return s\n\n    def from_splittable(self, ustr, to_output=True):\n        """Convert a splittable string back into an encoded string.\n\n        Uses the proper codec to try and convert the string from Unicode back\n        into an encoded format.  Return the string as-is if it is not Unicode,\n        or if it could not be converted from Unicode.\n\n        Characters that could not be converted from Unicode will be replaced\n        with an appropriate character (usually \'?\').\n\n        If to_output is True (the default), uses output_codec to convert to an\n        encoded format.  If to_output is False, uses input_codec.\n        """\n        if to_output:\n            codec = self.output_codec\n        else:\n            codec = self.input_codec\n        if not isinstance(ustr, unicode) or codec is None:\n            return ustr\n        try:\n            return ustr.encode(codec, \'replace\')\n        except LookupError:\n            # Output codec not installed\n            return ustr\n\n    def get_output_charset(self):\n        """Return the output character set.\n\n        This is self.output_charset if that is not None, otherwise it is\n        self.input_charset.\n        """\n        return self.output_charset or self.input_charset\n\n    def encoded_header_len(self, s):\n        """Return the length of the encoded header string."""\n        cset = self.get_output_charset()\n        # The len(s) of a 7bit encoding is len(s)\n        if self.header_encoding == BASE64:\n            return email.base64mime.base64_len(s) + len(cset) + MISC_LEN\n        elif self.header_encoding == QP:\n            return email.quoprimime.header_quopri_len(s) + len(cset) + MISC_LEN\n        elif self.header_encoding == SHORTEST:\n            lenb64 = email.base64mime.base64_len(s)\n            lenqp = email.quoprimime.header_quopri_len(s)\n            return min(lenb64, lenqp) + len(cset) + MISC_LEN\n        else:\n            return len(s)\n\n    def header_encode(self, s, convert=False):\n        """Header-encode a string, optionally converting it to output_charset.\n\n        If convert is True, the string will be converted from the input\n        charset to the output charset automatically.  This is not useful for\n        multibyte character sets, which have line length issues (multibyte\n        characters must be split on a character, not a byte boundary); use the\n        high-level Header class to deal with these issues.  convert defaults\n        to False.\n\n        The type of encoding (base64 or quoted-printable) will be based on\n        self.header_encoding.\n        """\n        cset = self.get_output_charset()\n        if convert:\n            s = self.convert(s)\n        # 7bit/8bit encodings return the string unchanged (modulo conversions)\n        if self.header_encoding == BASE64:\n            return email.base64mime.header_encode(s, cset)\n        elif self.header_encoding == QP:\n            return email.quoprimime.header_encode(s, cset, maxlinelen=None)\n        elif self.header_encoding == SHORTEST:\n            lenb64 = email.base64mime.base64_len(s)\n            lenqp = email.quoprimime.header_quopri_len(s)\n            if lenb64 < lenqp:\n                return email.base64mime.header_encode(s, cset)\n            else:\n                return email.quoprimime.header_encode(s, cset, maxlinelen=None)\n        else:\n            return s\n\n    def body_encode(self, s, convert=True):\n        """Body-encode a string and convert it to output_charset.\n\n        If convert is True (the default), the string will be converted from\n        the input charset to output charset automatically.  Unlike\n        header_encode(), there are no issues with byte boundaries and\n        multibyte charsets in email bodies, so this is usually pretty safe.\n\n        The type of encoding (base64 or quoted-printable) will be based on\n        self.body_encoding.\n        """\n        if convert:\n            s = self.convert(s)\n        # 7bit/8bit encodings return the string unchanged (module conversions)\n        if self.body_encoding is BASE64:\n            return email.base64mime.body_encode(s)\n        elif self.body_encoding is QP:\n            return email.quoprimime.body_encode(s)\n        else:\n            return s\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'charset.py', 3, '2012-07-06 13:39:01'),
	('9253851237374694855e542f4db020d1', '(.*)\\n",content)', 'a sublime text plugin of a share code library ', 'jamiesun', 'jamiesun.net@gmail.com', 'python,sublime text 2,python', '#!/usr/bin/python2.7 \n#coding:utf-8\nimport sublime,sublime_plugin\nimport re,os,sys,json\nimport urllib,urllib2\nimport logging\n\nreload(sys)\nsys.setdefaultencoding(\'utf-8\')\n\nlogger = logging.getLogger("talkincode")\nlogger.setLevel(logging.DEBUG)\nformatter = logging.Formatter(\'%(levelname)-8s %(message)s\', \'%a, %d %b %Y %H:%M:%S\',)\nconsole_handler = logging.StreamHandler(sys.stderr)\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n"""\n@description:a sublime text plugin of a share code library \n@tags:python,sublime text 2\n"""\nsettings = sublime.load_settings(\'ShareCodeLibrary.sublime-settings\')      \n\ndef post_code(params,url):\n    sublime.status_message("post request, please wait......")\n    try:\n        data = urllib.urlencode(params) \n        logger.info(data)\n        request = urllib2.Request(url, data)\n        response = urllib2.urlopen(request)    # This request is sent in HTTP POST\n        sublime.status_message("post response:%s"%response.read())\n    except Exception,e:\n        logger.info("error %s"%e)\n        raise\n\n\nclass ShareCurrentView(sublime_plugin.TextCommand):\n    def __init__(self,view):\n        self.view = view\n\n    def run(self, edit):\n        view = self.view\n        region = sublime.Region(0L, view.size())\n        filename = os.path.basename(view.file_name())\n        content = view.substr(region)\n        titlegrp = re.search("@description:(.*)\\n",content)\n        tagsgrp = re.search("@tags:(.*)\\n",content)\n        idgrp = re.search("        if not titlegrp:\n            sublime.status_message(r"your code source must contains @description:{some text} ")\n        else:\n            title = titlegrp.group(1)\n            tags = []\n            if tagsgrp:\n                tags.append(tagsgrp.group(1))\n            default_tags = settings.get("tags")\n            if default_tags:\n                tags.append(default_tags)\n\n            parentid = 0\n            if idgrp:\n                parentid = idgrp.group(1)\n\n\n\n            filename = view.file_name()\n            fext = os.path.splitext(filename)[1]\n            if len(fext) >1:\n                fext = fext[1:]\n\n            params = dict(pid=parentid,\n                title=title,\n                auther=settings.get("auther"),\n                email=settings.get("email"),\n                tagstr=",".join(tags),\n                content=re.sub("                lang=fext,\n                filename=os.path.basename(view.file_name()),\n                authkey=settings.get("authkey"))\n\n            post_code(params,settings.get("post_url"))\n\n\n\nclass ShareCodeQuery(sublime_plugin.WindowCommand):\n    def run(self):      \n        sublime.status_message("query code index, please wait......")\n        params = dict(index_limit=settings.get("index_limit"),authkey=settings.get("authkey"))\n        url = settings.get("index_url")\n        data = urllib.urlencode(params) \n        request = urllib2.Request("%s?%s"%(url,data))\n        response = urllib2.urlopen(request)   \n\n        try:\n            rstr = response.read()\n            result = json.loads(rstr)\n            if type(result) ==dict and result.has_key("error"):\n                sublime.status_message("error:%s"%result.get("error"))\n\n            format_it = lambda row: ["%s - %s"%(row["lang"],row["title"]),\n                                     "by @%s <%s> hits : %s"%(row["auther"],row["email"],row["hits"] )]\n            items = [format_it(row) for row in result]\n\n            def on_code_click(idx):\n                if idx == -1:\n                    return\n                uid = result[idx]["id"]\n                lang = result[idx]["lang"]\n                # rfile = result[idx].get("filename")\n                code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,lang)\n                # if rfile:\n                #     code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,rfile)\n\n                if not os.path.exists(code_file_path):\n                    get_url = settings.get("get_url")\n                    request = urllib2.Request("%s/%s"%(get_url,uid))\n                    response = urllib2.urlopen(request) \n                    get_json = json.loads(response.read())\n                    if type(get_json) ==dict and get_json.has_key("error"):\n                        sublime.status_message("error:%s"%get_json.get("error"))\n\n                    code_file = open(code_file_path,"wb")\n                    code_file.write("                    code_file.write(get_json[\'content\'])\n                    code_file.close()\n\n                code_view = self.window.open_file(code_file_path)\n                self.window.focus_view(code_view)\n\n            self.window.show_quick_panel(items,on_code_click)            \n        except Exception, e:\n            sublime.status_message("error:%s"%e)\n\n        \n\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'ShareCodeLibrary..py', 6, '2012-07-06 16:36:29'),
	('9891231113e14fcb83a71863984dc55c', '0', 'python cgi http server module', 'jamiesun', 'jamiesun.net@gmail.com', 'cgi,python', '"""CGI-savvy HTTP Server.\n\nThis module builds on SimpleHTTPServer by implementing GET and POST\nrequests to cgi-bin scripts.\n\nIf the os.fork() function is not present (e.g. on Windows),\nos.popen2() is used as a fallback, with slightly altered semantics; if\nthat function is not present either (e.g. on Macintosh), only Python\nscripts are supported, and they are executed by the current process.\n\nIn all cases, the implementation is intentionally naive -- all\nrequests are executed sychronously.\n\nSECURITY WARNING: DON\'T USE THIS CODE UNLESS YOU ARE INSIDE A FIREWALL\n-- it may execute arbitrary Python code or external programs.\n\nNote that status code 200 is sent prior to execution of a CGI script, so\nscripts cannot send other status codes such as 302 (redirect).\n"""\n"""\n@description:python cgi http server module\n@tags:cgi\n"""\n\n__version__ = "0.4"\n\n__all__ = ["CGIHTTPRequestHandler"]\n\nimport os\nimport sys\nimport urllib\nimport BaseHTTPServer\nimport SimpleHTTPServer\nimport select\nimport copy\n\n\nclass CGIHTTPRequestHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):\n\n    """Complete HTTP server with GET, HEAD and POST commands.\n\n    GET and HEAD also support running CGI scripts.\n\n    The POST command is *only* implemented for CGI scripts.\n\n    """\n\n    # Determine platform specifics\n    have_fork = hasattr(os, \'fork\')\n    have_popen2 = hasattr(os, \'popen2\')\n    have_popen3 = hasattr(os, \'popen3\')\n\n    # Make rfile unbuffered -- we need to read one line and then pass\n    # the rest to a subprocess, so we can\'t use buffered input.\n    rbufsize = 0\n\n    def do_POST(self):\n        """Serve a POST request.\n\n        This is only implemented for CGI scripts.\n\n        """\n\n        if self.is_cgi():\n            self.run_cgi()\n        else:\n            self.send_error(501, "Can only POST to CGI scripts")\n\n    def send_head(self):\n        """Version of send_head that support CGI scripts"""\n        if self.is_cgi():\n            return self.run_cgi()\n        else:\n            return SimpleHTTPServer.SimpleHTTPRequestHandler.send_head(self)\n\n    def is_cgi(self):\n        """Test whether self.path corresponds to a CGI script.\n\n        Returns True and updates the cgi_info attribute to the tuple\n        (dir, rest) if self.path requires running a CGI script.\n        Returns False otherwise.\n\n        If any exception is raised, the caller should assume that\n        self.path was rejected as invalid and act accordingly.\n\n        The default implementation tests whether the normalized url\n        path begins with one of the strings in self.cgi_directories\n        (and the next character is a \'/\' or the end of the string).\n        """\n        splitpath = _url_collapse_path_split(self.path)\n        if splitpath[0] in self.cgi_directories:\n            self.cgi_info = splitpath\n            return True\n        return False\n\n    cgi_directories = [\'/cgi-bin\', \'/htbin\']\n\n    def is_executable(self, path):\n        """Test whether argument path is an executable file."""\n        return executable(path)\n\n    def is_python(self, path):\n        """Test whether argument path is a Python script."""\n        head, tail = os.path.splitext(path)\n        return tail.lower() in (".py", ".pyw")\n\n    def run_cgi(self):\n        """Execute a CGI script."""\n        path = self.path\n        dir, rest = self.cgi_info\n\n        i = path.find(\'/\', len(dir) + 1)\n        while i >= 0:\n            nextdir = path[:i]\n            nextrest = path[i+1:]\n\n            scriptdir = self.translate_path(nextdir)\n            if os.path.isdir(scriptdir):\n                dir, rest = nextdir, nextrest\n                i = path.find(\'/\', len(dir) + 1)\n            else:\n                break\n\n        # find an explicit query string, if present.\n        i = rest.rfind(\'?\')\n        if i >= 0:\n            rest, query = rest[:i], rest[i+1:]\n        else:\n            query = \'\'\n\n        # dissect the part after the directory name into a script name &\n        # a possible additional path, to be stored in PATH_INFO.\n        i = rest.find(\'/\')\n        if i >= 0:\n            script, rest = rest[:i], rest[i:]\n        else:\n            script, rest = rest, \'\'\n\n        scriptname = dir + \'/\' + script\n        scriptfile = self.translate_path(scriptname)\n        if not os.path.exists(scriptfile):\n            self.send_error(404, "No such CGI script (%r)" % scriptname)\n            return\n        if not os.path.isfile(scriptfile):\n            self.send_error(403, "CGI script is not a plain file (%r)" %\n                            scriptname)\n            return\n        ispy = self.is_python(scriptname)\n        if not ispy:\n            if not (self.have_fork or self.have_popen2 or self.have_popen3):\n                self.send_error(403, "CGI script is not a Python script (%r)" %\n                                scriptname)\n                return\n            if not self.is_executable(scriptfile):\n                self.send_error(403, "CGI script is not executable (%r)" %\n                                scriptname)\n                return\n\n        # Reference: http://hoohoo.ncsa.uiuc.edu/cgi/env.html\n        # XXX Much of the following could be prepared ahead of time!\n        env = copy.deepcopy(os.environ)\n        env[\'SERVER_SOFTWARE\'] = self.version_string()\n        env[\'SERVER_NAME\'] = self.server.server_name\n        env[\'GATEWAY_INTERFACE\'] = \'CGI/1.1\'\n        env[\'SERVER_PROTOCOL\'] = self.protocol_version\n        env[\'SERVER_PORT\'] = str(self.server.server_port)\n        env[\'REQUEST_METHOD\'] = self.command\n        uqrest = urllib.unquote(rest)\n        env[\'PATH_INFO\'] = uqrest\n        env[\'PATH_TRANSLATED\'] = self.translate_path(uqrest)\n        env[\'SCRIPT_NAME\'] = scriptname\n        if query:\n            env[\'QUERY_STRING\'] = query\n        host = self.address_string()\n        if host != self.client_address[0]:\n            env[\'REMOTE_HOST\'] = host\n        env[\'REMOTE_ADDR\'] = self.client_address[0]\n        authorization = self.headers.getheader("authorization")\n        if authorization:\n            authorization = authorization.split()\n            if len(authorization) == 2:\n                import base64, binascii\n                env[\'AUTH_TYPE\'] = authorization[0]\n                if authorization[0].lower() == "basic":\n                    try:\n                        authorization = base64.decodestring(authorization[1])\n                    except binascii.Error:\n                        pass\n                    else:\n                        authorization = authorization.split(\':\')\n                        if len(authorization) == 2:\n                            env[\'REMOTE_USER\'] = authorization[0]\n        # XXX REMOTE_IDENT\n        if self.headers.typeheader is None:\n            env[\'CONTENT_TYPE\'] = self.headers.type\n        else:\n            env[\'CONTENT_TYPE\'] = self.headers.typeheader\n        length = self.headers.getheader(\'content-length\')\n        if length:\n            env[\'CONTENT_LENGTH\'] = length\n        referer = self.headers.getheader(\'referer\')\n        if referer:\n            env[\'HTTP_REFERER\'] = referer\n        accept = []\n        for line in self.headers.getallmatchingheaders(\'accept\'):\n            if line[:1] in "\\t\\n\\r ":\n                accept.append(line.strip())\n            else:\n                accept = accept + line[7:].split(\',\')\n        env[\'HTTP_ACCEPT\'] = \',\'.join(accept)\n        ua = self.headers.getheader(\'user-agent\')\n        if ua:\n            env[\'HTTP_USER_AGENT\'] = ua\n        co = filter(None, self.headers.getheaders(\'cookie\'))\n        if co:\n            env[\'HTTP_COOKIE\'] = \', \'.join(co)\n        # XXX Other HTTP_* headers\n        # Since we\'re setting the env in the parent, provide empty\n        # values to override previously set values\n        for k in (\'QUERY_STRING\', \'REMOTE_HOST\', \'CONTENT_LENGTH\',\n                  \'HTTP_USER_AGENT\', \'HTTP_COOKIE\', \'HTTP_REFERER\'):\n            env.setdefault(k, "")\n\n        self.send_response(200, "Script output follows")\n\n        decoded_query = query.replace(\'+\', \' \')\n\n        if self.have_fork:\n            # Unix -- fork as we should\n            args = [script]\n            if \'=\' not in decoded_query:\n                args.append(decoded_query)\n            nobody = nobody_uid()\n            self.wfile.flush() # Always flush before forking\n            pid = os.fork()\n            if pid != 0:\n                # Parent\n                pid, sts = os.waitpid(pid, 0)\n                # throw away additional data [see bug #427345]\n                while select.select([self.rfile], [], [], 0)[0]:\n                    if not self.rfile.read(1):\n                        break\n                if sts:\n                    self.log_error("CGI script exit status %#x", sts)\n                return\n            # Child\n            try:\n                try:\n                    os.setuid(nobody)\n                except os.error:\n                    pass\n                os.dup2(self.rfile.fileno(), 0)\n                os.dup2(self.wfile.fileno(), 1)\n                os.execve(scriptfile, args, env)\n            except:\n                self.server.handle_error(self.request, self.client_address)\n                os._exit(127)\n\n        else:\n            # Non Unix - use subprocess\n            import subprocess\n            cmdline = [scriptfile]\n            if self.is_python(scriptfile):\n                interp = sys.executable\n                if interp.lower().endswith("w.exe"):\n                    # On Windows, use python.exe, not pythonw.exe\n                    interp = interp[:-5] + interp[-4:]\n                cmdline = [interp, \'-u\'] + cmdline\n            if \'=\' not in query:\n                cmdline.append(query)\n\n            self.log_message("command: %s", subprocess.list2cmdline(cmdline))\n            try:\n                nbytes = int(length)\n            except (TypeError, ValueError):\n                nbytes = 0\n            p = subprocess.Popen(cmdline,\n                                 stdin = subprocess.PIPE,\n                                 stdout = subprocess.PIPE,\n                                 stderr = subprocess.PIPE,\n                                 env = env\n                                )\n            if self.command.lower() == "post" and nbytes > 0:\n                data = self.rfile.read(nbytes)\n            else:\n                data = None\n            # throw away additional data [see bug #427345]\n            while select.select([self.rfile._sock], [], [], 0)[0]:\n                if not self.rfile._sock.recv(1):\n                    break\n            stdout, stderr = p.communicate(data)\n            self.wfile.write(stdout)\n            if stderr:\n                self.log_error(\'%s\', stderr)\n            p.stderr.close()\n            p.stdout.close()\n            status = p.returncode\n            if status:\n                self.log_error("CGI script exit status %#x", status)\n            else:\n                self.log_message("CGI script exited OK")\n\n\n# TODO(gregory.p.smith): Move this into an appropriate library.\ndef _url_collapse_path_split(path):\n    """\n    Given a URL path, remove extra \'/\'s and \'.\' path elements and collapse\n    any \'..\' references.\n\n    Implements something akin to RFC-2396 5.2 step 6 to parse relative paths.\n\n    Returns: A tuple of (head, tail) where tail is everything after the final /\n    and head is everything before it.  Head will always start with a \'/\' and,\n    if it contains anything else, never have a trailing \'/\'.\n\n    Raises: IndexError if too many \'..\' occur within the path.\n    """\n    # Similar to os.path.split(os.path.normpath(path)) but specific to URL\n    # path semantics rather than local operating system semantics.\n    path_parts = []\n    for part in path.split(\'/\'):\n        if part == \'.\':\n            path_parts.append(\'\')\n        else:\n            path_parts.append(part)\n    # Filter out blank non trailing parts before consuming the \'..\'.\n    path_parts = [part for part in path_parts[:-1] if part] + path_parts[-1:]\n    if path_parts:\n        tail_part = path_parts.pop()\n    else:\n        tail_part = \'\'\n    head_parts = []\n    for part in path_parts:\n        if part == \'..\':\n            head_parts.pop()\n        else:\n            head_parts.append(part)\n    if tail_part and tail_part == \'..\':\n        head_parts.pop()\n        tail_part = \'\'\n    return (\'/\' + \'/\'.join(head_parts), tail_part)\n\n\nnobody = None\n\ndef nobody_uid():\n    """Internal routine to get nobody\'s uid"""\n    global nobody\n    if nobody:\n        return nobody\n    try:\n        import pwd\n    except ImportError:\n        return -1\n    try:\n        nobody = pwd.getpwnam(\'nobody\')[2]\n    except KeyError:\n        nobody = 1 + max(map(lambda x: x[2], pwd.getpwall()))\n    return nobody\n\n\ndef executable(path):\n    """Test for executable file."""\n    try:\n        st = os.stat(path)\n    except os.error:\n        return False\n    return st.st_mode & 0111 != 0\n\n\ndef test(HandlerClass = CGIHTTPRequestHandler,\n         ServerClass = BaseHTTPServer.HTTPServer):\n    SimpleHTTPServer.test(HandlerClass, ServerClass)\n\n\nif __name__ == \'__main__\':\n    test()\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', '0efd503e59cb402d887ed5972f56995f.py', 7, '2012-07-06 15:15:54'),
	('b46cdf69363a4b56a8be46dfbe3df44d', NULL, 'mysql of python ', 'jamiesun', 'jamiesun.net@gmail.com', 'other', '#!/usr/bin/python2.7 \n#coding:utf-8\n"""\n@description:mysql of python \n"""\nimport MySQLdb\n\nfrom DBUtils.PooledDB import PooledDB\n\ndbpool = PooledDB(creator=MySQLdb,\n                  maxusage=1000,\n                  host=\'localhost\',\n                  user=\'root\',\n                  passwd=\'root\',\n                  db=\'talkincode_db1\',\n                  charset="utf8"\n                  )\n\nget_conn = lambda : dbpool.connection()\n\ndef todict(row,rowdesc):\n    d = {}\n    for idx, col in enumerate(rowdesc):\n        d[col[0]] = row[idx]\n    return d\n\n\n\n\n\n\n\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'store.py', 17, '2012-07-06 13:18:14'),
	('bc99a9d78b5647d5aa5ab5f73e55ca9e', NULL, 'python cgi module', 'jamiesun', 'jamiesun.net@gmail.com', 'cgi,python', '#! /usr/local/bin/python\n\n# NOTE: the above "/usr/local/bin/python" is NOT a mistake.  It is\n# intentionally NOT "/usr/bin/env python".  On many systems\n# (e.g. Solaris), /usr/local/bin is not in $PATH as passed to CGI\n# scripts, and /usr/local/bin is the default directory where Python is\n# installed, so /usr/bin/env would be unable to find python.  Granted,\n# binary installations by Linux vendors often install Python in\n# /usr/bin.  So let those vendors patch cgi.py to match their choice\n# of installation.\n\n"""Support module for CGI (Common Gateway Interface) scripts.\n\nThis module defines a number of utilities for use by CGI scripts\nwritten in Python.\n"""\n"""\n@description:python cgi module\n@tags:cgi\n"""\n# XXX Perhaps there should be a slimmed version that doesn\'t contain\n# all those backwards compatible and debugging classes and functions?\n\n# History\n# -------\n#\n# Michael McLay started this module.  Steve Majewski changed the\n# interface to SvFormContentDict and FormContentDict.  The multipart\n# parsing was inspired by code submitted by Andreas Paepcke.  Guido van\n# Rossum rewrote, reformatted and documented the module and is currently\n# responsible for its maintenance.\n#\n\n__version__ = "2.6"\n\n\n# Imports\n# =======\n\nfrom operator import attrgetter\nimport sys\nimport os\nimport urllib\nimport UserDict\nimport urlparse\n\nfrom warnings import filterwarnings, catch_warnings, warn\nwith catch_warnings():\n    if sys.py3kwarning:\n        filterwarnings("ignore", ".*mimetools has been removed",\n                       DeprecationWarning)\n        filterwarnings("ignore", ".*rfc822 has been removed",\n                       DeprecationWarning)\n    import mimetools\n    import rfc822\n\ntry:\n    from cStringIO import StringIO\nexcept ImportError:\n    from StringIO import StringIO\n\n__all__ = ["MiniFieldStorage", "FieldStorage", "FormContentDict",\n           "SvFormContentDict", "InterpFormContentDict", "FormContent",\n           "parse", "parse_qs", "parse_qsl", "parse_multipart",\n           "parse_header", "print_exception", "print_environ",\n           "print_form", "print_directory", "print_arguments",\n           "print_environ_usage", "escape"]\n\n# Logging support\n# ===============\n\nlogfile = ""            # Filename to log to, if not empty\nlogfp = None            # File object to log to, if not None\n\ndef initlog(*allargs):\n    """Write a log message, if there is a log file.\n\n    Even though this function is called initlog(), you should always\n    use log(); log is a variable that is set either to initlog\n    (initially), to dolog (once the log file has been opened), or to\n    nolog (when logging is disabled).\n\n    The first argument is a format string; the remaining arguments (if\n    any) are arguments to the % operator, so e.g.\n        log("%s: %s", "a", "b")\n    will write "a: b" to the log file, followed by a newline.\n\n    If the global logfp is not None, it should be a file object to\n    which log data is written.\n\n    If the global logfp is None, the global logfile may be a string\n    giving a filename to open, in append mode.  This file should be\n    world writable!!!  If the file can\'t be opened, logging is\n    silently disabled (since there is no safe place where we could\n    send an error message).\n\n    """\n    global logfp, log\n    if logfile and not logfp:\n        try:\n            logfp = open(logfile, "a")\n        except IOError:\n            pass\n    if not logfp:\n        log = nolog\n    else:\n        log = dolog\n    log(*allargs)\n\ndef dolog(fmt, *args):\n    """Write a log message to the log file.  See initlog() for docs."""\n    logfp.write(fmt%args + "\\n")\n\ndef nolog(*allargs):\n    """Dummy function, assigned to log when logging is disabled."""\n    pass\n\nlog = initlog           # The current logging function\n\n\n# Parsing functions\n# =================\n\n# Maximum input we will accept when REQUEST_METHOD is POST\n# 0 ==> unlimited input\nmaxlen = 0\n\ndef parse(fp=None, environ=os.environ, keep_blank_values=0, strict_parsing=0):\n    """Parse a query in the environment or from a file (default stdin)\n\n        Arguments, all optional:\n\n        fp              : file pointer; default: sys.stdin\n\n        environ         : environment dictionary; default: os.environ\n\n        keep_blank_values: flag indicating whether blank values in\n            percent-encoded forms should be treated as blank strings.\n            A true value indicates that blanks should be retained as\n            blank strings.  The default false value indicates that\n            blank values are to be ignored and treated as if they were\n            not included.\n\n        strict_parsing: flag indicating what to do with parsing errors.\n            If false (the default), errors are silently ignored.\n            If true, errors raise a ValueError exception.\n    """\n    if fp is None:\n        fp = sys.stdin\n    if not \'REQUEST_METHOD\' in environ:\n        environ[\'REQUEST_METHOD\'] = \'GET\'       # For testing stand-alone\n    if environ[\'REQUEST_METHOD\'] == \'POST\':\n        ctype, pdict = parse_header(environ[\'CONTENT_TYPE\'])\n        if ctype == \'multipart/form-data\':\n            return parse_multipart(fp, pdict)\n        elif ctype == \'application/x-www-form-urlencoded\':\n            clength = int(environ[\'CONTENT_LENGTH\'])\n            if maxlen and clength > maxlen:\n                raise ValueError, \'Maximum content length exceeded\'\n            qs = fp.read(clength)\n        else:\n            qs = \'\'                     # Unknown content-type\n        if \'QUERY_STRING\' in environ:\n            if qs: qs = qs + \'&\'\n            qs = qs + environ[\'QUERY_STRING\']\n        elif sys.argv[1:]:\n            if qs: qs = qs + \'&\'\n            qs = qs + sys.argv[1]\n        environ[\'QUERY_STRING\'] = qs    # XXX Shouldn\'t, really\n    elif \'QUERY_STRING\' in environ:\n        qs = environ[\'QUERY_STRING\']\n    else:\n        if sys.argv[1:]:\n            qs = sys.argv[1]\n        else:\n            qs = ""\n        environ[\'QUERY_STRING\'] = qs    # XXX Shouldn\'t, really\n    return urlparse.parse_qs(qs, keep_blank_values, strict_parsing)\n\n\n# parse query string function called from urlparse,\n# this is done in order to maintain backward compatiblity.\n\ndef parse_qs(qs, keep_blank_values=0, strict_parsing=0):\n    """Parse a query given as a string argument."""\n    warn("cgi.parse_qs is deprecated, use urlparse.parse_qs instead",\n         PendingDeprecationWarning, 2)\n    return urlparse.parse_qs(qs, keep_blank_values, strict_parsing)\n\n\ndef parse_qsl(qs, keep_blank_values=0, strict_parsing=0):\n    """Parse a query given as a string argument."""\n    warn("cgi.parse_qsl is deprecated, use urlparse.parse_qsl instead",\n         PendingDeprecationWarning, 2)\n    return urlparse.parse_qsl(qs, keep_blank_values, strict_parsing)\n\ndef parse_multipart(fp, pdict):\n    """Parse multipart input.\n\n    Arguments:\n    fp   : input file\n    pdict: dictionary containing other parameters of content-type header\n\n    Returns a dictionary just like parse_qs(): keys are the field names, each\n    value is a list of values for that field.  This is easy to use but not\n    much good if you are expecting megabytes to be uploaded -- in that case,\n    use the FieldStorage class instead which is much more flexible.  Note\n    that content-type is the raw, unparsed contents of the content-type\n    header.\n\n    XXX This does not parse nested multipart parts -- use FieldStorage for\n    that.\n\n    XXX This should really be subsumed by FieldStorage altogether -- no\n    point in having two implementations of the same parsing algorithm.\n    Also, FieldStorage protects itself better against certain DoS attacks\n    by limiting the size of the data read in one chunk.  The API here\n    does not support that kind of protection.  This also affects parse()\n    since it can call parse_multipart().\n\n    """\n    boundary = ""\n    if \'boundary\' in pdict:\n        boundary = pdict[\'boundary\']\n    if not valid_boundary(boundary):\n        raise ValueError,  (\'Invalid boundary in multipart form: %r\'\n                            % (boundary,))\n\n    nextpart = "--" + boundary\n    lastpart = "--" + boundary + "--"\n    partdict = {}\n    terminator = ""\n\n    while terminator != lastpart:\n        bytes = -1\n        data = None\n        if terminator:\n            # At start of next part.  Read headers first.\n            headers = mimetools.Message(fp)\n            clength = headers.getheader(\'content-length\')\n            if clength:\n                try:\n                    bytes = int(clength)\n                except ValueError:\n                    pass\n            if bytes > 0:\n                if maxlen and bytes > maxlen:\n                    raise ValueError, \'Maximum content length exceeded\'\n                data = fp.read(bytes)\n            else:\n                data = ""\n        # Read lines until end of part.\n        lines = []\n        while 1:\n            line = fp.readline()\n            if not line:\n                terminator = lastpart # End outer loop\n                break\n            if line[:2] == "--":\n                terminator = line.strip()\n                if terminator in (nextpart, lastpart):\n                    break\n            lines.append(line)\n        # Done with part.\n        if data is None:\n            continue\n        if bytes < 0:\n            if lines:\n                # Strip final line terminator\n                line = lines[-1]\n                if line[-2:] == "\\r\\n":\n                    line = line[:-2]\n                elif line[-1:] == "\\n":\n                    line = line[:-1]\n                lines[-1] = line\n                data = "".join(lines)\n        line = headers[\'content-disposition\']\n        if not line:\n            continue\n        key, params = parse_header(line)\n        if key != \'form-data\':\n            continue\n        if \'name\' in params:\n            name = params[\'name\']\n        else:\n            continue\n        if name in partdict:\n            partdict[name].append(data)\n        else:\n            partdict[name] = [data]\n\n    return partdict\n\n\ndef _parseparam(s):\n    while s[:1] == \';\':\n        s = s[1:]\n        end = s.find(\';\')\n        while end > 0 and (s.count(\'"\', 0, end) - s.count(\'\\\\"\', 0, end)) % 2:\n            end = s.find(\';\', end + 1)\n        if end < 0:\n            end = len(s)\n        f = s[:end]\n        yield f.strip()\n        s = s[end:]\n\ndef parse_header(line):\n    """Parse a Content-type like header.\n\n    Return the main content-type and a dictionary of options.\n\n    """\n    parts = _parseparam(\';\' + line)\n    key = parts.next()\n    pdict = {}\n    for p in parts:\n        i = p.find(\'=\')\n        if i >= 0:\n            name = p[:i].strip().lower()\n            value = p[i+1:].strip()\n            if len(value) >= 2 and value[0] == value[-1] == \'"\':\n                value = value[1:-1]\n                value = value.replace(\'\\\\\\\\\', \'\\\\\').replace(\'\\\\"\', \'"\')\n            pdict[name] = value\n    return key, pdict\n\n\n# Classes for field storage\n# =========================\n\nclass MiniFieldStorage:\n\n    """Like FieldStorage, for use when no file uploads are possible."""\n\n    # Dummy attributes\n    filename = None\n    list = None\n    type = None\n    file = None\n    type_options = {}\n    disposition = None\n    disposition_options = {}\n    headers = {}\n\n    def __init__(self, name, value):\n        """Constructor from field name and value."""\n        self.name = name\n        self.value = value\n        # self.file = StringIO(value)\n\n    def __repr__(self):\n        """Return printable representation."""\n        return "MiniFieldStorage(%r, %r)" % (self.name, self.value)\n\n\nclass FieldStorage:\n\n    """Store a sequence of fields, reading multipart/form-data.\n\n    This class provides naming, typing, files stored on disk, and\n    more.  At the top level, it is accessible like a dictionary, whose\n    keys are the field names.  (Note: None can occur as a field name.)\n    The items are either a Python list (if there\'s multiple values) or\n    another FieldStorage or MiniFieldStorage object.  If it\'s a single\n    object, it has the following attributes:\n\n    name: the field name, if specified; otherwise None\n\n    filename: the filename, if specified; otherwise None; this is the\n        client side filename, *not* the file name on which it is\n        stored (that\'s a temporary file you don\'t deal with)\n\n    value: the value as a *string*; for file uploads, this\n        transparently reads the file every time you request the value\n\n    file: the file(-like) object from which you can read the data;\n        None if the data is stored a simple string\n\n    type: the content-type, or None if not specified\n\n    type_options: dictionary of options specified on the content-type\n        line\n\n    disposition: content-disposition, or None if not specified\n\n    disposition_options: dictionary of corresponding options\n\n    headers: a dictionary(-like) object (sometimes rfc822.Message or a\n        subclass thereof) containing *all* headers\n\n    The class is subclassable, mostly for the purpose of overriding\n    the make_file() method, which is called internally to come up with\n    a file open for reading and writing.  This makes it possible to\n    override the default choice of storing all files in a temporary\n    directory and unlinking them as soon as they have been opened.\n\n    """\n\n    def __init__(self, fp=None, headers=None, outerboundary="",\n                 environ=os.environ, keep_blank_values=0, strict_parsing=0):\n        """Constructor.  Read multipart/* until last part.\n\n        Arguments, all optional:\n\n        fp              : file pointer; default: sys.stdin\n            (not used when the request method is GET)\n\n        headers         : header dictionary-like object; default:\n            taken from environ as per CGI spec\n\n        outerboundary   : terminating multipart boundary\n            (for internal use only)\n\n        environ         : environment dictionary; default: os.environ\n\n        keep_blank_values: flag indicating whether blank values in\n            percent-encoded forms should be treated as blank strings.\n            A true value indicates that blanks should be retained as\n            blank strings.  The default false value indicates that\n            blank values are to be ignored and treated as if they were\n            not included.\n\n        strict_parsing: flag indicating what to do with parsing errors.\n            If false (the default), errors are silently ignored.\n            If true, errors raise a ValueError exception.\n\n        """\n        method = \'GET\'\n        self.keep_blank_values = keep_blank_values\n        self.strict_parsing = strict_parsing\n        if \'REQUEST_METHOD\' in environ:\n            method = environ[\'REQUEST_METHOD\'].upper()\n        self.qs_on_post = None\n        if method == \'GET\' or method == \'HEAD\':\n            if \'QUERY_STRING\' in environ:\n                qs = environ[\'QUERY_STRING\']\n            elif sys.argv[1:]:\n                qs = sys.argv[1]\n            else:\n                qs = ""\n            fp = StringIO(qs)\n            if headers is None:\n                headers = {\'content-type\':\n                           "application/x-www-form-urlencoded"}\n        if headers is None:\n            headers = {}\n            if method == \'POST\':\n                # Set default content-type for POST to what\'s traditional\n                headers[\'content-type\'] = "application/x-www-form-urlencoded"\n            if \'CONTENT_TYPE\' in environ:\n                headers[\'content-type\'] = environ[\'CONTENT_TYPE\']\n            if \'QUERY_STRING\' in environ:\n                self.qs_on_post = environ[\'QUERY_STRING\']\n            if \'CONTENT_LENGTH\' in environ:\n                headers[\'content-length\'] = environ[\'CONTENT_LENGTH\']\n        self.fp = fp or sys.stdin\n        self.headers = headers\n        self.outerboundary = outerboundary\n\n        # Process content-disposition header\n        cdisp, pdict = "", {}\n        if \'content-disposition\' in self.headers:\n            cdisp, pdict = parse_header(self.headers[\'content-disposition\'])\n        self.disposition = cdisp\n        self.disposition_options = pdict\n        self.name = None\n        if \'name\' in pdict:\n            self.name = pdict[\'name\']\n        self.filename = None\n        if \'filename\' in pdict:\n            self.filename = pdict[\'filename\']\n\n        # Process content-type header\n        #\n        # Honor any existing content-type header.  But if there is no\n        # content-type header, use some sensible defaults.  Assume\n        # outerboundary is "" at the outer level, but something non-false\n        # inside a multi-part.  The default for an inner part is text/plain,\n        # but for an outer part it should be urlencoded.  This should catch\n        # bogus clients which erroneously forget to include a content-type\n        # header.\n        #\n        # See below for what we do if there does exist a content-type header,\n        # but it happens to be something we don\'t understand.\n        if \'content-type\' in self.headers:\n            ctype, pdict = parse_header(self.headers[\'content-type\'])\n        elif self.outerboundary or method != \'POST\':\n            ctype, pdict = "text/plain", {}\n        else:\n            ctype, pdict = \'application/x-www-form-urlencoded\', {}\n        self.type = ctype\n        self.type_options = pdict\n        self.innerboundary = ""\n        if \'boundary\' in pdict:\n            self.innerboundary = pdict[\'boundary\']\n        clen = -1\n        if \'content-length\' in self.headers:\n            try:\n                clen = int(self.headers[\'content-length\'])\n            except ValueError:\n                pass\n            if maxlen and clen > maxlen:\n                raise ValueError, \'Maximum content length exceeded\'\n        self.length = clen\n\n        self.list = self.file = None\n        self.done = 0\n        if ctype == \'application/x-www-form-urlencoded\':\n            self.read_urlencoded()\n        elif ctype[:10] == \'multipart/\':\n            self.read_multi(environ, keep_blank_values, strict_parsing)\n        else:\n            self.read_single()\n\n    def __repr__(self):\n        """Return a printable representation."""\n        return "FieldStorage(%r, %r, %r)" % (\n                self.name, self.filename, self.value)\n\n    def __iter__(self):\n        return iter(self.keys())\n\n    def __getattr__(self, name):\n        if name != \'value\':\n            raise AttributeError, name\n        if self.file:\n            self.file.seek(0)\n            value = self.file.read()\n            self.file.seek(0)\n        elif self.list is not None:\n            value = self.list\n        else:\n            value = None\n        return value\n\n    def __getitem__(self, key):\n        """Dictionary style indexing."""\n        if self.list is None:\n            raise TypeError, "not indexable"\n        found = []\n        for item in self.list:\n            if item.name == key: found.append(item)\n        if not found:\n            raise KeyError, key\n        if len(found) == 1:\n            return found[0]\n        else:\n            return found\n\n    def getvalue(self, key, default=None):\n        """Dictionary style get() method, including \'value\' lookup."""\n        if key in self:\n            value = self[key]\n            if type(value) is type([]):\n                return map(attrgetter(\'value\'), value)\n            else:\n                return value.value\n        else:\n            return default\n\n    def getfirst(self, key, default=None):\n        """ Return the first value received."""\n        if key in self:\n            value = self[key]\n            if type(value) is type([]):\n                return value[0].value\n            else:\n                return value.value\n        else:\n            return default\n\n    def getlist(self, key):\n        """ Return list of received values."""\n        if key in self:\n            value = self[key]\n            if type(value) is type([]):\n                return map(attrgetter(\'value\'), value)\n            else:\n                return [value.value]\n        else:\n            return []\n\n    def keys(self):\n        """Dictionary style keys() method."""\n        if self.list is None:\n            raise TypeError, "not indexable"\n        return list(set(item.name for item in self.list))\n\n    def has_key(self, key):\n        """Dictionary style has_key() method."""\n        if self.list is None:\n            raise TypeError, "not indexable"\n        return any(item.name == key for item in self.list)\n\n    def __contains__(self, key):\n        """Dictionary style __contains__ method."""\n        if self.list is None:\n            raise TypeError, "not indexable"\n        return any(item.name == key for item in self.list)\n\n    def __len__(self):\n        """Dictionary style len(x) support."""\n        return len(self.keys())\n\n    def __nonzero__(self):\n        return bool(self.list)\n\n    def read_urlencoded(self):\n        """Internal: read data in query string format."""\n        qs = self.fp.read(self.length)\n        if self.qs_on_post:\n            qs += \'&\' + self.qs_on_post\n        self.list = list = []\n        for key, value in urlparse.parse_qsl(qs, self.keep_blank_values,\n                                            self.strict_parsing):\n            list.append(MiniFieldStorage(key, value))\n        self.skip_lines()\n\n    FieldStorageClass = None\n\n    def read_multi(self, environ, keep_blank_values, strict_parsing):\n        """Internal: read a part that is itself multipart."""\n        ib = self.innerboundary\n        if not valid_boundary(ib):\n            raise ValueError, \'Invalid boundary in multipart form: %r\' % (ib,)\n        self.list = []\n        if self.qs_on_post:\n            for key, value in urlparse.parse_qsl(self.qs_on_post,\n                                self.keep_blank_values, self.strict_parsing):\n                self.list.append(MiniFieldStorage(key, value))\n            FieldStorageClass = None\n\n        klass = self.FieldStorageClass or self.__class__\n        part = klass(self.fp, {}, ib,\n                     environ, keep_blank_values, strict_parsing)\n        # Throw first part away\n        while not part.done:\n            headers = rfc822.Message(self.fp)\n            part = klass(self.fp, headers, ib,\n                         environ, keep_blank_values, strict_parsing)\n            self.list.append(part)\n        self.skip_lines()\n\n    def read_single(self):\n        """Internal: read an atomic part."""\n        if self.length >= 0:\n            self.read_binary()\n            self.skip_lines()\n        else:\n            self.read_lines()\n        self.file.seek(0)\n\n    bufsize = 8*1024            # I/O buffering size for copy to file\n\n    def read_binary(self):\n        """Internal: read binary data."""\n        self.file = self.make_file(\'b\')\n        todo = self.length\n        if todo >= 0:\n            while todo > 0:\n                data = self.fp.read(min(todo, self.bufsize))\n                if not data:\n                    self.done = -1\n                    break\n                self.file.write(data)\n                todo = todo - len(data)\n\n    def read_lines(self):\n        """Internal: read lines until EOF or outerboundary."""\n        self.file = self.__file = StringIO()\n        if self.outerboundary:\n            self.read_lines_to_outerboundary()\n        else:\n            self.read_lines_to_eof()\n\n    def __write(self, line):\n        if self.__file is not None:\n            if self.__file.tell() + len(line) > 1000:\n                self.file = self.make_file(\'\')\n                self.file.write(self.__file.getvalue())\n                self.__file = None\n        self.file.write(line)\n\n    def read_lines_to_eof(self):\n        """Internal: read lines until EOF."""\n        while 1:\n            line = self.fp.readline(1<<16)\n            if not line:\n                self.done = -1\n                break\n            self.__write(line)\n\n    def read_lines_to_outerboundary(self):\n        """Internal: read lines until outerboundary."""\n        next = "--" + self.outerboundary\n        last = next + "--"\n        delim = ""\n        last_line_lfend = True\n        while 1:\n            line = self.fp.readline(1<<16)\n            if not line:\n                self.done = -1\n                break\n            if line[:2] == "--" and last_line_lfend:\n                strippedline = line.strip()\n                if strippedline == next:\n                    break\n                if strippedline == last:\n                    self.done = 1\n                    break\n            odelim = delim\n            if line[-2:] == "\\r\\n":\n                delim = "\\r\\n"\n                line = line[:-2]\n                last_line_lfend = True\n            elif line[-1] == "\\n":\n                delim = "\\n"\n                line = line[:-1]\n                last_line_lfend = True\n            else:\n                delim = ""\n                last_line_lfend = False\n            self.__write(odelim + line)\n\n    def skip_lines(self):\n        """Internal: skip lines until outer boundary if defined."""\n        if not self.outerboundary or self.done:\n            return\n        next = "--" + self.outerboundary\n        last = next + "--"\n        last_line_lfend = True\n        while 1:\n            line = self.fp.readline(1<<16)\n            if not line:\n                self.done = -1\n                break\n            if line[:2] == "--" and last_line_lfend:\n                strippedline = line.strip()\n                if strippedline == next:\n                    break\n                if strippedline == last:\n                    self.done = 1\n                    break\n            last_line_lfend = line.endswith(\'\\n\')\n\n    def make_file(self, binary=None):\n        """Overridable: return a readable & writable file.\n\n        The file will be used as follows:\n        - data is written to it\n        - seek(0)\n        - data is read from it\n\n        The \'binary\' argument is unused -- the file is always opened\n        in binary mode.\n\n        This version opens a temporary file for reading and writing,\n        and immediately deletes (unlinks) it.  The trick (on Unix!) is\n        that the file can still be used, but it can\'t be opened by\n        another process, and it will automatically be deleted when it\n        is closed or when the current process terminates.\n\n        If you want a more permanent file, you derive a class which\n        overrides this method.  If you want a visible temporary file\n        that is nevertheless automatically deleted when the script\n        terminates, try defining a __del__ method in a derived class\n        which unlinks the temporary files you have created.\n\n        """\n        import tempfile\n        return tempfile.TemporaryFile("w+b")\n\n\n\n# Backwards Compatibility Classes\n# ===============================\n\nclass FormContentDict(UserDict.UserDict):\n    """Form content as dictionary with a list of values per field.\n\n    form = FormContentDict()\n\n    form[key] -> [value, value, ...]\n    key in form -> Boolean\n    form.keys() -> [key, key, ...]\n    form.values() -> [[val, val, ...], [val, val, ...], ...]\n    form.items() ->  [(key, [val, val, ...]), (key, [val, val, ...]), ...]\n    form.dict == {key: [val, val, ...], ...}\n\n    """\n    def __init__(self, environ=os.environ, keep_blank_values=0, strict_parsing=0):\n        self.dict = self.data = parse(environ=environ,\n                                      keep_blank_values=keep_blank_values,\n                                      strict_parsing=strict_parsing)\n        self.query_string = environ[\'QUERY_STRING\']\n\n\nclass SvFormContentDict(FormContentDict):\n    """Form content as dictionary expecting a single value per field.\n\n    If you only expect a single value for each field, then form[key]\n    will return that single value.  It will raise an IndexError if\n    that expectation is not true.  If you expect a field to have\n    possible multiple values, than you can use form.getlist(key) to\n    get all of the values.  values() and items() are a compromise:\n    they return single strings where there is a single value, and\n    lists of strings otherwise.\n\n    """\n    def __getitem__(self, key):\n        if len(self.dict[key]) > 1:\n            raise IndexError, \'expecting a single value\'\n        return self.dict[key][0]\n    def getlist(self, key):\n        return self.dict[key]\n    def values(self):\n        result = []\n        for value in self.dict.values():\n            if len(value) == 1:\n                result.append(value[0])\n            else: result.append(value)\n        return result\n    def items(self):\n        result = []\n        for key, value in self.dict.items():\n            if len(value) == 1:\n                result.append((key, value[0]))\n            else: result.append((key, value))\n        return result\n\n\nclass InterpFormContentDict(SvFormContentDict):\n    """This class is present for backwards compatibility only."""\n    def __getitem__(self, key):\n        v = SvFormContentDict.__getitem__(self, key)\n        if v[0] in \'0123456789+-.\':\n            try: return int(v)\n            except ValueError:\n                try: return float(v)\n                except ValueError: pass\n        return v.strip()\n    def values(self):\n        result = []\n        for key in self.keys():\n            try:\n                result.append(self[key])\n            except IndexError:\n                result.append(self.dict[key])\n        return result\n    def items(self):\n        result = []\n        for key in self.keys():\n            try:\n                result.append((key, self[key]))\n            except IndexError:\n                result.append((key, self.dict[key]))\n        return result\n\n\nclass FormContent(FormContentDict):\n    """This class is present for backwards compatibility only."""\n    def values(self, key):\n        if key in self.dict :return self.dict[key]\n        else: return None\n    def indexed_value(self, key, location):\n        if key in self.dict:\n            if len(self.dict[key]) > location:\n                return self.dict[key][location]\n            else: return None\n        else: return None\n    def value(self, key):\n        if key in self.dict: return self.dict[key][0]\n        else: return None\n    def length(self, key):\n        return len(self.dict[key])\n    def stripped(self, key):\n        if key in self.dict: return self.dict[key][0].strip()\n        else: return None\n    def pars(self):\n        return self.dict\n\n\n# Test/debug code\n# ===============\n\ndef test(environ=os.environ):\n    """Robust test CGI script, usable as main program.\n\n    Write minimal HTTP headers and dump all information provided to\n    the script in HTML form.\n\n    """\n    print "Content-type: text/html"\n    print\n    sys.stderr = sys.stdout\n    try:\n        form = FieldStorage()   # Replace with other classes to test those\n        print_directory()\n        print_arguments()\n        print_form(form)\n        print_environ(environ)\n        print_environ_usage()\n        def f():\n            exec "testing print_exception() -- <I>italics?</I>"\n        def g(f=f):\n            f()\n        print "<H3>What follows is a test, not an actual exception:</H3>"\n        g()\n    except:\n        print_exception()\n\n    print "<H1>Second try with a small maxlen...</H1>"\n\n    global maxlen\n    maxlen = 50\n    try:\n        form = FieldStorage()   # Replace with other classes to test those\n        print_directory()\n        print_arguments()\n        print_form(form)\n        print_environ(environ)\n    except:\n        print_exception()\n\ndef print_exception(type=None, value=None, tb=None, limit=None):\n    if type is None:\n        type, value, tb = sys.exc_info()\n    import traceback\n    print\n    print "<H3>Traceback (most recent call last):</H3>"\n    list = traceback.format_tb(tb, limit) + \\\n           traceback.format_exception_only(type, value)\n    print "<PRE>%s<B>%s</B></PRE>" % (\n        escape("".join(list[:-1])),\n        escape(list[-1]),\n        )\n    del tb\n\ndef print_environ(environ=os.environ):\n    """Dump the shell environment as HTML."""\n    keys = environ.keys()\n    keys.sort()\n    print\n    print "<H3>Shell Environment:</H3>"\n    print "<DL>"\n    for key in keys:\n        print "<DT>", escape(key), "<DD>", escape(environ[key])\n    print "</DL>"\n    print\n\ndef print_form(form):\n    """Dump the contents of a form as HTML."""\n    keys = form.keys()\n    keys.sort()\n    print\n    print "<H3>Form Contents:</H3>"\n    if not keys:\n        print "<P>No form fields."\n    print "<DL>"\n    for key in keys:\n        print "<DT>" + escape(key) + ":",\n        value = form[key]\n        print "<i>" + escape(repr(type(value))) + "</i>"\n        print "<DD>" + escape(repr(value))\n    print "</DL>"\n    print\n\ndef print_directory():\n    """Dump the current directory as HTML."""\n    print\n    print "<H3>Current Working Directory:</H3>"\n    try:\n        pwd = os.getcwd()\n    except os.error, msg:\n        print "os.error:", escape(str(msg))\n    else:\n        print escape(pwd)\n    print\n\ndef print_arguments():\n    print\n    print "<H3>Command Line Arguments:</H3>"\n    print\n    print sys.argv\n    print\n\ndef print_environ_usage():\n    """Dump a list of environment variables used by CGI as HTML."""\n    print """\n<H3>These environment variables could have been set:</H3>\n<UL>\n<LI>AUTH_TYPE\n<LI>CONTENT_LENGTH\n<LI>CONTENT_TYPE\n<LI>DATE_GMT\n<LI>DATE_LOCAL\n<LI>DOCUMENT_NAME\n<LI>DOCUMENT_ROOT\n<LI>DOCUMENT_URI\n<LI>GATEWAY_INTERFACE\n<LI>LAST_MODIFIED\n<LI>PATH\n<LI>PATH_INFO\n<LI>PATH_TRANSLATED\n<LI>QUERY_STRING\n<LI>REMOTE_ADDR\n<LI>REMOTE_HOST\n<LI>REMOTE_IDENT\n<LI>REMOTE_USER\n<LI>REQUEST_METHOD\n<LI>SCRIPT_NAME\n<LI>SERVER_NAME\n<LI>SERVER_PORT\n<LI>SERVER_PROTOCOL\n<LI>SERVER_ROOT\n<LI>SERVER_SOFTWARE\n</UL>\nIn addition, HTTP headers sent by the server may be passed in the\nenvironment as well.  Here are some common variable names:\n<UL>\n<LI>HTTP_ACCEPT\n<LI>HTTP_CONNECTION\n<LI>HTTP_HOST\n<LI>HTTP_PRAGMA\n<LI>HTTP_REFERER\n<LI>HTTP_USER_AGENT\n</UL>\n"""\n\n\n# Utilities\n# =========\n\ndef escape(s, quote=None):\n    \'\'\'Replace special characters "&", "<" and ">" to HTML-safe sequences.\n    If the optional flag quote is true, the quotation mark character (")\n    is also translated.\'\'\'\n    s = s.replace("&", "&amp;") # Must be done first!\n    s = s.replace("<", "&lt;")\n    s = s.replace(">", "&gt;")\n    if quote:\n        s = s.replace(\'"\', "&quot;")\n    return s\n\ndef valid_boundary(s, _vb_pattern="^[ -~]{0,200}[!-~]$"):\n    import re\n    return re.match(_vb_pattern, s)\n\n# Invoke mainline\n# ===============\n\n# Call test() when this file is run as a script (not imported as a module)\nif __name__ == \'__main__\':\n    test()\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'cgi.py', 9, '2012-07-06 13:59:18'),
	('c35f9bde444a432d9db99ef65edd1a27', '(.*)\\n",content)', 'a sublime text plugin of a share code library ', 'jamiesun', 'jamiesun.net@gmail.com', 'python,sublime text 2,python', '#!/usr/bin/python2.7 \n#coding:utf-8\nimport sublime,sublime_plugin\nimport re,os,sys,json\nimport urllib,urllib2\nimport logging\n\nreload(sys)\nsys.setdefaultencoding(\'utf-8\')\n\nlogger = logging.getLogger("talkincode")\nlogger.setLevel(logging.DEBUG)\nformatter = logging.Formatter(\'%(levelname)-8s %(message)s\', \'%a, %d %b %Y %H:%M:%S\',)\nconsole_handler = logging.StreamHandler(sys.stderr)\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n"""\n@description:a sublime text plugin of a share code library \n@tags:python,sublime text 2\n"""\nsettings = sublime.load_settings(\'ShareCodeLibrary.sublime-settings\')      \n\ndef post_code(params,url):\n    sublime.status_message("post request, please wait......")\n    try:\n        data = urllib.urlencode(params) \n        logger.info(data)\n        request = urllib2.Request(url, data)\n        response = urllib2.urlopen(request)    # This request is sent in HTTP POST\n        sublime.status_message("post response:%s"%response.read())\n    except Exception,e:\n        logger.info("error %s"%e)\n        raise\n\n\nclass ShareCurrentView(sublime_plugin.TextCommand):\n    def __init__(self,view):\n        self.view = view\n\n    def run(self, edit):\n        view = self.view\n        region = sublime.Region(0L, view.size())\n        filename = os.path.basename(view.file_name())\n        content = view.substr(region)\n        titlegrp = re.search("@description:(.*)\\n",content)\n        tagsgrp = re.search("@tags:(.*)\\n",content)\n        idgrp = re.search("        if not titlegrp:\n            sublime.status_message(r"your code source must contains @description:{some text} ")\n        else:\n            title = titlegrp.group(1)\n            tags = []\n            if tagsgrp:\n                tags.append(tagsgrp.group(1))\n            default_tags = settings.get("tags")\n            if default_tags:\n                tags.append(default_tags)\n\n            parentid = 0\n            if idgrp:\n                parentid = idgrp.group(1)\n\n\n\n            filename = view.file_name()\n            fext = os.path.splitext(filename)[1]\n            if len(fext) >1:\n                fext = fext[1:]\n\n            params = dict(pid=parentid,\n                title=title,\n                auther=settings.get("auther"),\n                email=settings.get("email"),\n                tagstr=",".join(tags),\n                content=re.sub("                lang=fext,\n                filename=os.path.basename(view.file_name()),\n                authkey=settings.get("authkey"))\n\n            post_code(params,settings.get("post_url"))\n\n\n\nclass ShareCodeQuery(sublime_plugin.WindowCommand):\n    def run(self):      \n        sublime.status_message("query code index, please wait......")\n        params = dict(index_limit=settings.get("index_limit"),authkey=settings.get("authkey"))\n        url = settings.get("index_url")\n        data = urllib.urlencode(params) \n        request = urllib2.Request("%s?%s"%(url,data))\n        response = urllib2.urlopen(request)   \n\n        try:\n            rstr = response.read()\n            result = json.loads(rstr)\n            if type(result) ==dict and result.has_key("error"):\n                sublime.status_message("error:%s"%result.get("error"))\n\n            format_it = lambda row: ["%s - %s"%(row["lang"],row["title"]),\n                                     "by @%s <%s> hits : %s"%(row["auther"],row["email"],row["hits"] )]\n            items = [format_it(row) for row in result]\n\n            def on_code_click(idx):\n                if idx == -1:\n                    return\n                uid = result[idx]["id"]\n                lang = result[idx]["lang"]\n                # rfile = result[idx].get("filename")\n                code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,lang)\n                # if rfile:\n                #     code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,rfile)\n\n                if not os.path.exists(code_file_path):\n                    get_url = settings.get("get_url")\n                    request = urllib2.Request("%s/%s"%(get_url,uid))\n                    response = urllib2.urlopen(request) \n                    get_json = json.loads(response.read())\n                    if type(get_json) ==dict and get_json.has_key("error"):\n                        sublime.status_message("error:%s"%get_json.get("error"))\n\n                    code_file = open(code_file_path,"wb")\n                    code_file.write("                    code_file.write(get_json[\'content\'])\n                    code_file.close()\n\n                code_view = self.window.open_file(code_file_path)\n                self.window.focus_view(code_view)\n\n            self.window.show_quick_panel(items,on_code_click)            \n        except Exception, e:\n            sublime.status_message("error:%s"%e)\n\n        \n\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'ShareCodeLibrary..py', 8, '2012-07-06 16:36:29'),
	('cc50e7ea4f764ffc96fe22733402bc4b', '(.*)\\n",content)', 'a sublime text plugin of a share code library ', 'jamiesun', 'jamiesun.net@gmail.com', 'python,sublime text 2,python', '#!/usr/bin/python2.7 \n#coding:utf-8\nimport sublime,sublime_plugin\nimport re,os,sys,json\nimport urllib,urllib2\nimport logging\n\nreload(sys)\nsys.setdefaultencoding(\'utf-8\')\n\nlogger = logging.getLogger("talkincode")\nlogger.setLevel(logging.DEBUG)\nformatter = logging.Formatter(\'%(levelname)-8s %(message)s\', \'%a, %d %b %Y %H:%M:%S\',)\nconsole_handler = logging.StreamHandler(sys.stderr)\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n"""\n@description:a sublime text plugin of a share code library \n@tags:python,sublime text 2\n"""\nsettings = sublime.load_settings(\'ShareCodeLibrary.sublime-settings\')      \n\ndef post_code(params,url):\n    sublime.status_message("post request, please wait......")\n    try:\n        data = urllib.urlencode(params) \n        logger.info(data)\n        request = urllib2.Request(url, data)\n        response = urllib2.urlopen(request)    # This request is sent in HTTP POST\n        sublime.status_message("post response:%s"%response.read())\n    except Exception,e:\n        logger.info("error %s"%e)\n        raise\n\n\nclass ShareCurrentView(sublime_plugin.TextCommand):\n    def __init__(self,view):\n        self.view = view\n\n    def run(self, edit):\n        view = self.view\n        region = sublime.Region(0L, view.size())\n        filename = os.path.basename(view.file_name())\n        content = view.substr(region)\n        titlegrp = re.search("@description:(.*)\\n",content)\n        tagsgrp = re.search("@tags:(.*)\\n",content)\n        idgrp = re.search("        if not titlegrp:\n            sublime.status_message(r"your code source must contains @description:{some text} ")\n        else:\n            title = titlegrp.group(1)\n            tags = []\n            if tagsgrp:\n                tags.append(tagsgrp.group(1))\n            default_tags = settings.get("tags")\n            if default_tags:\n                tags.append(default_tags)\n\n            parentid = 0\n            if idgrp:\n                parentid = idgrp.group(1)\n\n\n\n            filename = view.file_name()\n            fext = os.path.splitext(filename)[1]\n            if len(fext) >1:\n                fext = fext[1:]\n\n            params = dict(pid=parentid,\n                title=title,\n                auther=settings.get("auther"),\n                email=settings.get("email"),\n                tagstr=",".join(tags),\n                content=re.sub("                lang=fext,\n                filename=os.path.basename(view.file_name()),\n                authkey=settings.get("authkey"))\n\n            post_code(params,settings.get("post_url"))\n\n\n\nclass ShareCodeQuery(sublime_plugin.WindowCommand):\n    def run(self):      \n        sublime.status_message("query code index, please wait......")\n        params = dict(index_limit=settings.get("index_limit"),authkey=settings.get("authkey"))\n        url = settings.get("index_url")\n        data = urllib.urlencode(params) \n        request = urllib2.Request("%s?%s"%(url,data))\n        response = urllib2.urlopen(request)   \n\n        try:\n            rstr = response.read()\n            result = json.loads(rstr)\n            if type(result) ==dict and result.has_key("error"):\n                sublime.status_message("error:%s"%result.get("error"))\n\n            format_it = lambda row: ["%s - %s"%(row["lang"],row["title"]),\n                                     "by @%s <%s> hits : %s"%(row["auther"],row["email"],row["hits"] )]\n            items = [format_it(row) for row in result]\n\n            def on_code_click(idx):\n                if idx == -1:\n                    return\n                uid = result[idx]["id"]\n                lang = result[idx]["lang"]\n                # rfile = result[idx].get("filename")\n                code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,lang)\n                # if rfile:\n                #     code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,rfile)\n\n                if not os.path.exists(code_file_path):\n                    get_url = settings.get("get_url")\n                    request = urllib2.Request("%s/%s"%(get_url,uid))\n                    response = urllib2.urlopen(request) \n                    get_json = json.loads(response.read())\n                    if type(get_json) ==dict and get_json.has_key("error"):\n                        sublime.status_message("error:%s"%get_json.get("error"))\n\n                    code_file = open(code_file_path,"wb")\n                    code_file.write("                    code_file.write(get_json[\'content\'])\n                    code_file.close()\n\n                code_view = self.window.open_file(code_file_path)\n                self.window.focus_view(code_view)\n\n            self.window.show_quick_panel(items,on_code_click)            \n        except Exception, e:\n            sublime.status_message("error:%s"%e)\n\n        \n\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'ShareCodeLibrary..py', 12, '2012-07-06 16:35:59'),
	('d270f6ea886d4209a62b3c951946b3eb', '(.*)\\n",content)', 'a sublime text plugin of a share code library ', 'jamiesun', 'jamiesun.net@gmail.com', 'python,sublime text 2,python', '#!/usr/bin/python2.7 \n#coding:utf-8\nimport sublime,sublime_plugin\nimport re,os,sys,json\nimport urllib,urllib2\nimport logging\n\nreload(sys)\nsys.setdefaultencoding(\'utf-8\')\n\nlogger = logging.getLogger("talkincode")\nlogger.setLevel(logging.DEBUG)\nformatter = logging.Formatter(\'%(levelname)-8s %(message)s\', \'%a, %d %b %Y %H:%M:%S\',)\nconsole_handler = logging.StreamHandler(sys.stderr)\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n"""\n@description:a sublime text plugin of a share code library \n@tags:python,sublime text 2\n"""\nsettings = sublime.load_settings(\'ShareCodeLibrary.sublime-settings\')      \n\ndef post_code(params,url):\n    sublime.status_message("post request, please wait......")\n    try:\n        data = urllib.urlencode(params) \n        logger.info(data)\n        request = urllib2.Request(url, data)\n        response = urllib2.urlopen(request)    # This request is sent in HTTP POST\n        sublime.status_message("post response:%s"%response.read())\n    except Exception,e:\n        logger.info("error %s"%e)\n        raise\n\n\nclass ShareCurrentView(sublime_plugin.TextCommand):\n    def __init__(self,view):\n        self.view = view\n\n    def run(self, edit):\n        view = self.view\n        region = sublime.Region(0L, view.size())\n        filename = os.path.basename(view.file_name())\n        content = view.substr(region)\n        titlegrp = re.search("@description:(.*)\\n",content)\n        tagsgrp = re.search("@tags:(.*)\\n",content)\n        idgrp = re.search("        if not titlegrp:\n            sublime.status_message(r"your code source must contains @description:{some text} ")\n        else:\n            title = titlegrp.group(1)\n            tags = []\n            if tagsgrp:\n                tags.append(tagsgrp.group(1))\n            default_tags = settings.get("tags")\n            if default_tags:\n                tags.append(default_tags)\n\n            parentid = 0\n            if idgrp:\n                parentid = idgrp.group(1)\n\n\n\n            filename = view.file_name()\n            fext = os.path.splitext(filename)[1]\n            if len(fext) >1:\n                fext = fext[1:]\n\n            params = dict(pid=parentid,\n                title=title,\n                auther=settings.get("auther"),\n                email=settings.get("email"),\n                tagstr=",".join(tags),\n                content=re.sub("                lang=fext,\n                filename=os.path.basename(view.file_name()),\n                authkey=settings.get("authkey"))\n\n            post_code(params,settings.get("post_url"))\n\n\n\nclass ShareCodeQuery(sublime_plugin.WindowCommand):\n    def run(self):      \n        sublime.status_message("query code index, please wait......")\n        params = dict(index_limit=settings.get("index_limit"),authkey=settings.get("authkey"))\n        url = settings.get("index_url")\n        data = urllib.urlencode(params) \n        request = urllib2.Request("%s?%s"%(url,data))\n        response = urllib2.urlopen(request)   \n\n        try:\n            rstr = response.read()\n            result = json.loads(rstr)\n            if type(result) ==dict and result.has_key("error"):\n                sublime.status_message("error:%s"%result.get("error"))\n\n            format_it = lambda row: ["%s - %s"%(row["lang"],row["title"]),\n                                     "by @%s <%s> hits : %s"%(row["auther"],row["email"],row["hits"] )]\n            items = [format_it(row) for row in result]\n\n            def on_code_click(idx):\n                if idx == -1:\n                    return\n                uid = result[idx]["id"]\n                lang = result[idx]["lang"]\n                # rfile = result[idx].get("filename")\n                code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,lang)\n                # if rfile:\n                #     code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,rfile)\n\n                if not os.path.exists(code_file_path):\n                    get_url = settings.get("get_url")\n                    request = urllib2.Request("%s/%s"%(get_url,uid))\n                    response = urllib2.urlopen(request) \n                    get_json = json.loads(response.read())\n                    if type(get_json) ==dict and get_json.has_key("error"):\n                        sublime.status_message("error:%s"%get_json.get("error"))\n\n                    code_file = open(code_file_path,"wb")\n                    code_file.write("                    code_file.write(get_json[\'content\'])\n                    code_file.close()\n\n                code_view = self.window.open_file(code_file_path)\n                self.window.focus_view(code_view)\n\n            self.window.show_quick_panel(items,on_code_click)            \n        except Exception, e:\n            sublime.status_message("error:%s"%e)\n\n        \n\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'ShareCodeLibrary..py', 63, '2012-07-06 16:36:30'),
	('e9bd1956828140f1a542477b87067440', NULL, 'a sublime text plugin of a share code library ', 'jamiesun', 'jamiesun.net@gmail.com', 'python', '#!/usr/bin/python2.7 \n#coding:utf-8\nimport sublime,sublime_plugin\nimport re,os,sys,json\nimport urllib,urllib2\nimport logging\n\nreload(sys)\nsys.setdefaultencoding(\'utf-8\')\n\nlogger = logging.getLogger("talkincode")\nlogger.setLevel(logging.DEBUG)\nformatter = logging.Formatter(\'%(levelname)-8s %(message)s\', \'%a, %d %b %Y %H:%M:%S\',)\nconsole_handler = logging.StreamHandler(sys.stderr)\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n"""\n@description:a sublime text plugin of a share code library \n@tags:python,sublime text 2\n"""\nsettings = sublime.load_settings(\'ShareCodeLibrary.sublime-settings\')      \n\ndef post_code(params,url):\n    sublime.status_message("post request, please wait......")\n    try:\n        data = urllib.urlencode(params) \n        logger.info(data)\n        request = urllib2.Request(url, data)\n        response = urllib2.urlopen(request)    # This request is sent in HTTP POST\n        sublime.status_message("post response:%s"%response.read())\n    except Exception,e:\n        logger.info("error %s"%e)\n        raise\n\n\nclass ShareCurrentView(sublime_plugin.TextCommand):\n    def __init__(self,view):\n        self.view = view\n\n    def run(self, edit):\n        view = self.view\n        region = sublime.Region(0L, view.size())\n        filename = os.path.basename(view.file_name())\n        content = view.substr(region)\n        titlegrp = re.search("@description:(.*)\\n",content)\n        tagsgrp = re.search("@tags:(.*)\\r\\n",content)\n        if not titlegrp:\n            sublime.status_message(r"your code source must contains @description:{some text} ")\n        else:\n            title = titlegrp.group(1)\n            tags = []\n            if tagsgrp:\n                tags.append(tagsgrp.group(1))\n            default_tags = settings.get("tags")\n            if default_tags:\n                tags.append(default_tags)\n\n            filename = view.file_name()\n            fext = os.path.splitext(filename)[1]\n            if len(fext) >1:\n                fext = fext[1:]\n\n            params = dict(title=title,\n                auther=settings.get("auther"),\n                email=settings.get("email"),\n                tagstr=",".join(tags),\n                content=content,\n                lang=fext,\n                filename=os.path.basename(view.file_name()),\n                authkey=settings.get("authkey"))\n\n            post_code(params,settings.get("post_url"))\n\n\n\nclass ShareCodeQuery(sublime_plugin.WindowCommand):\n    def run(self):      \n        sublime.status_message("query code index, please wait......")\n        params = dict(index_limit=settings.get("index_limit"),authkey=settings.get("authkey"))\n        url = settings.get("index_url")\n        data = urllib.urlencode(params) \n        request = urllib2.Request("%s?%s"%(url,data))\n        response = urllib2.urlopen(request)   \n\n        try:\n            rstr = response.read()\n            result = json.loads(rstr)\n            if type(result) ==dict and result.has_key("error"):\n                sublime.status_message("error:%s"%result.get("error"))\n\n            format_it = lambda row: ["%s - %s"%(row["lang"],row["title"]),\n                                     "by @%s <%s> hits : %s"%(row["auther"],row["email"],row["hits"] )]\n            items = [format_it(row) for row in result]\n\n            def on_code_click(idx):\n                if idx == -1:\n                    return\n                uid = result[idx]["id"]\n                lang = result[idx]["lang"]\n                rfile = result[idx].get("filename")\n                code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,lang)\n                if rfile:\n                    code_file_path = "%s/%s"%(os.environ["TMP"],rfile)\n\n                if not os.path.exists(code_file_path):\n                    get_url = settings.get("get_url")\n                    request = urllib2.Request("%s/%s"%(get_url,uid))\n                    response = urllib2.urlopen(request) \n                    get_json = json.loads(response.read())\n                    if type(get_json) ==dict and get_json.has_key("error"):\n                        sublime.status_message("error:%s"%get_json.get("error"))\n\n                    code_file = open(code_file_path,"wb")\n                    code_file.write(get_json[\'content\'])\n                    code_file.close()\n\n                code_view = self.window.open_file(code_file_path)\n                self.window.focus_view(code_view)\n\n            self.window.show_quick_panel(items,on_code_click)            \n        except Exception, e:\n            sublime.status_message("error:%s"%e)\n\n        \n\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'ShareCodeLibrary..py', 8, '2012-07-06 13:47:44'),
	('fa5cb029cf274a6b871729eae4b6e429', '(.*)\\n",content)', 'a sublime text plugin of a share code library ', 'jamiesun', 'jamiesun.net@gmail.com', 'python,sublime text 2,python', '#!/usr/bin/python2.7 \n#coding:utf-8\nimport sublime,sublime_plugin\nimport re,os,sys,json\nimport urllib,urllib2\nimport logging\n\nreload(sys)\nsys.setdefaultencoding(\'utf-8\')\n\nlogger = logging.getLogger("talkincode")\nlogger.setLevel(logging.DEBUG)\nformatter = logging.Formatter(\'%(levelname)-8s %(message)s\', \'%a, %d %b %Y %H:%M:%S\',)\nconsole_handler = logging.StreamHandler(sys.stderr)\nconsole_handler.setFormatter(formatter)\nlogger.addHandler(console_handler)\n\n"""\n@description:a sublime text plugin of a share code library \n@tags:python,sublime text 2\n"""\nsettings = sublime.load_settings(\'ShareCodeLibrary.sublime-settings\')      \n\ndef post_code(params,url):\n    sublime.status_message("post request, please wait......")\n    try:\n        data = urllib.urlencode(params) \n        logger.info(data)\n        request = urllib2.Request(url, data)\n        response = urllib2.urlopen(request)    # This request is sent in HTTP POST\n        sublime.status_message("post response:%s"%response.read())\n    except Exception,e:\n        logger.info("error %s"%e)\n        raise\n\n\nclass ShareCurrentView(sublime_plugin.TextCommand):\n    def __init__(self,view):\n        self.view = view\n\n    def run(self, edit):\n        view = self.view\n        region = sublime.Region(0L, view.size())\n        filename = os.path.basename(view.file_name())\n        content = view.substr(region)\n        titlegrp = re.search("@description:(.*)\\n",content)\n        tagsgrp = re.search("@tags:(.*)\\n",content)\n        idgrp = re.search("        if not titlegrp:\n            sublime.status_message(r"your code source must contains @description:{some text} ")\n        else:\n            title = titlegrp.group(1)\n            tags = []\n            if tagsgrp:\n                tags.append(tagsgrp.group(1))\n            default_tags = settings.get("tags")\n            if default_tags:\n                tags.append(default_tags)\n\n            parentid = 0\n            if idgrp:\n                parentid = idgrp.group(1)\n\n\n\n            filename = view.file_name()\n            fext = os.path.splitext(filename)[1]\n            if len(fext) >1:\n                fext = fext[1:]\n\n            params = dict(pid=parentid,\n                title=title,\n                auther=settings.get("auther"),\n                email=settings.get("email"),\n                tagstr=",".join(tags),\n                content=re.sub("                lang=fext,\n                filename=os.path.basename(view.file_name()),\n                authkey=settings.get("authkey"))\n\n            post_code(params,settings.get("post_url"))\n\n\n\nclass ShareCodeQuery(sublime_plugin.WindowCommand):\n    def run(self):      \n        sublime.status_message("query code index, please wait......")\n        params = dict(index_limit=settings.get("index_limit"),authkey=settings.get("authkey"))\n        url = settings.get("index_url")\n        data = urllib.urlencode(params) \n        request = urllib2.Request("%s?%s"%(url,data))\n        response = urllib2.urlopen(request)   \n\n        try:\n            rstr = response.read()\n            result = json.loads(rstr)\n            if type(result) ==dict and result.has_key("error"):\n                sublime.status_message("error:%s"%result.get("error"))\n\n            format_it = lambda row: ["%s - %s"%(row["lang"],row["title"]),\n                                     "by @%s <%s> hits : %s"%(row["auther"],row["email"],row["hits"] )]\n            items = [format_it(row) for row in result]\n\n            def on_code_click(idx):\n                if idx == -1:\n                    return\n                uid = result[idx]["id"]\n                lang = result[idx]["lang"]\n                # rfile = result[idx].get("filename")\n                code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,lang)\n                # if rfile:\n                #     code_file_path = "%s/%s.%s"%(os.environ["TMP"],uid,rfile)\n\n                if not os.path.exists(code_file_path):\n                    get_url = settings.get("get_url")\n                    request = urllib2.Request("%s/%s"%(get_url,uid))\n                    response = urllib2.urlopen(request) \n                    get_json = json.loads(response.read())\n                    if type(get_json) ==dict and get_json.has_key("error"):\n                        sublime.status_message("error:%s"%get_json.get("error"))\n\n                    code_file = open(code_file_path,"wb")\n                    code_file.write("                    code_file.write(get_json[\'content\'])\n                    code_file.close()\n\n                code_view = self.window.open_file(code_file_path)\n                self.window.focus_view(code_view)\n\n            self.window.show_quick_panel(items,on_code_click)            \n        except Exception, e:\n            sublime.status_message("error:%s"%e)\n\n        \n\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'ShareCodeLibrary..py', 6, '2012-07-06 16:36:29'),
	('fcf60924630b4b1ab61000133279a158', NULL, 'python bdb module', 'jamiesun', 'jamiesun.net@gmail.com', 'bdb,python', '"""Debugger basics"""\n"""\n@description:python bdb module\n@tags:bdb\n"""\nimport fnmatch\nimport sys\nimport os\nimport types\n\n__all__ = ["BdbQuit","Bdb","Breakpoint"]\n\nclass BdbQuit(Exception):\n    """Exception to give up completely"""\n\n\nclass Bdb:\n\n    """Generic Python debugger base class.\n\n    This class takes care of details of the trace facility;\n    a derived class should implement user interaction.\n    The standard debugger class (pdb.Pdb) is an example.\n    """\n\n    def __init__(self, skip=None):\n        self.skip = set(skip) if skip else None\n        self.breaks = {}\n        self.fncache = {}\n\n    def canonic(self, filename):\n        if filename == "<" + filename[1:-1] + ">":\n            return filename\n        canonic = self.fncache.get(filename)\n        if not canonic:\n            canonic = os.path.abspath(filename)\n            canonic = os.path.normcase(canonic)\n            self.fncache[filename] = canonic\n        return canonic\n\n    def reset(self):\n        import linecache\n        linecache.checkcache()\n        self.botframe = None\n        self._set_stopinfo(None, None)\n\n    def trace_dispatch(self, frame, event, arg):\n        if self.quitting:\n            return # None\n        if event == \'line\':\n            return self.dispatch_line(frame)\n        if event == \'call\':\n            return self.dispatch_call(frame, arg)\n        if event == \'return\':\n            return self.dispatch_return(frame, arg)\n        if event == \'exception\':\n            return self.dispatch_exception(frame, arg)\n        if event == \'c_call\':\n            return self.trace_dispatch\n        if event == \'c_exception\':\n            return self.trace_dispatch\n        if event == \'c_return\':\n            return self.trace_dispatch\n        print \'bdb.Bdb.dispatch: unknown debugging event:\', repr(event)\n        return self.trace_dispatch\n\n    def dispatch_line(self, frame):\n        if self.stop_here(frame) or self.break_here(frame):\n            self.user_line(frame)\n            if self.quitting: raise BdbQuit\n        return self.trace_dispatch\n\n    def dispatch_call(self, frame, arg):\n        # XXX \'arg\' is no longer used\n        if self.botframe is None:\n            # First call of dispatch since reset()\n            self.botframe = frame.f_back # (CT) Note that this may also be None!\n            return self.trace_dispatch\n        if not (self.stop_here(frame) or self.break_anywhere(frame)):\n            # No need to trace this function\n            return # None\n        self.user_call(frame, arg)\n        if self.quitting: raise BdbQuit\n        return self.trace_dispatch\n\n    def dispatch_return(self, frame, arg):\n        if self.stop_here(frame) or frame == self.returnframe:\n            self.user_return(frame, arg)\n            if self.quitting: raise BdbQuit\n        return self.trace_dispatch\n\n    def dispatch_exception(self, frame, arg):\n        if self.stop_here(frame):\n            self.user_exception(frame, arg)\n            if self.quitting: raise BdbQuit\n        return self.trace_dispatch\n\n    # Normally derived classes don\'t override the following\n    # methods, but they may if they want to redefine the\n    # definition of stopping and breakpoints.\n\n    def is_skipped_module(self, module_name):\n        for pattern in self.skip:\n            if fnmatch.fnmatch(module_name, pattern):\n                return True\n        return False\n\n    def stop_here(self, frame):\n        # (CT) stopframe may now also be None, see dispatch_call.\n        # (CT) the former test for None is therefore removed from here.\n        if self.skip and \\\n               self.is_skipped_module(frame.f_globals.get(\'__name__\')):\n            return False\n        if frame is self.stopframe:\n            if self.stoplineno == -1:\n                return False\n            return frame.f_lineno >= self.stoplineno\n        while frame is not None and frame is not self.stopframe:\n            if frame is self.botframe:\n                return True\n            frame = frame.f_back\n        return False\n\n    def break_here(self, frame):\n        filename = self.canonic(frame.f_code.co_filename)\n        if not filename in self.breaks:\n            return False\n        lineno = frame.f_lineno\n        if not lineno in self.breaks[filename]:\n            # The line itself has no breakpoint, but maybe the line is the\n            # first line of a function with breakpoint set by function name.\n            lineno = frame.f_code.co_firstlineno\n            if not lineno in self.breaks[filename]:\n                return False\n\n        # flag says ok to delete temp. bp\n        (bp, flag) = effective(filename, lineno, frame)\n        if bp:\n            self.currentbp = bp.number\n            if (flag and bp.temporary):\n                self.do_clear(str(bp.number))\n            return True\n        else:\n            return False\n\n    def do_clear(self, arg):\n        raise NotImplementedError, "subclass of bdb must implement do_clear()"\n\n    def break_anywhere(self, frame):\n        return self.canonic(frame.f_code.co_filename) in self.breaks\n\n    # Derived classes should override the user_* methods\n    # to gain control.\n\n    def user_call(self, frame, argument_list):\n        """This method is called when there is the remote possibility\n        that we ever need to stop in this function."""\n        pass\n\n    def user_line(self, frame):\n        """This method is called when we stop or break at this line."""\n        pass\n\n    def user_return(self, frame, return_value):\n        """This method is called when a return trap is set here."""\n        pass\n\n    def user_exception(self, frame, exc_info):\n        exc_type, exc_value, exc_traceback = exc_info\n        """This method is called if an exception occurs,\n        but only if we are to stop at or just below this level."""\n        pass\n\n    def _set_stopinfo(self, stopframe, returnframe, stoplineno=0):\n        self.stopframe = stopframe\n        self.returnframe = returnframe\n        self.quitting = 0\n        # stoplineno >= 0 means: stop at line >= the stoplineno\n        # stoplineno -1 means: don\'t stop at all\n        self.stoplineno = stoplineno\n\n    # Derived classes and clients can call the following methods\n    # to affect the stepping state.\n\n    def set_until(self, frame): #the name "until" is borrowed from gdb\n        """Stop when the line with the line no greater than the current one is\n        reached or when returning from current frame"""\n        self._set_stopinfo(frame, frame, frame.f_lineno+1)\n\n    def set_step(self):\n        """Stop after one line of code."""\n        self._set_stopinfo(None, None)\n\n    def set_next(self, frame):\n        """Stop on the next line in or below the given frame."""\n        self._set_stopinfo(frame, None)\n\n    def set_return(self, frame):\n        """Stop when returning from the given frame."""\n        self._set_stopinfo(frame.f_back, frame)\n\n    def set_trace(self, frame=None):\n        """Start debugging from `frame`.\n\n        If frame is not specified, debugging starts from caller\'s frame.\n        """\n        if frame is None:\n            frame = sys._getframe().f_back\n        self.reset()\n        while frame:\n            frame.f_trace = self.trace_dispatch\n            self.botframe = frame\n            frame = frame.f_back\n        self.set_step()\n        sys.settrace(self.trace_dispatch)\n\n    def set_continue(self):\n        # Don\'t stop except at breakpoints or when finished\n        self._set_stopinfo(self.botframe, None, -1)\n        if not self.breaks:\n            # no breakpoints; run without debugger overhead\n            sys.settrace(None)\n            frame = sys._getframe().f_back\n            while frame and frame is not self.botframe:\n                del frame.f_trace\n                frame = frame.f_back\n\n    def set_quit(self):\n        self.stopframe = self.botframe\n        self.returnframe = None\n        self.quitting = 1\n        sys.settrace(None)\n\n    # Derived classes and clients can call the following methods\n    # to manipulate breakpoints.  These methods return an\n    # error message is something went wrong, None if all is well.\n    # Set_break prints out the breakpoint line and file:lineno.\n    # Call self.get_*break*() to see the breakpoints or better\n    # for bp in Breakpoint.bpbynumber: if bp: bp.bpprint().\n\n    def set_break(self, filename, lineno, temporary=0, cond = None,\n                  funcname=None):\n        filename = self.canonic(filename)\n        import linecache # Import as late as possible\n        line = linecache.getline(filename, lineno)\n        if not line:\n            return \'Line %s:%d does not exist\' % (filename,\n                                   lineno)\n        if not filename in self.breaks:\n            self.breaks[filename] = []\n        list = self.breaks[filename]\n        if not lineno in list:\n            list.append(lineno)\n        bp = Breakpoint(filename, lineno, temporary, cond, funcname)\n\n    def _prune_breaks(self, filename, lineno):\n        if (filename, lineno) not in Breakpoint.bplist:\n            self.breaks[filename].remove(lineno)\n        if not self.breaks[filename]:\n            del self.breaks[filename]\n\n    def clear_break(self, filename, lineno):\n        filename = self.canonic(filename)\n        if not filename in self.breaks:\n            return \'There are no breakpoints in %s\' % filename\n        if lineno not in self.breaks[filename]:\n            return \'There is no breakpoint at %s:%d\' % (filename,\n                                    lineno)\n        # If there\'s only one bp in the list for that file,line\n        # pair, then remove the breaks entry\n        for bp in Breakpoint.bplist[filename, lineno][:]:\n            bp.deleteMe()\n        self._prune_breaks(filename, lineno)\n\n    def clear_bpbynumber(self, arg):\n        try:\n            number = int(arg)\n        except:\n            return \'Non-numeric breakpoint number (%s)\' % arg\n        try:\n            bp = Breakpoint.bpbynumber[number]\n        except IndexError:\n            return \'Breakpoint number (%d) out of range\' % number\n        if not bp:\n            return \'Breakpoint (%d) already deleted\' % number\n        bp.deleteMe()\n        self._prune_breaks(bp.file, bp.line)\n\n    def clear_all_file_breaks(self, filename):\n        filename = self.canonic(filename)\n        if not filename in self.breaks:\n            return \'There are no breakpoints in %s\' % filename\n        for line in self.breaks[filename]:\n            blist = Breakpoint.bplist[filename, line]\n            for bp in blist:\n                bp.deleteMe()\n        del self.breaks[filename]\n\n    def clear_all_breaks(self):\n        if not self.breaks:\n            return \'There are no breakpoints\'\n        for bp in Breakpoint.bpbynumber:\n            if bp:\n                bp.deleteMe()\n        self.breaks = {}\n\n    def get_break(self, filename, lineno):\n        filename = self.canonic(filename)\n        return filename in self.breaks and \\\n            lineno in self.breaks[filename]\n\n    def get_breaks(self, filename, lineno):\n        filename = self.canonic(filename)\n        return filename in self.breaks and \\\n            lineno in self.breaks[filename] and \\\n            Breakpoint.bplist[filename, lineno] or []\n\n    def get_file_breaks(self, filename):\n        filename = self.canonic(filename)\n        if filename in self.breaks:\n            return self.breaks[filename]\n        else:\n            return []\n\n    def get_all_breaks(self):\n        return self.breaks\n\n    # Derived classes and clients can call the following method\n    # to get a data structure representing a stack trace.\n\n    def get_stack(self, f, t):\n        stack = []\n        if t and t.tb_frame is f:\n            t = t.tb_next\n        while f is not None:\n            stack.append((f, f.f_lineno))\n            if f is self.botframe:\n                break\n            f = f.f_back\n        stack.reverse()\n        i = max(0, len(stack) - 1)\n        while t is not None:\n            stack.append((t.tb_frame, t.tb_lineno))\n            t = t.tb_next\n        if f is None:\n            i = max(0, len(stack) - 1)\n        return stack, i\n\n    #\n\n    def format_stack_entry(self, frame_lineno, lprefix=\': \'):\n        import linecache, repr\n        frame, lineno = frame_lineno\n        filename = self.canonic(frame.f_code.co_filename)\n        s = \'%s(%r)\' % (filename, lineno)\n        if frame.f_code.co_name:\n            s = s + frame.f_code.co_name\n        else:\n            s = s + "<lambda>"\n        if \'__args__\' in frame.f_locals:\n            args = frame.f_locals[\'__args__\']\n        else:\n            args = None\n        if args:\n            s = s + repr.repr(args)\n        else:\n            s = s + \'()\'\n        if \'__return__\' in frame.f_locals:\n            rv = frame.f_locals[\'__return__\']\n            s = s + \'->\'\n            s = s + repr.repr(rv)\n        line = linecache.getline(filename, lineno, frame.f_globals)\n        if line: s = s + lprefix + line.strip()\n        return s\n\n    # The following two methods can be called by clients to use\n    # a debugger to debug a statement, given as a string.\n\n    def run(self, cmd, globals=None, locals=None):\n        if globals is None:\n            import __main__\n            globals = __main__.__dict__\n        if locals is None:\n            locals = globals\n        self.reset()\n        sys.settrace(self.trace_dispatch)\n        if not isinstance(cmd, types.CodeType):\n            cmd = cmd+\'\\n\'\n        try:\n            exec cmd in globals, locals\n        except BdbQuit:\n            pass\n        finally:\n            self.quitting = 1\n            sys.settrace(None)\n\n    def runeval(self, expr, globals=None, locals=None):\n        if globals is None:\n            import __main__\n            globals = __main__.__dict__\n        if locals is None:\n            locals = globals\n        self.reset()\n        sys.settrace(self.trace_dispatch)\n        if not isinstance(expr, types.CodeType):\n            expr = expr+\'\\n\'\n        try:\n            return eval(expr, globals, locals)\n        except BdbQuit:\n            pass\n        finally:\n            self.quitting = 1\n            sys.settrace(None)\n\n    def runctx(self, cmd, globals, locals):\n        # B/W compatibility\n        self.run(cmd, globals, locals)\n\n    # This method is more useful to debug a single function call.\n\n    def runcall(self, func, *args, **kwds):\n        self.reset()\n        sys.settrace(self.trace_dispatch)\n        res = None\n        try:\n            res = func(*args, **kwds)\n        except BdbQuit:\n            pass\n        finally:\n            self.quitting = 1\n            sys.settrace(None)\n        return res\n\n\ndef set_trace():\n    Bdb().set_trace()\n\n\nclass Breakpoint:\n\n    """Breakpoint class\n\n    Implements temporary breakpoints, ignore counts, disabling and\n    (re)-enabling, and conditionals.\n\n    Breakpoints are indexed by number through bpbynumber and by\n    the file,line tuple using bplist.  The former points to a\n    single instance of class Breakpoint.  The latter points to a\n    list of such instances since there may be more than one\n    breakpoint per line.\n\n    """\n\n    # XXX Keeping state in the class is a mistake -- this means\n    # you cannot have more than one active Bdb instance.\n\n    next = 1        # Next bp to be assigned\n    bplist = {}     # indexed by (file, lineno) tuple\n    bpbynumber = [None] # Each entry is None or an instance of Bpt\n                # index 0 is unused, except for marking an\n                # effective break .... see effective()\n\n    def __init__(self, file, line, temporary=0, cond=None, funcname=None):\n        self.funcname = funcname\n        # Needed if funcname is not None.\n        self.func_first_executable_line = None\n        self.file = file    # This better be in canonical form!\n        self.line = line\n        self.temporary = temporary\n        self.cond = cond\n        self.enabled = 1\n        self.ignore = 0\n        self.hits = 0\n        self.number = Breakpoint.next\n        Breakpoint.next = Breakpoint.next + 1\n        # Build the two lists\n        self.bpbynumber.append(self)\n        if (file, line) in self.bplist:\n            self.bplist[file, line].append(self)\n        else:\n            self.bplist[file, line] = [self]\n\n\n    def deleteMe(self):\n        index = (self.file, self.line)\n        self.bpbynumber[self.number] = None   # No longer in list\n        self.bplist[index].remove(self)\n        if not self.bplist[index]:\n            # No more bp for this f:l combo\n            del self.bplist[index]\n\n    def enable(self):\n        self.enabled = 1\n\n    def disable(self):\n        self.enabled = 0\n\n    def bpprint(self, out=None):\n        if out is None:\n            out = sys.stdout\n        if self.temporary:\n            disp = \'del  \'\n        else:\n            disp = \'keep \'\n        if self.enabled:\n            disp = disp + \'yes  \'\n        else:\n            disp = disp + \'no   \'\n        print >>out, \'%-4dbreakpoint   %s at %s:%d\' % (self.number, disp,\n                                                       self.file, self.line)\n        if self.cond:\n            print >>out, \'\\tstop only if %s\' % (self.cond,)\n        if self.ignore:\n            print >>out, \'\\tignore next %d hits\' % (self.ignore)\n        if (self.hits):\n            if (self.hits > 1): ss = \'s\'\n            else: ss = \'\'\n            print >>out, (\'\\tbreakpoint already hit %d time%s\' %\n                          (self.hits, ss))\n\n# -----------end of Breakpoint class----------\n\ndef checkfuncname(b, frame):\n    """Check whether we should break here because of `b.funcname`."""\n    if not b.funcname:\n        # Breakpoint was set via line number.\n        if b.line != frame.f_lineno:\n            # Breakpoint was set at a line with a def statement and the function\n            # defined is called: don\'t break.\n            return False\n        return True\n\n    # Breakpoint set via function name.\n\n    if frame.f_code.co_name != b.funcname:\n        # It\'s not a function call, but rather execution of def statement.\n        return False\n\n    # We are in the right frame.\n    if not b.func_first_executable_line:\n        # The function is entered for the 1st time.\n        b.func_first_executable_line = frame.f_lineno\n\n    if  b.func_first_executable_line != frame.f_lineno:\n        # But we are not at the first line number: don\'t break.\n        return False\n    return True\n\n# Determines if there is an effective (active) breakpoint at this\n# line of code.  Returns breakpoint number or 0 if none\ndef effective(file, line, frame):\n    """Determine which breakpoint for this file:line is to be acted upon.\n\n    Called only if we know there is a bpt at this\n    location.  Returns breakpoint that was triggered and a flag\n    that indicates if it is ok to delete a temporary bp.\n\n    """\n    possibles = Breakpoint.bplist[file,line]\n    for i in range(0, len(possibles)):\n        b = possibles[i]\n        if b.enabled == 0:\n            continue\n        if not checkfuncname(b, frame):\n            continue\n        # Count every hit when bp is enabled\n        b.hits = b.hits + 1\n        if not b.cond:\n            # If unconditional, and ignoring,\n            # go on to next, else break\n            if b.ignore > 0:\n                b.ignore = b.ignore -1\n                continue\n            else:\n                # breakpoint and marker that\'s ok\n                # to delete if temporary\n                return (b,1)\n        else:\n            # Conditional bp.\n            # Ignore count applies only to those bpt hits where the\n            # condition evaluates to true.\n            try:\n                val = eval(b.cond, frame.f_globals,\n                       frame.f_locals)\n                if val:\n                    if b.ignore > 0:\n                        b.ignore = b.ignore -1\n                        # continue\n                    else:\n                        return (b,1)\n                # else:\n                #   continue\n            except:\n                # if eval fails, most conservative\n                # thing is to stop on breakpoint\n                # regardless of ignore count.\n                # Don\'t delete temporary,\n                # as another hint to user.\n                return (b,0)\n    return (None, None)\n\n# -------------------- testing --------------------\n\nclass Tdb(Bdb):\n    def user_call(self, frame, args):\n        name = frame.f_code.co_name\n        if not name: name = \'???\'\n        print \'+++ call\', name, args\n    def user_line(self, frame):\n        import linecache\n        name = frame.f_code.co_name\n        if not name: name = \'???\'\n        fn = self.canonic(frame.f_code.co_filename)\n        line = linecache.getline(fn, frame.f_lineno, frame.f_globals)\n        print \'+++\', fn, frame.f_lineno, name, \':\', line.strip()\n    def user_return(self, frame, retval):\n        print \'+++ return\', retval\n    def user_exception(self, frame, exc_stuff):\n        print \'+++ exception\', exc_stuff\n        self.set_continue()\n\ndef foo(n):\n    print \'foo(\', n, \')\'\n    x = bar(n*10)\n    print \'bar returned\', x\n\ndef bar(a):\n    print \'bar(\', a, \')\'\n    return a/2\n\ndef test():\n    t = Tdb()\n    t.run(\'import bdb; bdb.foo(10)\')\n\n# end\n', '494ec9f9cbaf40cfa8d4b44447374d27', 'py', 'bdb.py', 4, '2012-07-06 13:58:31');
/*!40000 ALTER TABLE `codes` ENABLE KEYS */;


-- Dumping structure for table talkincode_db1.comments
DROP TABLE IF EXISTS `comments`;
CREATE TABLE IF NOT EXISTS `comments` (
  `id` varchar(32) NOT NULL,
  `postid` varchar(32) NOT NULL,
  `content` text NOT NULL,
  `author` varchar(64) DEFAULT NULL,
  `userid` varchar(32) DEFAULT NULL,
  `email` varchar(128) DEFAULT NULL,
  `url` varchar(128) DEFAULT NULL,
  `ip` varchar(128) DEFAULT NULL,
  `agent` varchar(128) DEFAULT NULL,
  `status` int(1) NOT NULL,
  `created` varchar(19) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- Dumping data for table talkincode_db1.comments: ~16 rows (approximately)
DELETE FROM `comments`;
/*!40000 ALTER TABLE `comments` DISABLE KEYS */;
INSERT INTO `comments` (`id`, `postid`, `content`, `author`, `userid`, `email`, `url`, `ip`, `agent`, `status`, `created`) VALUES
	('15bd73b94c0a409099e288a6286b15f3', 'd26d6219c98341fbbbce89d3d893242f', '移动指针到某一行.如果mode=\'relative\',则表示从当前所在行移动value条,如果mode=\'absolute\',则表示从结果集的第一行移动value条. 下面是具体进行数据库操作的示意代码：', '', NULL, 'jamiesun.net@gmail.com', '', '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', 0, '2012-07-07 22:00:32'),
	('16ff3ce9058a4159ab217edbe2a87d4d', '2fede7d45b46482bab7d310c6b73b891', 'wer评论内容（支持markdown语法）', 'jamiesun.net@gmail.com', NULL, 'http://t.sina.com.cn/ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack', '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', '0', 0, '2012-07-07 23:06:57'),
	('388804a7856b454a93ed7ccebf559811', '2fede7d45b46482bab7d310c6b73b891', 'se Ultra simplistic and minimally styled pagination inspired by Rdio, great for apps and search results. The large block is hard to miss, easily scalable, and provides large click areas. Stateful page links Links are customizable and work in a number of circumstances with the right class. .disabled for unclickable links and .active for current page. Flexible alignment Add either of two optional classes to change the alignment of pagination links: .pagination-centered and .pagination-right.', 'jamiiesun', NULL, 'jamiesun.net@gmail.com', 'http://redis.io', '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', 0, '2012-07-07 23:15:24'),
	('3a3ab6c50143410ca1ab6d422e057a0a', 'd26d6219c98341fbbbce89d3d893242f', '移动指针到某一行.如果mode=\'relative\',则表示从当前所在行移动value条,如果mode=\'absolute\',则表示从结果集的第一行移动value条. 下面是具体进行数据库操作的示意代码：', '', NULL, 'jamiesun.net@gmail.com', '', '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', 0, '2012-07-07 22:00:13'),
	('76d2ef11a52f43bbbc87304dcc37cf06', '2fede7d45b46482bab7d310c6b73b891', '非常反感', '', NULL, 'jamiesun.net@gmail.com', '', '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', 0, '2012-07-07 22:02:16'),
	('7aa956001a3141f99c6b405154790ad2', '2fede7d45b46482bab7d310c6b73b891', '345r35', '', NULL, 'jamiesun.net@gmail.com', '', '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', 0, '2012-07-07 22:10:17'),
	('9680812ba5fa4184be5727f9bb185eb5', '8c1cf870893f4dc3820075616cf75475', '', '', NULL, '', '', '127.0.0.1', 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0)', 0, '2012-07-08 01:28:01'),
	('9ee52791b3a24a77a44c6509dfad6df0', '2fede7d45b46482bab7d310c6b73b891', '非常反感', '', NULL, 'jamiesun.net@gmail.com', '', '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', 0, '2012-07-07 22:10:10'),
	('a6e267e0c1c64a38b1c17d81e005038d', '8c1cf870893f4dc3820075616cf75475', '>ith two paragraphs. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus. Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.', NULL, 'c6ea05d93eb44b9a988ffbfe84d869a9', NULL, NULL, '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', 1, '2012-07-07 23:36:06'),
	('b5bf7b2f2e5a4c73848c55d9424fe827', '8c1cf870893f4dc3820075616cf75475', '', '', NULL, '', '', '127.0.0.1', 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0)', 0, '2012-07-08 01:28:07'),
	('b7802081076d47868dceea1445c94d05', '8c1cf870893f4dc3820075616cf75475', 'dsffdg', NULL, 'c6ea05d93eb44b9a988ffbfe84d869a9', NULL, NULL, '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', 1, '2012-07-07 23:35:56'),
	('b9712795bc1e46578d74b9860d77469d', '2fede7d45b46482bab7d310c6b73b891', 'ewrerewteterWhen to use Ultra simplistic and minimally styled pagination inspired by Rdio, great for apps and search results. The large block is hard to miss, easily scalable, and provides large click areas. Stateful page links Links are customizable and work in a number of circumstances with the right class. .disabled for unclickable links and .active for current page. Flexible alignment Add either of two optional classes to change the alignment of pagination links: .pagination-centered and .pagination-right.', NULL, '', '6583805@qq.com', 'http://ew', '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', 0, '2012-07-07 23:10:12'),
	('c0c6dd282b184c1f9b21b97c6d75b8ef', 'd26d6219c98341fbbbce89d3d893242f', '移动指针到某一行.如果mode=\'relative\',则表示从当前所在行移动value条,如果mode=\'absolute\',则表示从结果集的第一行移动value条. 下面是具体进行数据库操作的示意代码：', '', NULL, 'jamiesun.net@gmail.com', '', '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', 0, '2012-07-07 22:00:28'),
	('d4a8e6fbdc15416b9e154183aaa23020', 'e7b9ce6ef0d64e8d808440bf9b9bbc93', 'ylint over PostgreSQL PL/Python functions pylint 0.25.1	9	python code static checker DirPyLint 1.1.3	7	PyLint for your directories logilab.pylintinstaller 0.15.2	7	egg installer for Pylint pylint2tusar 0.3	7	PyLint plugin to allow TUSAR output format setuptools-lint 0.1	5	Setuptools command for pylint EatLint 1.1.0	4	PyLint Summary and Graph Generators for Bitten. pylint-i18n 0.1.3	4	Find strings in your code that should be passed through gettext eggchecker 0.1.3dev	2	setuptools command extensions to run QA and tests on the code unilint 0.1.3	2	script wrapping static code analyzers producing unified output AChemKit 0.3.0	1	An Artificial Chemistry Tookit aristoxenus 0.1.0	1	Library for music data and humdrum parsing astng 0.16.1	1	extend python\'s abstract syntax tree breadability 0.1.6	1	Redone port of Readability API in Python collective.disqus 0.3.1	1	Integrates DISQUS comment system with Plone. cutadapt 1.1	1	trim adapters from high-throughput sequencing reads dedun 0.3.2	1	Dedun is a Python client for the RES', 'jamiesun', '', 'jamiesun.net@gmail.com', 'http://weibo.com/ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack', '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', 0, '2012-07-07 23:11:42'),
	('ea20540918464561a34fcf4173c9dc0a', '9707434a97fd48fe97ae40bfa980e844', '> import cc', '345345', NULL, 'jamiesun.net@gmail.com', 'http://weibo.com/ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack', '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', 0, '2012-07-07 23:25:32'),
	('eadf3c931bec47ce8bea8b97901658d3', '2fede7d45b46482bab7d310c6b73b891', 'wer评论内容（支持markdown语法）', 'jamiesun.net@gmail.com', NULL, 'http://t.sina.com.cn/ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack', '127.0.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/21.0.1171.0 Safari/537.1', '0', 0, '2012-07-07 23:07:56');
/*!40000 ALTER TABLE `comments` ENABLE KEYS */;


-- Dumping structure for table talkincode_db1.groups
DROP TABLE IF EXISTS `groups`;
CREATE TABLE IF NOT EXISTS `groups` (
  `id` int(4) NOT NULL AUTO_INCREMENT,
  `name` varchar(32) NOT NULL DEFAULT '',
  `description` text,
  `guid` varchar(32) NOT NULL,
  `posts` int(11) NOT NULL DEFAULT '0',
  PRIMARY KEY (`id`),
  UNIQUE KEY `guid` (`guid`)
) ENGINE=InnoDB AUTO_INCREMENT=14 DEFAULT CHARSET=utf8;

-- Dumping data for table talkincode_db1.groups: ~6 rows (approximately)
DELETE FROM `groups`;
/*!40000 ALTER TABLE `groups` DISABLE KEYS */;
INSERT INTO `groups` (`id`, `name`, `description`, `guid`, `posts`) VALUES
	(8, 'python编程', NULL, 'python', 0),
	(9, 'vim小站', NULL, 'vim', 0),
	(10, 'html&css', NULL, 'html', 0),
	(11, 'emacs小站', NULL, 'emacs', 0),
	(12, 'sublime text 2小站', NULL, 'st2', 0),
	(13, 'php编程', NULL, 'php', 0);
/*!40000 ALTER TABLE `groups` ENABLE KEYS */;


-- Dumping structure for table talkincode_db1.langs
DROP TABLE IF EXISTS `langs`;
CREATE TABLE IF NOT EXISTS `langs` (
  `id` int(4) NOT NULL AUTO_INCREMENT,
  `name` varchar(32) NOT NULL DEFAULT '',
  `hits` int(10) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=58 DEFAULT CHARSET=utf8;

-- Dumping data for table talkincode_db1.langs: ~19 rows (approximately)
DELETE FROM `langs`;
/*!40000 ALTER TABLE `langs` DISABLE KEYS */;
INSERT INTO `langs` (`id`, `name`, `hits`) VALUES
	(39, 'c', 0),
	(40, 'c++', 0),
	(41, 'java', 0),
	(42, 'c#', 0),
	(43, 'python', 0),
	(44, 'ruby', 0),
	(45, 'php', 0),
	(46, 'perl', 0),
	(47, 'objective-c', 0),
	(48, 'vb', 0),
	(49, 'javascript', 0),
	(50, ' pascal', 0),
	(51, 'Lisp', 0),
	(52, 'sql', 0),
	(53, 'ada', 0),
	(54, 'lua', 0),
	(55, 'matlab', 0),
	(56, 'shell', 0),
	(57, 'go', 0);
/*!40000 ALTER TABLE `langs` ENABLE KEYS */;


-- Dumping structure for table talkincode_db1.postmeta
DROP TABLE IF EXISTS `postmeta`;
CREATE TABLE IF NOT EXISTS `postmeta` (
  `id` varchar(32) NOT NULL,
  `postid` varchar(32) NOT NULL,
  `key` varchar(255) NOT NULL,
  `value` text,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- Dumping data for table talkincode_db1.postmeta: ~0 rows (approximately)
DELETE FROM `postmeta`;
/*!40000 ALTER TABLE `postmeta` DISABLE KEYS */;
/*!40000 ALTER TABLE `postmeta` ENABLE KEYS */;


-- Dumping structure for table talkincode_db1.posts
DROP TABLE IF EXISTS `posts`;
CREATE TABLE IF NOT EXISTS `posts` (
  `id` varchar(32) NOT NULL,
  `userid` varchar(32) NOT NULL,
  `groupid` varchar(32) NOT NULL,
  `title` varchar(255) NOT NULL,
  `tags` varchar(255) NOT NULL,
  `description` varchar(1024) DEFAULT NULL,
  `content` text NOT NULL,
  `status` int(1) NOT NULL DEFAULT '1',
  `hits` int(10) NOT NULL DEFAULT '0',
  `created` varchar(19) NOT NULL,
  `modified` varchar(19) NOT NULL,
  PRIMARY KEY (`id`),
  KEY `created` (`created`),
  KEY `modified` (`modified`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- Dumping data for table talkincode_db1.posts: ~8 rows (approximately)
DELETE FROM `posts`;
/*!40000 ALTER TABLE `posts` DISABLE KEYS */;
INSERT INTO `posts` (`id`, `userid`, `groupid`, `title`, `tags`, `description`, `content`, `status`, `hits`, `created`, `modified`) VALUES
	('2fede7d45b46482bab7d310c6b73b891', 'c6ea05d93eb44b9a988ffbfe84d869a9', '9', 'add a plugin named ShareCodeLibrary', '个性,士大夫', NULL, 'When to use\r\nUltra simplistic and minimally styled pagination inspired by Rdio, great for apps and search results. The large block is hard to miss, easily scalable, and provides large click areas.\r\n\r\nStateful page links\r\nLinks are customizable and work in a number of circumstances with the right class. .disabled for unclickable links and .active for current page.\r\n\r\nFlexible alignment\r\nAdd either of two optional classes to change the alignment of pagination links: .pagination-centered and .pagination-right.', 1, 24, '2012-07-07 18:17:59', '2012-07-07 18:17:59'),
	('321737b247df4d91a24aa89430229678', 'c6ea05d93eb44b9a988ffbfe84d869a9', '8', 'python实现短网址生成', '435345', NULL, '23423', 1, 2, '2012-07-07 14:51:28', '2012-07-07 14:51:28'),
	('817245fa3e0c4062bf908a2039773c8d', 'c6ea05d93eb44b9a988ffbfe84d869a9', '8', 'python实现短网址生成', '435345', NULL, '23423厄特问题', 1, 5, '2012-07-07 15:14:23', '2012-07-07 15:14:23'),
	('8c1cf870893f4dc3820075616cf75475', 'c6ea05d93eb44b9a988ffbfe84d869a9', '8', 'Java编程那些事儿25—位运算符 - 技术应用 - 豆豆网', '个性,士大夫', NULL, '# 这是 H1\r\n\r\n## 这是 H2\r\n\r\n###### 这是 H6\r\n> This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,\r\nconsectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.\r\nVestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.\r\n\r\n> Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse\r\nid sem consectetuer libero luctus adipiscing.', 1, 24, '2012-07-07 23:28:31', '2012-07-07 23:28:31'),
	('9707434a97fd48fe97ae40bfa980e844', 'c6ea05d93eb44b9a988ffbfe84d869a9', '8', '如何同时运行两个连接，连接H2数据库？', '而特体', NULL, '最近正在搞springside，第一次接触的H2数据库，发现居然只能运行一个实例！？\r\n如果运行网站（在eclipse跑的MiniWebServer），就不能使用h2-console.bat直接查看数据，总提示：Database may be already in use: "Server is running". Possible solutions: close all other connection(s); use the server mode; SQL statement\r\n\r\n如果 使用h2-console.bat 就没办法运行网站\r\n\r\n请问这个如何处理，使之同时运行？', 1, 48, '2012-07-07 16:23:29', '2012-07-07 16:23:29'),
	('d02cdb457f5e4a23a30ebcaf1c55ee93', 'c6ea05d93eb44b9a988ffbfe84d869a9', '8', 'python实现短网址生成', '435345', NULL, '23423', 1, 1, '2012-07-07 15:14:11', '2012-07-07 15:14:11'),
	('d26d6219c98341fbbbce89d3d893242f', 'c6ea05d93eb44b9a988ffbfe84d869a9', '9', 'ensymble.py:mergesis 合并多个sis文件', '个性,士大夫', NULL, '建立建立连接后，首先就要获取一个Cursor对象，因为以后的数据库操作都要通过它来进行。那么Cursor对象都有哪些方法呢？Cursor对象的主要有以下方法：\r\ncallproc(self, procname, args)：执行存储过程,接收的参数为存储过程名和参数列表,返回值为受影响的行数\r\nexecute(self, query, args)：执行单条sql语句,接收的参数为sql语句本身和使用的参数列表,返回值为受影响的行数\r\nexecutemany(self, query, args)：执行单挑sql语句,但是重复执行参数列表里的参数,返回值为受影响的行数\r\nnextset(self)：移动到下一个结果集\r\nfetchall(self)：接收全部的返回结果行.\r\nfetchmany(self, size=None)：接收size条返回结果行.如果size的值大于返回的结果行的数量,则会返回cursor.arraysize条数据.\r\nfetchone(self)：返回一条结果行.\r\nscroll(self, value, mode=\'relative\')：移动指针到某一行.如果mode=\'relative\',则表示从当前所在行移动value条,如果mode=\'absolute\',则表示从结果集的第一行移动value条.\r\n下面是具体进行数据库操作的示意代码：', 1, 10, '2012-07-07 18:16:45', '2012-07-07 18:16:45'),
	('e7b9ce6ef0d64e8d808440bf9b9bbc93', 'c6ea05d93eb44b9a988ffbfe84d869a9', '9', 'Java编程那些事儿25—位运算符 - 技术应用 - 豆豆网', '个性,士大夫', NULL, 'runs pylint over PostgreSQL PL/Python functions\r\npylint 0.25.1	9	python code static checker\r\nDirPyLint 1.1.3	7	PyLint for your directories\r\nlogilab.pylintinstaller 0.15.2	7	egg installer for Pylint\r\npylint2tusar 0.3	7	PyLint plugin to allow TUSAR output format\r\nsetuptools-lint 0.1	5	Setuptools command for pylint\r\nEatLint 1.1.0	4	PyLint Summary and Graph Generators for Bitten.\r\npylint-i18n 0.1.3	4	Find strings in your code that should be passed through gettext\r\neggchecker 0.1.3dev	2	setuptools command extensions to run QA and tests on the code\r\nunilint 0.1.3	2	script wrapping static code analyzers producing unified output\r\nAChemKit 0.3.0	1	An Artificial Chemistry Tookit\r\naristoxenus 0.1.0	1	Library for music data and humdrum parsing\r\nastng 0.16.1	1	extend python\'s abstract syntax tree\r\nbreadability 0.1.6	1	Redone port of Readability API in Python\r\ncollective.disqus 0.3.1	1	Integrates DISQUS comment system with Plone.\r\ncutadapt 1.1	1	trim adapters from high-throughput sequencing reads\r\ndedun 0.3.2	1	Dedun is a Python client for the RES', 1, 3, '2012-07-07 18:12:06', '2012-07-07 18:12:06');
/*!40000 ALTER TABLE `posts` ENABLE KEYS */;


-- Dumping structure for table talkincode_db1.settings
DROP TABLE IF EXISTS `settings`;
CREATE TABLE IF NOT EXISTS `settings` (
  `key` varchar(255) NOT NULL,
  `value` text,
  `desc` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`key`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- Dumping data for table talkincode_db1.settings: ~1 rows (approximately)
DELETE FROM `settings`;
/*!40000 ALTER TABLE `settings` DISABLE KEYS */;
INSERT INTO `settings` (`key`, `value`, `desc`) VALUES
	('LANG_SET', 'c , c++,java,c#,python,ruby,php,perl,objective-c,vb,javascript, pascal,Lisp,sql,ada,lua,matlab,shell,go', NULL);
/*!40000 ALTER TABLE `settings` ENABLE KEYS */;


-- Dumping structure for table talkincode_db1.tags
DROP TABLE IF EXISTS `tags`;
CREATE TABLE IF NOT EXISTS `tags` (
  `id` varchar(32) NOT NULL,
  `tagname` varchar(64) NOT NULL,
  `hits` int(10) DEFAULT '0'
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- Dumping data for table talkincode_db1.tags: ~0 rows (approximately)
DELETE FROM `tags`;
/*!40000 ALTER TABLE `tags` DISABLE KEYS */;
/*!40000 ALTER TABLE `tags` ENABLE KEYS */;


-- Dumping structure for table talkincode_db1.usermeta
DROP TABLE IF EXISTS `usermeta`;
CREATE TABLE IF NOT EXISTS `usermeta` (
  `id` varchar(32) NOT NULL,
  `userid` varchar(32) NOT NULL,
  `key` varchar(255) NOT NULL,
  `value` text,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- Dumping data for table talkincode_db1.usermeta: ~0 rows (approximately)
DELETE FROM `usermeta`;
/*!40000 ALTER TABLE `usermeta` DISABLE KEYS */;
/*!40000 ALTER TABLE `usermeta` ENABLE KEYS */;


-- Dumping structure for table talkincode_db1.users
DROP TABLE IF EXISTS `users`;
CREATE TABLE IF NOT EXISTS `users` (
  `id` varchar(32) NOT NULL,
  `username` varchar(64) NOT NULL,
  `password` varchar(64) NOT NULL,
  `nicename` varchar(64) DEFAULT NULL,
  `email` varchar(128) DEFAULT NULL,
  `url` varchar(128) DEFAULT NULL,
  `created` varchar(19) NOT NULL,
  `lastlogin` varchar(19) NOT NULL,
  `status` int(2) NOT NULL DEFAULT '0',
  `authkey` varchar(128) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `username` (`username`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- Dumping data for table talkincode_db1.users: ~3 rows (approximately)
DELETE FROM `users`;
/*!40000 ALTER TABLE `users` DISABLE KEYS */;
INSERT INTO `users` (`id`, `username`, `password`, `nicename`, `email`, `url`, `created`, `lastlogin`, `status`, `authkey`) VALUES
	('4661d99ed6c44cffac0ec49a8810fed9', 'test', '123456', NULL, 'test@com', NULL, '2012-07-07 01:13:54', '2012-07-07 01:13:54', 0, '4661d99ed6c44cffac0ec49a8810fed9'),
	('c6ea05d93eb44b9a988ffbfe84d869a9', 'jamiesun', '111111', 'jamiesun', 'jamiesun.net@gmail.com', NULL, '2012-07-07 01:20:22', '2012-07-07 01:20:22', 0, 'c6ea05d93eb44b9a988ffbfe84d869a9'),
	('e3fbf732af7a4f09ae8a2fc9c14e1fc6', 'test2', '123456', 'test2', 'test@com', NULL, '2012-07-07 01:17:17', '2012-07-07 01:17:17', 0, 'e3fbf732af7a4f09ae8a2fc9c14e1fc6');
/*!40000 ALTER TABLE `users` ENABLE KEYS */;
/*!40101 SET SQL_MODE=IFNULL(@OLD_SQL_MODE, '') */;
/*!40014 SET FOREIGN_KEY_CHECKS=IF(@OLD_FOREIGN_KEY_CHECKS IS NULL, 1, @OLD_FOREIGN_KEY_CHECKS) */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
